{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32ad471e",
   "metadata": {},
   "source": [
    "# Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0cb1a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, Lambda, Input, GlobalAveragePooling1D\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6abf6ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Model() :\n",
    "    def __init__(self, weight, input_shape) :\n",
    "        self.checkpoint = weight\n",
    "        self.model = self.build_model(input_shape)\n",
    "        \n",
    "    def build_model(self, input_shape : tuple):\n",
    "        input = Input(shape=input_shape)\n",
    "        x = LSTM(128, return_sequences=True, activation='tanh', dropout=0.2)(input)\n",
    "        x = LSTM(64, return_sequences=True, activation='tanh', dropout=0.2)(x)\n",
    "        x = LSTM(32, return_sequences=True, activation='tanh', dropout=0.2)(x)\n",
    "        x = GlobalAveragePooling1D()(x)\n",
    "        output = Dense(1)(x)\n",
    "        return Model(input, output)\n",
    "        \n",
    "    \n",
    "    def load_model(self) :\n",
    "        self.model.load_weights(self.checkpoint)\n",
    "        return self.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fb21423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 6, 6)]            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 6, 128)            69120     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 6, 64)             49408     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 6, 32)             12416     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 130,977\n",
      "Trainable params: 130,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "window_size = 6\n",
    "n_feature = 6\n",
    "\n",
    "weight = './checkpoints/ckeckpointer.ckpt'\n",
    "input_shape = (window_size, n_feature)\n",
    "\n",
    "model = Custom_Model(weight, input_shape)\n",
    "lstm_model = model.load_model()\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae09625e",
   "metadata": {},
   "source": [
    "# Inference Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0206f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pyupbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f8111da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_preprocess() :\n",
    "    def __init__(self, ticker, interval, to, count) :\n",
    "        self.dataset = pyupbit.get_ohlcv(ticker=ticker, interval=interval, to=to, count=count)\n",
    "        self.preprocess()\n",
    "        \n",
    "    def preprocess(self) :\n",
    "        # index(시간) 제거\n",
    "        dataset_df = self.dataset.reset_index(drop=True)\n",
    "        \n",
    "        # value 제거\n",
    "        dataset_df = dataset_df.drop(columns=['value'])\n",
    "        \n",
    "        # avg_price 추가\n",
    "        dataset_df['avg_price'] = (dataset_df['high'] + dataset_df['low'] +\n",
    "                                  dataset_df['open'] + dataset_df['close']) // 4\n",
    "        \n",
    "        # min max 정규화 (MinMaxScaler) 적용\n",
    "        norm = MinMaxScaler()\n",
    "        norm_dataset = norm.fit_transform(dataset_df)\n",
    "        norm_dataset = pd.DataFrame(norm_dataset, columns=list(dataset_df.columns))\n",
    "        self.data = norm_dataset\n",
    "        \n",
    "        # 예측될 값(label)인 10분 후 가격\n",
    "        after10 = np.zeros_like(norm_dataset['close'])\n",
    "        for i in range(len(norm_dataset['close']) - 1) :\n",
    "            after10[i] = norm_dataset['close'][i + 1]\n",
    "            self.label = after10\n",
    "        \n",
    "    def windowed_dataset(self, window_size, batch_size) :\n",
    "        sliced_data = tf.data.Dataset.from_tensor_slices(self.data)\n",
    "        sliced_data = sliced_data.window(window_size, shift=1, stride=1, drop_remainder=True)\n",
    "        sliced_data = sliced_data.flat_map(lambda x : x.batch(window_size))\n",
    "        \n",
    "        sliced_label = tf.data.Dataset.from_tensor_slices(self.label[window_size:])\n",
    "        \n",
    "        sliced_dataset = tf.data.Dataset.zip((sliced_data, sliced_label))\n",
    "        \n",
    "        return sliced_dataset.batch(batch_size).prefetch(1)\n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8207beae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data == \n",
      "tf.Tensor(\n",
      "[[[0.22419028 0.21817058 0.23657237 0.203964   0.12238874 0.21419267]\n",
      "  [0.2041498  0.20220437 0.23677737 0.20993023 0.07456903 0.20658573]\n",
      "  [0.21012146 0.2092089  0.24446494 0.21266053 0.07799429 0.21255145]\n",
      "  [0.21295547 0.20879687 0.24395244 0.21963798 0.0829506  0.21484395]\n",
      "  [0.21973684 0.20488257 0.22539975 0.19445849 0.06683506 0.20439744]\n",
      "  [0.19463563 0.1894314  0.20110701 0.17382951 0.11533618 0.18254051]]], shape=(1, 6, 6), dtype=float64)\n",
      "\n",
      "Label == \n",
      "tf.Tensor([0.16988573], shape=(1,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "ticker = 'KRW-BTC'\n",
    "interval ='minute10'\n",
    "to = f'2021-11-10 00:10'\n",
    "count = 1000\n",
    "\n",
    "window_size = 6\n",
    "batch_size = 1\n",
    "\n",
    "processed_data =  Data_preprocess(ticker, interval, to, count)\n",
    "dataset = processed_data.windowed_dataset(window_size, batch_size)\n",
    "\n",
    "\n",
    "for data in dataset.take(1):\n",
    "    print(\"Data == \")\n",
    "    print(data[0])\n",
    "    \n",
    "    print(\"\\nLabel == \")\n",
    "    print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e930768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20993023, 0.21266053, 0.21963798, 0.19445849, 0.17382951,\n",
       "       0.17807665, 0.16988573, 0.17039134, 0.16493073, 0.15633532,\n",
       "       0.15775104, 0.15673981, 0.15259379, 0.15522298, 0.14854889,\n",
       "       0.14147032, 0.15552634, 0.1782789 , 0.15967236, 0.17595308,\n",
       "       0.15067246, 0.14167257, 0.12953787, 0.12134695, 0.13469512,\n",
       "       0.1530994 , 0.1553241 , 0.15077359, 0.13439175, 0.14531297,\n",
       "       0.14359389, 0.12387501, 0.12104358, 0.13075134, 0.13702093,\n",
       "       0.13894226, 0.12539185, 0.12377389, 0.10547073, 0.09232481,\n",
       "       0.09192032, 0.10880777, 0.13044797, 0.1355041 , 0.11426838,\n",
       "       0.13044797, 0.09101021, 0.10011123, 0.11517848, 0.16189706,\n",
       "       0.15330165, 0.14602083, 0.16199818, 0.15239155, 0.13631308,\n",
       "       0.13580746, 0.10809991, 0.11881889, 0.13499848, 0.14197593,\n",
       "       0.16068359, 0.1720093 , 0.15370614, 0.15026797, 0.15856002,\n",
       "       0.15684093, 0.14844777, 0.16179593, 0.13975124, 0.1175043 ,\n",
       "       0.11558297, 0.09910001, 0.09101021, 0.07119021, 0.09505511,\n",
       "       0.10092021, 0.11740318, 0.13762767, 0.14561634, 0.12266154,\n",
       "       0.10274042, 0.10587521, 0.11093134, 0.12033573, 0.1062797 ,\n",
       "       0.09262817, 0.10112246, 0.10122358, 0.1062797 , 0.09404389,\n",
       "       0.11507736, 0.14308828, 0.13843665, 0.09687532, 0.11002124,\n",
       "       0.11285266, 0.11093134, 0.11831328, 0.11174032, 0.1125493 ,\n",
       "       0.12883001, 0.12468399, 0.12438062, 0.14056022, 0.1355041 ,\n",
       "       0.1503691 , 0.13833552, 0.12529073, 0.12791991, 0.12438062,\n",
       "       0.11143695, 0.10648195, 0.10698756, 0.11416726, 0.11588634,\n",
       "       0.10901001, 0.10031348, 0.10516736, 0.10567297, 0.07917889,\n",
       "       0.04955001, 0.05976337, 0.06299929, 0.06906664, 0.0738194 ,\n",
       "       0.0715947 , 0.03225806, 0.01921327, 0.02103347, 0.01547174,\n",
       "       0.01911214, 0.        , 0.01375265, 0.02871878, 0.00707857,\n",
       "       0.02426939, 0.03974113, 0.0378198 , 0.03812317, 0.05966225,\n",
       "       0.07836991, 0.09818991, 0.07058348, 0.06198807, 0.04853878,\n",
       "       0.05622409, 0.06360603, 0.07028011, 0.09727981, 0.08099909,\n",
       "       0.06967337, 0.08817878, 0.02153908, 0.07634746, 0.05935888,\n",
       "       0.09171807, 0.16826777, 0.16584083, 0.18303165, 0.17312165,\n",
       "       0.17706543, 0.17140257, 0.1800991 , 0.16311053, 0.17403175,\n",
       "       0.16917787, 0.16725655, 0.16786328, 0.16321165, 0.16007685,\n",
       "       0.16331277, 0.16745879, 0.19668318, 0.20163818, 0.23551421,\n",
       "       0.21154818, 0.18111032, 0.19688543, 0.1782789 , 0.18394175,\n",
       "       0.18899788, 0.18363839, 0.1850541 , 0.1733239 , 0.1760542 ,\n",
       "       0.17625645, 0.20113257, 0.1810092 , 0.19415512, 0.2021438 ,\n",
       "       0.199009  , 0.17190818, 0.14096471, 0.16725655, 0.17211043,\n",
       "       0.14379614, 0.13954899, 0.13247042, 0.13085246, 0.12185256,\n",
       "       0.13499848, 0.13135807, 0.12397614, 0.1265042 , 0.15077359,\n",
       "       0.14480736, 0.13833552, 0.12791991, 0.13782991, 0.14399838,\n",
       "       0.13408838, 0.13833552, 0.14996461, 0.15067246, 0.15087471,\n",
       "       0.15603195, 0.15208818, 0.16533522, 0.1521893 , 0.15279604,\n",
       "       0.15269491, 0.13762767, 0.14248155, 0.1422793 , 0.14349277,\n",
       "       0.15673981, 0.164324  , 0.15208818, 0.14238042, 0.14440287,\n",
       "       0.15400951, 0.14217818, 0.13762767, 0.14076246, 0.12053797,\n",
       "       0.11153807, 0.10911113, 0.12235818, 0.12680756, 0.10901001,\n",
       "       0.09849328, 0.08423501, 0.07786429, 0.0936394 , 0.07958338,\n",
       "       0.07199919, 0.1053696 , 0.10749317, 0.10729093, 0.10011123,\n",
       "       0.1013247 , 0.10931338, 0.09849328, 0.11639195, 0.13044797,\n",
       "       0.13044797, 0.12195369, 0.0985944 , 0.10789766, 0.10799879,\n",
       "       0.11881889, 0.11730205, 0.10729093, 0.11720093, 0.1116392 ,\n",
       "       0.11740318, 0.1404591 , 0.12812216, 0.12256042, 0.12235818,\n",
       "       0.12438062, 0.164324  , 0.17291941, 0.17413287, 0.15845889,\n",
       "       0.14470624, 0.14480736, 0.13489736, 0.11275154, 0.09990899,\n",
       "       0.10516736, 0.11669532, 0.09404389, 0.09727981, 0.10779654,\n",
       "       0.10506624, 0.10789766, 0.09869552, 0.10203256, 0.09849328,\n",
       "       0.10274042, 0.09151583, 0.08393164, 0.11396501, 0.09808879,\n",
       "       0.10870664, 0.10809991, 0.12053797, 0.12609971, 0.12417838,\n",
       "       0.11467287, 0.11194256, 0.10860552, 0.11598746, 0.10607746,\n",
       "       0.11629083, 0.10658307, 0.11538073, 0.11376277, 0.12286379,\n",
       "       0.12458287, 0.12508848, 0.11720093, 0.11649307, 0.11629083,\n",
       "       0.11103246, 0.1165942 , 0.11800991, 0.11800991, 0.11538073,\n",
       "       0.09030236, 0.10749317, 0.10122358, 0.10506624, 0.09333603,\n",
       "       0.08919001, 0.08676307, 0.11396501, 0.11285266, 0.10779654,\n",
       "       0.10122358, 0.10081909, 0.1165942 , 0.08575185, 0.08797654,\n",
       "       0.09070685, 0.08403276, 0.06886439, 0.08757205, 0.10253817,\n",
       "       0.08676307, 0.09293154, 0.12053797, 0.14561634, 0.15724542,\n",
       "       0.15269491, 0.15067246, 0.1571443 , 0.15158257, 0.14753767,\n",
       "       0.16513298, 0.21255941, 0.19172818, 0.18282941, 0.18737992,\n",
       "       0.20477298, 0.19304277, 0.18515522, 0.19324502, 0.18454849,\n",
       "       0.19041359, 0.18111032, 0.18808777, 0.19102033, 0.19911012,\n",
       "       0.1769643 , 0.19193043, 0.19799778, 0.21903125, 0.20507635,\n",
       "       0.21437961, 0.21539084, 0.20184043, 0.19617757, 0.20123369,\n",
       "       0.20244716, 0.20244716, 0.20750329, 0.20376176, 0.19658206,\n",
       "       0.16968349, 0.17716655, 0.1868743 , 0.18070583, 0.17575083,\n",
       "       0.19455961, 0.18111032, 0.18829002, 0.1832339 , 0.1670543 ,\n",
       "       0.16644757, 0.16584083, 0.17251492, 0.18090808, 0.17838002,\n",
       "       0.17362726, 0.17089696, 0.17716655, 0.16503185, 0.15067246,\n",
       "       0.16887451, 0.18282941, 0.16462736, 0.15957124, 0.17039134,\n",
       "       0.17403175, 0.16088583, 0.17281828, 0.17999798, 0.18303165,\n",
       "       0.17382951, 0.16543634, 0.16108808, 0.18475073, 0.18394175,\n",
       "       0.18636869, 0.17807665, 0.18262716, 0.18313277, 0.16563859,\n",
       "       0.17160481, 0.15896451, 0.15279604, 0.16321165, 0.15785216,\n",
       "       0.14278491, 0.13691981, 0.12377389, 0.12033573, 0.12994236,\n",
       "       0.12124583, 0.10516736, 0.11629083, 0.11689756, 0.12539185,\n",
       "       0.12690869, 0.1215492 , 0.12953787, 0.11042573, 0.12013348,\n",
       "       0.12175144, 0.11093134, 0.13034685, 0.11426838, 0.13287491,\n",
       "       0.12165032, 0.11477399, 0.12043685, 0.12680756, 0.12599858,\n",
       "       0.12225705, 0.13924563, 0.12680756, 0.12711093, 0.13793103,\n",
       "       0.13095358, 0.14217818, 0.14986348, 0.14945899, 0.15542522,\n",
       "       0.16038022, 0.154414  , 0.15370614, 0.15087471, 0.15916675,\n",
       "       0.16584083, 0.15451512, 0.15097583, 0.15360502, 0.15764991,\n",
       "       0.14612195, 0.14895338, 0.14086359, 0.1323693 , 0.14025685,\n",
       "       0.13257154, 0.13338052, 0.13813328, 0.13267267, 0.13277379,\n",
       "       0.14278491, 0.13166144, 0.13034685, 0.11072909, 0.1152796 ,\n",
       "       0.13813328, 0.14349277, 0.14824553, 0.13287491, 0.13499848,\n",
       "       0.14126808, 0.13135807, 0.1413692 , 0.13944787, 0.13752654,\n",
       "       0.1413692 , 0.14248155, 0.13044797, 0.14187481, 0.1440995 ,\n",
       "       0.1440995 , 0.14167257, 0.15138032, 0.14682981, 0.14056022,\n",
       "       0.14278491, 0.14440287, 0.15107695, 0.14865002, 0.1530994 ,\n",
       "       0.14551522, 0.15289716, 0.15057134, 0.15451512, 0.1481444 ,\n",
       "       0.14743655, 0.15168369, 0.15057134, 0.15350389, 0.14167257,\n",
       "       0.11204368, 0.1292345 , 0.12195369, 0.12589746, 0.14743655,\n",
       "       0.15138032, 0.14207706, 0.15431287, 0.14865002, 0.15562746,\n",
       "       0.1481444 , 0.15299828, 0.14703206, 0.15279604, 0.14743655,\n",
       "       0.14703206, 0.15077359, 0.14399838, 0.13793103, 0.13793103,\n",
       "       0.12943675, 0.12589746, 0.13297603, 0.14622308, 0.14753767,\n",
       "       0.13954899, 0.12215593, 0.13257154, 0.13884114, 0.12953787,\n",
       "       0.14844777, 0.14966124, 0.13257154, 0.12306603, 0.13247042,\n",
       "       0.13985236, 0.13803216, 0.13368389, 0.13034685, 0.13044797,\n",
       "       0.14430175, 0.13257154, 0.12984124, 0.14056022, 0.14015573,\n",
       "       0.12822328, 0.12953787, 0.12933563, 0.12357165, 0.12953787,\n",
       "       0.12943675, 0.12893114, 0.13459399, 0.13479624, 0.12721205,\n",
       "       0.11922338, 0.12458287, 0.12670644, 0.12690869, 0.14207706,\n",
       "       0.13995348, 0.13742542, 0.13702093, 0.14561634, 0.14763879,\n",
       "       0.15016685, 0.14844777, 0.1422793 , 0.14268379, 0.14248155,\n",
       "       0.15269491, 0.14298716, 0.15016685, 0.14905451, 0.15572859,\n",
       "       0.16230155, 0.1530994 , 0.14824553, 0.15694206, 0.15067246,\n",
       "       0.15229042, 0.15067246, 0.16038022, 0.16725655, 0.17059359,\n",
       "       0.16968349, 0.17706543, 0.17443624, 0.18212155, 0.17049247,\n",
       "       0.16776216, 0.17049247, 0.16877338, 0.16634645, 0.16381838,\n",
       "       0.16584083, 0.17079583, 0.17666094, 0.17160481, 0.17848114,\n",
       "       0.18040247, 0.19031247, 0.1751441 , 0.17291941, 0.17150369,\n",
       "       0.2210537 , 0.24744666, 0.25826676, 0.24309839, 0.23763778,\n",
       "       0.23349176, 0.23945798, 0.24552533, 0.23844676, 0.23824451,\n",
       "       0.25250278, 0.26190717, 0.25685105, 0.26342401, 0.25786227,\n",
       "       0.24218829, 0.26352513, 0.2656487 , 0.26544646, 0.28880574,\n",
       "       0.29032258, 0.29558095, 0.30356962, 0.29507534, 0.29234503,\n",
       "       0.29821013, 0.29578319, 0.28041258, 0.28718778, 0.27616544,\n",
       "       0.25361513, 0.26504197, 0.27252503, 0.26180605, 0.25776115,\n",
       "       0.24977247, 0.25937911, 0.25179492, 0.24835676, 0.2498736 ,\n",
       "       0.24876125, 0.25179492, 0.23652543, 0.23753666, 0.23966023,\n",
       "       0.23976135, 0.24158156, 0.24946911, 0.25270503, 0.23531196,\n",
       "       0.22762666, 0.22813227, 0.24239053, 0.25523309, 0.25604207,\n",
       "       0.27677217, 0.27727778, 0.26423299, 0.25766003, 0.24683992,\n",
       "       0.25836788, 0.23612094, 0.24744666, 0.23955911, 0.24845788,\n",
       "       0.24289615, 0.24330064, 0.24158156, 0.24299727, 0.26534533,\n",
       "       0.24886237, 0.24562645, 0.238649  , 0.24380625, 0.23966023,\n",
       "       0.25048033, 0.24431186, 0.25108707, 0.2426939 , 0.24026696,\n",
       "       0.24046921, 0.24036809, 0.23025584, 0.23157043, 0.22884013,\n",
       "       0.24137931, 0.23935686, 0.22641319, 0.22712104, 0.22368288,\n",
       "       0.24451411, 0.25877237, 0.25088482, 0.25836788, 0.25108707,\n",
       "       0.25321064, 0.25371625, 0.2539185 , 0.25705329, 0.26676105,\n",
       "       0.27090707, 0.28405299, 0.30731115, 0.27940136, 0.27131156,\n",
       "       0.28971585, 0.29224391, 0.29365962, 0.29244615, 0.29861462,\n",
       "       0.28850238, 0.27950248, 0.27717666, 0.26504197, 0.28850238,\n",
       "       0.28870462, 0.2904237 , 0.30235615, 0.2976034 , 0.31145717,\n",
       "       0.31610881, 0.33673779, 0.32571544, 0.34391748, 0.35332187,\n",
       "       0.34502983, 0.33238952, 0.34523208, 0.34331075, 0.35190616,\n",
       "       0.36191728, 0.34826575, 0.34523208, 0.34887248, 0.3493781 ,\n",
       "       0.36070381, 0.35726565, 0.358378  , 0.37678228, 0.44069168,\n",
       "       0.50085954, 0.5173425 , 0.6249368 , 0.58863384, 0.59915057,\n",
       "       0.64415007, 0.63535241, 0.63636364, 0.62807159, 0.63970068,\n",
       "       0.62372333, 0.64081302, 0.6519365 , 0.65861058, 0.64779047,\n",
       "       0.65122864, 0.63879058, 0.62867833, 0.60986955, 0.61826272,\n",
       "       0.62159976, 0.63616139, 0.62615027, 0.63100415, 0.63515017,\n",
       "       0.64354333, 0.65436343, 0.64617251, 0.63777935, 0.6339367 ,\n",
       "       0.67054303, 0.66639701, 0.65325109, 0.66144201, 0.67923956,\n",
       "       0.69167762, 0.72696936, 0.73768834, 0.73910406, 0.72575589,\n",
       "       0.72343007, 0.74122763, 0.7303064 , 0.72090201, 0.68561027,\n",
       "       0.7064415 , 0.72201436, 0.69643038, 0.69875619, 0.68368895,\n",
       "       0.66386895, 0.69976742, 0.73495803, 0.74314895, 0.73293558,\n",
       "       0.72029528, 0.73172212, 0.73313783, 0.72605926, 0.72282334,\n",
       "       0.72484579, 0.6965315 , 0.71695824, 0.7073516 , 0.72575589,\n",
       "       0.71898069, 0.7113965 , 0.71523915, 0.70907068, 0.70846395,\n",
       "       0.71392456, 0.72434018, 0.72595814, 0.72555365, 0.72878956,\n",
       "       0.73212661, 0.72504803, 0.72231773, 0.71109313, 0.71281222,\n",
       "       0.70502579, 0.68500354, 0.66326221, 0.67549803, 0.65628476,\n",
       "       0.68267772, 0.66437456, 0.67388007, 0.67135201, 0.68156538,\n",
       "       0.68652038, 0.69875619, 0.72747497, 0.74325008, 0.7591263 ,\n",
       "       0.73303671, 0.73202548, 0.72100313, 0.7203964 , 0.71827283,\n",
       "       0.70391344, 0.69380119, 0.70613813, 0.70583477, 0.72393569,\n",
       "       0.70381232, 0.69673374, 0.68419456, 0.68389119, 0.67539691,\n",
       "       0.68783497, 0.68692487, 0.68813834, 0.70543028, 0.7055314 ,\n",
       "       0.70411568, 0.70229548, 0.69289109, 0.69430681, 0.68641925,\n",
       "       0.70998079, 0.72504803, 0.71513803, 0.72696936, 0.72231773,\n",
       "       0.72878956, 0.74972191, 0.73687936, 0.72201436, 0.72959854,\n",
       "       0.7235312 , 0.71503691, 0.72808171, 0.72737385, 0.73647487,\n",
       "       0.75538477, 0.77358681, 0.80705835, 0.88006876, 0.86813631,\n",
       "       0.87673172, 0.87005764, 0.86894529, 0.88239458, 0.87309131,\n",
       "       0.90150672, 0.89918091, 0.92638285, 0.92021438, 0.90595611,\n",
       "       0.92092224, 0.90848417, 0.89978764, 0.90302356, 0.91788856,\n",
       "       0.89897866, 0.91414703, 0.9243604 , 0.86823744, 0.87885529,\n",
       "       0.88957427, 0.88522601, 0.85306907, 0.8784508 , 0.89119223,\n",
       "       0.95671959, 1.        , 0.95843867, 0.93791081, 0.95894428,\n",
       "       0.95368591, 0.95671959, 0.95125897, 0.94691071, 0.90403479,\n",
       "       0.90322581, 0.90989989, 0.91768632, 0.91667509, 0.89776519,\n",
       "       0.90150672, 0.90100111, 0.91546162, 0.89948428, 0.91070887,\n",
       "       0.91080999, 0.92213571, 0.90706846, 0.91172009, 0.88664172,\n",
       "       0.89129336, 0.88482152, 0.89200121, 0.88876529, 0.88997876,\n",
       "       0.88947315, 0.91212458, 0.89028213, 0.87824856, 0.8658105 ,\n",
       "       0.88411366, 0.9104055 , 0.90939428, 0.90170897, 0.92537163,\n",
       "       0.89887754, 0.90100111, 0.88987764, 0.88391142, 0.87936091,\n",
       "       0.8775407 , 0.86469815, 0.82708059, 0.82161998, 0.83891192,\n",
       "       0.80078876, 0.77662049, 0.80463141, 0.83264233, 0.83405804,\n",
       "       0.84073213, 0.86297907, 0.85499039, 0.85256345, 0.85236121,\n",
       "       0.85984427, 0.90201234, 0.85751845, 0.8644959 , 0.8487208 ,\n",
       "       0.84012539, 0.80554151, 0.79280008, 0.77166549, 0.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3ccea47",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-ec273575d84e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mactual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessed_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predict' is not defined"
     ]
    }
   ],
   "source": [
    "pred = lstm_model,predict(dataset)\n",
    "actual = np.asarray(processed_data.label)[6:]\n",
    "\n",
    "pred = pred[:, 0]\n",
    "\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a65d4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
