{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32ad471e",
   "metadata": {},
   "source": [
    "# Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0cb1a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, Lambda, Input, GlobalAveragePooling1D\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6abf6ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Model() :\n",
    "    def __init__(self, weight, input_shape) :\n",
    "        self.checkpoint = weight\n",
    "        self.model = self.build_model(input_shape)\n",
    "        \n",
    "    def build_model(self, input_shape : tuple):\n",
    "        input = Input(shape=input_shape)\n",
    "        x = LSTM(128, return_sequences=True, activation='tanh', dropout=0.2)(input)\n",
    "        x = LSTM(64, return_sequences=True, activation='tanh', dropout=0.2)(x)\n",
    "        x = LSTM(32, return_sequences=True, activation='tanh', dropout=0.2)(x)\n",
    "        x = GlobalAveragePooling1D()(x)\n",
    "        output = Dense(1)(x)\n",
    "        return Model(input, output)\n",
    "        \n",
    "    \n",
    "    def load_model(self) :\n",
    "        self.model.load_weights(self.checkpoint)\n",
    "        return self.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fb21423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 6, 6)]            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 6, 128)            69120     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 6, 64)             49408     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 6, 32)             12416     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 130,977\n",
      "Trainable params: 130,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "window_size = 6\n",
    "n_feature = 6\n",
    "\n",
    "weight = './checkpoints/ckeckpointer.ckpt'\n",
    "input_shape = (window_size, n_feature)\n",
    "\n",
    "model = Custom_Model(weight, input_shape)\n",
    "lstm_model = model.load_model()\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae09625e",
   "metadata": {},
   "source": [
    "# Inference Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0206f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pyupbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f8111da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_preprocess() :\n",
    "    def __init__(self, ticker, interval, to, count) :\n",
    "        self.dataset = pyupbit.get_ohlcv(ticker=ticker, interval=interval, to=to, count=count)\n",
    "        self.preprocess()\n",
    "        \n",
    "    def preprocess(self) :\n",
    "        # index(시간) 제거\n",
    "        dataset_df = self.dataset.reset_index(drop=True)\n",
    "        \n",
    "        # value 제거\n",
    "        dataset_df = dataset_df.drop(columns=['value'])\n",
    "        \n",
    "        # avg_price 추가\n",
    "        dataset_df['avg_price'] = (dataset_df['high'] + dataset_df['low'] +\n",
    "                                  dataset_df['open'] + dataset_df['close']) // 4\n",
    "        \n",
    "        # min max 정규화 (MinMaxScaler) 적용\n",
    "        norm = MinMaxScaler()\n",
    "        norm_dataset = norm.fit_transform(dataset_df)\n",
    "        norm_dataset = pd.DataFrame(norm_dataset, columns=list(dataset_df.columns))\n",
    "        self.data = norm_dataset\n",
    "        \n",
    "        # 예측될 값(label)인 10분 후 가격\n",
    "        after10 = np.zeros_like(norm_dataset['close'])\n",
    "        for i in range(len(norm_dataset['close']) - 1) :\n",
    "            after10[i] = norm_dataset['close'][i + 1]\n",
    "            self.label = after10\n",
    "        \n",
    "    # dataset에 window 적용\n",
    "    def windowed_dataset(self, window_size, batch_size) :\n",
    "        sliced_data = tf.data.Dataset.from_tensor_slices(self.data)\n",
    "        sliced_data = sliced_data.window(window_size, shift=1, stride=1, drop_remainder=True)\n",
    "        sliced_data = sliced_data.flat_map(lambda x : x.batch(window_size))\n",
    "        \n",
    "        sliced_label = tf.data.Dataset.from_tensor_slices(self.label[window_size:])\n",
    "        \n",
    "        sliced_dataset = tf.data.Dataset.zip((sliced_data, sliced_label))\n",
    "        \n",
    "        return sliced_dataset.batch(batch_size).prefetch(1)\n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0b6cf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data == \n",
      "tf.Tensor(\n",
      "[[[0.22419028 0.21817058 0.23657237 0.203964   0.12238874 0.21419267]\n",
      "  [0.2041498  0.20220437 0.23677737 0.20993023 0.07456903 0.20658573]\n",
      "  [0.21012146 0.2092089  0.24446494 0.21266053 0.07799429 0.21255145]\n",
      "  [0.21295547 0.20879687 0.24395244 0.21963798 0.0829506  0.21484395]\n",
      "  [0.21973684 0.20488257 0.22539975 0.19445849 0.06683506 0.20439744]\n",
      "  [0.19463563 0.1894314  0.20110701 0.17382951 0.11533618 0.18254051]]], shape=(1, 6, 6), dtype=float64)\n",
      "\n",
      "Label == \n",
      "tf.Tensor([0.16988573], shape=(1,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "ticker = 'KRW-BTC'\n",
    "interval ='minute10'\n",
    "to = f'2021-11-10 00:10'\n",
    "count = 1000\n",
    "\n",
    "window_size = 6\n",
    "batch_size = 1\n",
    "\n",
    "processed_data =  Data_preprocess(ticker, interval, to, count)\n",
    "dataset = processed_data.windowed_dataset(window_size, batch_size)\n",
    "\n",
    "\n",
    "for data in dataset.take(1):\n",
    "    print(\"Data == \")\n",
    "    print(data[0])\n",
    "    \n",
    "    print(\"\\nLabel == \")\n",
    "    print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "746af75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(994,)\n",
      "(994,)\n"
     ]
    }
   ],
   "source": [
    "pred = lstm_model.predict(dataset)\n",
    "actual = np.asarray(processed_data.label)[6:]\n",
    "\n",
    "pred = pred[:, 0]\n",
    "\n",
    "print(pred.shape)\n",
    "print(actual.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2871fe9",
   "metadata": {},
   "source": [
    "# Data Parsing every 10 min\n",
    "# Delete First Line and add latest data at last line  \n",
    "\n",
    "### LIKE A QUEUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e57aaea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "2021-11-11 23:26\n"
     ]
    }
   ],
   "source": [
    "# 현재 시간 문자열로 가져오기\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "str_now = now.strftime('%Y-%m-%d %H:%M')\n",
    "print(type(str_now))\n",
    "print(str_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff3772d",
   "metadata": {},
   "source": [
    "# 다음 10분을 찾아야함, 59분에서 넘어가면 날짜가 바껴야함.\n",
    "# datetime은 날짜끼리 더 할 수 있음. deltatime?인가 이거 찾아서 적용해보기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a1ab39e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-11-11 23:30'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "today = datetime.datetime.now()\n",
    "current_min = today.minute\n",
    "remainder_min = current_min % 10\n",
    "if remainder_min  == 0:\n",
    "    current_min += 10\n",
    "else :\n",
    "    current_min += 10 - remainder_min \n",
    "\n",
    "if current_min == 60 :\n",
    "    current_min = '00'\n",
    "    \n",
    "now = datetime.datetime.now()\n",
    "coming_10m = now.strftime(f'%Y-%m-%d %H:{current_min}')\n",
    "coming_10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ddc2339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 59\n",
    "b = a%10\n",
    "a += 10 -b \n",
    "c = a%60\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684ce4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing_10m() :\n",
    "    date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
