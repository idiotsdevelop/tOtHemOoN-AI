{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "950c68f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4184d3d2",
   "metadata": {},
   "source": [
    "### csv 불러와서 DataFrame 에 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3049c5ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 51/51 [00:14<00:00,  3.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-25 12:00:00</td>\n",
       "      <td>4201000.0</td>\n",
       "      <td>4241000.0</td>\n",
       "      <td>4195000.0</td>\n",
       "      <td>4227000.0</td>\n",
       "      <td>15.940028</td>\n",
       "      <td>6.722878e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-09-25 12:10:00</td>\n",
       "      <td>4215000.0</td>\n",
       "      <td>4244000.0</td>\n",
       "      <td>4210000.0</td>\n",
       "      <td>4227000.0</td>\n",
       "      <td>16.224769</td>\n",
       "      <td>6.854317e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-09-25 12:20:00</td>\n",
       "      <td>4215000.0</td>\n",
       "      <td>4242000.0</td>\n",
       "      <td>4191000.0</td>\n",
       "      <td>4221000.0</td>\n",
       "      <td>16.144995</td>\n",
       "      <td>6.806705e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-25 12:30:00</td>\n",
       "      <td>4219000.0</td>\n",
       "      <td>4242000.0</td>\n",
       "      <td>4202000.0</td>\n",
       "      <td>4242000.0</td>\n",
       "      <td>17.943481</td>\n",
       "      <td>7.572972e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-09-25 12:40:00</td>\n",
       "      <td>4227000.0</td>\n",
       "      <td>4233000.0</td>\n",
       "      <td>4199000.0</td>\n",
       "      <td>4224000.0</td>\n",
       "      <td>19.122032</td>\n",
       "      <td>8.065820e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215598</th>\n",
       "      <td>2021-10-31 23:10:00</td>\n",
       "      <td>72015000.0</td>\n",
       "      <td>72201000.0</td>\n",
       "      <td>71950000.0</td>\n",
       "      <td>72195000.0</td>\n",
       "      <td>63.488926</td>\n",
       "      <td>4.572245e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215599</th>\n",
       "      <td>2021-10-31 23:20:00</td>\n",
       "      <td>72196000.0</td>\n",
       "      <td>72240000.0</td>\n",
       "      <td>72151000.0</td>\n",
       "      <td>72200000.0</td>\n",
       "      <td>56.652736</td>\n",
       "      <td>4.090660e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215600</th>\n",
       "      <td>2021-10-31 23:30:00</td>\n",
       "      <td>72220000.0</td>\n",
       "      <td>72350000.0</td>\n",
       "      <td>72077000.0</td>\n",
       "      <td>72215000.0</td>\n",
       "      <td>55.059246</td>\n",
       "      <td>3.976178e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215601</th>\n",
       "      <td>2021-10-31 23:40:00</td>\n",
       "      <td>72215000.0</td>\n",
       "      <td>72238000.0</td>\n",
       "      <td>71909000.0</td>\n",
       "      <td>72120000.0</td>\n",
       "      <td>53.188793</td>\n",
       "      <td>3.831516e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215602</th>\n",
       "      <td>2021-10-31 23:50:00</td>\n",
       "      <td>72120000.0</td>\n",
       "      <td>72124000.0</td>\n",
       "      <td>72001000.0</td>\n",
       "      <td>72092000.0</td>\n",
       "      <td>39.089480</td>\n",
       "      <td>2.816586e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215603 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Unnamed: 0        open        high         low       close  \\\n",
       "0       2017-09-25 12:00:00   4201000.0   4241000.0   4195000.0   4227000.0   \n",
       "1       2017-09-25 12:10:00   4215000.0   4244000.0   4210000.0   4227000.0   \n",
       "2       2017-09-25 12:20:00   4215000.0   4242000.0   4191000.0   4221000.0   \n",
       "3       2017-09-25 12:30:00   4219000.0   4242000.0   4202000.0   4242000.0   \n",
       "4       2017-09-25 12:40:00   4227000.0   4233000.0   4199000.0   4224000.0   \n",
       "...                     ...         ...         ...         ...         ...   \n",
       "215598  2021-10-31 23:10:00  72015000.0  72201000.0  71950000.0  72195000.0   \n",
       "215599  2021-10-31 23:20:00  72196000.0  72240000.0  72151000.0  72200000.0   \n",
       "215600  2021-10-31 23:30:00  72220000.0  72350000.0  72077000.0  72215000.0   \n",
       "215601  2021-10-31 23:40:00  72215000.0  72238000.0  71909000.0  72120000.0   \n",
       "215602  2021-10-31 23:50:00  72120000.0  72124000.0  72001000.0  72092000.0   \n",
       "\n",
       "           volume         value  \n",
       "0       15.940028  6.722878e+07  \n",
       "1       16.224769  6.854317e+07  \n",
       "2       16.144995  6.806705e+07  \n",
       "3       17.943481  7.572972e+07  \n",
       "4       19.122032  8.065820e+07  \n",
       "...           ...           ...  \n",
       "215598  63.488926  4.572245e+09  \n",
       "215599  56.652736  4.090660e+09  \n",
       "215600  55.059246  3.976178e+09  \n",
       "215601  53.188793  3.831516e+09  \n",
       "215602  39.089480  2.816586e+09  \n",
       "\n",
       "[215603 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root_path = './data'\n",
    "data_folders = glob(data_root_path + '/*')\n",
    "merge_df = pd.DataFrame()\n",
    "\n",
    "for data_folder in tqdm(data_folders) :\n",
    "    data_csvs = glob(data_folder + '/*.csv')\n",
    "    \n",
    "    for data_csv in data_csvs :\n",
    "        df = pd.read_csv(data_csv).drop(columns=[\"Unnamed: 0\"])\n",
    "        merge_df = pd.concat([merge_df, df], ignore_index=True)\n",
    "\n",
    "merge_df        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0139f5",
   "metadata": {},
   "source": [
    "### date, value 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0be9db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4670000.0</td>\n",
       "      <td>4676000.0</td>\n",
       "      <td>4659000.0</td>\n",
       "      <td>4674000.0</td>\n",
       "      <td>0.217243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4674000.0</td>\n",
       "      <td>4676000.0</td>\n",
       "      <td>4662000.0</td>\n",
       "      <td>4663000.0</td>\n",
       "      <td>0.372060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4670000.0</td>\n",
       "      <td>4670000.0</td>\n",
       "      <td>4662000.0</td>\n",
       "      <td>4669000.0</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4666000.0</td>\n",
       "      <td>4668000.0</td>\n",
       "      <td>4657000.0</td>\n",
       "      <td>4657000.0</td>\n",
       "      <td>0.025973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4656000.0</td>\n",
       "      <td>4662000.0</td>\n",
       "      <td>4651000.0</td>\n",
       "      <td>4651000.0</td>\n",
       "      <td>0.021728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215275</th>\n",
       "      <td>74604000.0</td>\n",
       "      <td>74692000.0</td>\n",
       "      <td>74374000.0</td>\n",
       "      <td>74557000.0</td>\n",
       "      <td>84.096223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215276</th>\n",
       "      <td>74550000.0</td>\n",
       "      <td>74657000.0</td>\n",
       "      <td>74495000.0</td>\n",
       "      <td>74634000.0</td>\n",
       "      <td>54.106478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215277</th>\n",
       "      <td>74634000.0</td>\n",
       "      <td>74800000.0</td>\n",
       "      <td>74555000.0</td>\n",
       "      <td>74574000.0</td>\n",
       "      <td>58.969552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215278</th>\n",
       "      <td>74578000.0</td>\n",
       "      <td>74689000.0</td>\n",
       "      <td>74540000.0</td>\n",
       "      <td>74542000.0</td>\n",
       "      <td>43.026878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215279</th>\n",
       "      <td>74542000.0</td>\n",
       "      <td>74576000.0</td>\n",
       "      <td>74482000.0</td>\n",
       "      <td>74552000.0</td>\n",
       "      <td>31.760840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215280 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              open        high         low       close     volume\n",
       "0        4670000.0   4676000.0   4659000.0   4674000.0   0.217243\n",
       "1        4674000.0   4676000.0   4662000.0   4663000.0   0.372060\n",
       "2        4670000.0   4670000.0   4662000.0   4669000.0   0.051731\n",
       "3        4666000.0   4668000.0   4657000.0   4657000.0   0.025973\n",
       "4        4656000.0   4662000.0   4651000.0   4651000.0   0.021728\n",
       "...            ...         ...         ...         ...        ...\n",
       "215275  74604000.0  74692000.0  74374000.0  74557000.0  84.096223\n",
       "215276  74550000.0  74657000.0  74495000.0  74634000.0  54.106478\n",
       "215277  74634000.0  74800000.0  74555000.0  74574000.0  58.969552\n",
       "215278  74578000.0  74689000.0  74540000.0  74542000.0  43.026878\n",
       "215279  74542000.0  74576000.0  74482000.0  74552000.0  31.760840\n",
       "\n",
       "[215280 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_columns = ['date', 'value']\n",
    "\n",
    "dropped_merge_df = merge_df.drop(columns=drop_columns)\n",
    "dropped_merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79879e65",
   "metadata": {},
   "source": [
    "###  average price 구해서 feature 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f680d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>avg_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4670000.0</td>\n",
       "      <td>4676000.0</td>\n",
       "      <td>4659000.0</td>\n",
       "      <td>4674000.0</td>\n",
       "      <td>0.217243</td>\n",
       "      <td>4669750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4674000.0</td>\n",
       "      <td>4676000.0</td>\n",
       "      <td>4662000.0</td>\n",
       "      <td>4663000.0</td>\n",
       "      <td>0.372060</td>\n",
       "      <td>4668750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4670000.0</td>\n",
       "      <td>4670000.0</td>\n",
       "      <td>4662000.0</td>\n",
       "      <td>4669000.0</td>\n",
       "      <td>0.051731</td>\n",
       "      <td>4667750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4666000.0</td>\n",
       "      <td>4668000.0</td>\n",
       "      <td>4657000.0</td>\n",
       "      <td>4657000.0</td>\n",
       "      <td>0.025973</td>\n",
       "      <td>4662000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4656000.0</td>\n",
       "      <td>4662000.0</td>\n",
       "      <td>4651000.0</td>\n",
       "      <td>4651000.0</td>\n",
       "      <td>0.021728</td>\n",
       "      <td>4655000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215275</th>\n",
       "      <td>74604000.0</td>\n",
       "      <td>74692000.0</td>\n",
       "      <td>74374000.0</td>\n",
       "      <td>74557000.0</td>\n",
       "      <td>84.096223</td>\n",
       "      <td>74556750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215276</th>\n",
       "      <td>74550000.0</td>\n",
       "      <td>74657000.0</td>\n",
       "      <td>74495000.0</td>\n",
       "      <td>74634000.0</td>\n",
       "      <td>54.106478</td>\n",
       "      <td>74584000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215277</th>\n",
       "      <td>74634000.0</td>\n",
       "      <td>74800000.0</td>\n",
       "      <td>74555000.0</td>\n",
       "      <td>74574000.0</td>\n",
       "      <td>58.969552</td>\n",
       "      <td>74640750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215278</th>\n",
       "      <td>74578000.0</td>\n",
       "      <td>74689000.0</td>\n",
       "      <td>74540000.0</td>\n",
       "      <td>74542000.0</td>\n",
       "      <td>43.026878</td>\n",
       "      <td>74587250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215279</th>\n",
       "      <td>74542000.0</td>\n",
       "      <td>74576000.0</td>\n",
       "      <td>74482000.0</td>\n",
       "      <td>74552000.0</td>\n",
       "      <td>31.760840</td>\n",
       "      <td>74538000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215280 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              open        high         low       close     volume   avg_price\n",
       "0        4670000.0   4676000.0   4659000.0   4674000.0   0.217243   4669750.0\n",
       "1        4674000.0   4676000.0   4662000.0   4663000.0   0.372060   4668750.0\n",
       "2        4670000.0   4670000.0   4662000.0   4669000.0   0.051731   4667750.0\n",
       "3        4666000.0   4668000.0   4657000.0   4657000.0   0.025973   4662000.0\n",
       "4        4656000.0   4662000.0   4651000.0   4651000.0   0.021728   4655000.0\n",
       "...            ...         ...         ...         ...        ...         ...\n",
       "215275  74604000.0  74692000.0  74374000.0  74557000.0  84.096223  74556750.0\n",
       "215276  74550000.0  74657000.0  74495000.0  74634000.0  54.106478  74584000.0\n",
       "215277  74634000.0  74800000.0  74555000.0  74574000.0  58.969552  74640750.0\n",
       "215278  74578000.0  74689000.0  74540000.0  74542000.0  43.026878  74587250.0\n",
       "215279  74542000.0  74576000.0  74482000.0  74552000.0  31.760840  74538000.0\n",
       "\n",
       "[215280 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped_merge_df['avg_price'] = (dropped_merge_df['high'] + \n",
    "                                 dropped_merge_df['low'] + \n",
    "                                dropped_merge_df['open'] + \n",
    "                                dropped_merge_df['close'] ) // 4\n",
    "dropped_merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5140fac7",
   "metadata": {},
   "source": [
    "### 10분 뒤 가격을 feature 추가\n",
    "- close 기준\n",
    "- target(label)이 될 예정\n",
    "- 마지막 1행은 after10이 없으므로 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cf180d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>after10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4670000.0</td>\n",
       "      <td>4676000.0</td>\n",
       "      <td>4659000.0</td>\n",
       "      <td>4674000.0</td>\n",
       "      <td>0.217243</td>\n",
       "      <td>4669750.0</td>\n",
       "      <td>4663000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4674000.0</td>\n",
       "      <td>4676000.0</td>\n",
       "      <td>4662000.0</td>\n",
       "      <td>4663000.0</td>\n",
       "      <td>0.372060</td>\n",
       "      <td>4668750.0</td>\n",
       "      <td>4669000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4670000.0</td>\n",
       "      <td>4670000.0</td>\n",
       "      <td>4662000.0</td>\n",
       "      <td>4669000.0</td>\n",
       "      <td>0.051731</td>\n",
       "      <td>4667750.0</td>\n",
       "      <td>4657000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4666000.0</td>\n",
       "      <td>4668000.0</td>\n",
       "      <td>4657000.0</td>\n",
       "      <td>4657000.0</td>\n",
       "      <td>0.025973</td>\n",
       "      <td>4662000.0</td>\n",
       "      <td>4651000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4656000.0</td>\n",
       "      <td>4662000.0</td>\n",
       "      <td>4651000.0</td>\n",
       "      <td>4651000.0</td>\n",
       "      <td>0.021728</td>\n",
       "      <td>4655000.0</td>\n",
       "      <td>4656000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215274</th>\n",
       "      <td>74701000.0</td>\n",
       "      <td>75120000.0</td>\n",
       "      <td>74547000.0</td>\n",
       "      <td>74604000.0</td>\n",
       "      <td>174.254459</td>\n",
       "      <td>74743000.0</td>\n",
       "      <td>74557000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215275</th>\n",
       "      <td>74604000.0</td>\n",
       "      <td>74692000.0</td>\n",
       "      <td>74374000.0</td>\n",
       "      <td>74557000.0</td>\n",
       "      <td>84.096223</td>\n",
       "      <td>74556750.0</td>\n",
       "      <td>74634000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215276</th>\n",
       "      <td>74550000.0</td>\n",
       "      <td>74657000.0</td>\n",
       "      <td>74495000.0</td>\n",
       "      <td>74634000.0</td>\n",
       "      <td>54.106478</td>\n",
       "      <td>74584000.0</td>\n",
       "      <td>74574000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215277</th>\n",
       "      <td>74634000.0</td>\n",
       "      <td>74800000.0</td>\n",
       "      <td>74555000.0</td>\n",
       "      <td>74574000.0</td>\n",
       "      <td>58.969552</td>\n",
       "      <td>74640750.0</td>\n",
       "      <td>74542000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215278</th>\n",
       "      <td>74578000.0</td>\n",
       "      <td>74689000.0</td>\n",
       "      <td>74540000.0</td>\n",
       "      <td>74542000.0</td>\n",
       "      <td>43.026878</td>\n",
       "      <td>74587250.0</td>\n",
       "      <td>74552000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215279 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              open        high         low       close      volume  \\\n",
       "0        4670000.0   4676000.0   4659000.0   4674000.0    0.217243   \n",
       "1        4674000.0   4676000.0   4662000.0   4663000.0    0.372060   \n",
       "2        4670000.0   4670000.0   4662000.0   4669000.0    0.051731   \n",
       "3        4666000.0   4668000.0   4657000.0   4657000.0    0.025973   \n",
       "4        4656000.0   4662000.0   4651000.0   4651000.0    0.021728   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "215274  74701000.0  75120000.0  74547000.0  74604000.0  174.254459   \n",
       "215275  74604000.0  74692000.0  74374000.0  74557000.0   84.096223   \n",
       "215276  74550000.0  74657000.0  74495000.0  74634000.0   54.106478   \n",
       "215277  74634000.0  74800000.0  74555000.0  74574000.0   58.969552   \n",
       "215278  74578000.0  74689000.0  74540000.0  74542000.0   43.026878   \n",
       "\n",
       "         avg_price     after10  \n",
       "0        4669750.0   4663000.0  \n",
       "1        4668750.0   4669000.0  \n",
       "2        4667750.0   4657000.0  \n",
       "3        4662000.0   4651000.0  \n",
       "4        4655000.0   4656000.0  \n",
       "...            ...         ...  \n",
       "215274  74743000.0  74557000.0  \n",
       "215275  74556750.0  74634000.0  \n",
       "215276  74584000.0  74574000.0  \n",
       "215277  74640750.0  74542000.0  \n",
       "215278  74587250.0  74552000.0  \n",
       "\n",
       "[215279 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after10 = np.zeros_like(dropped_merge_df['close'])\n",
    "for i in range(len(dropped_merge_df['close']) - 1) :\n",
    "        after10[i] = dropped_merge_df['close'][i + 1]\n",
    "        \n",
    "dropped_merge_df['after10'] = after10\n",
    "dropped_merge_df = dropped_merge_df.drop([dropped_merge_df.index[-1]])\n",
    "dropped_merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e30cda",
   "metadata": {},
   "source": [
    "### Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2fb435b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>after10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014033</td>\n",
       "      <td>0.014027</td>\n",
       "      <td>0.014034</td>\n",
       "      <td>0.014059</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.014037</td>\n",
       "      <td>0.013919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.014027</td>\n",
       "      <td>0.014072</td>\n",
       "      <td>0.013919</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.014024</td>\n",
       "      <td>0.013995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014033</td>\n",
       "      <td>0.013951</td>\n",
       "      <td>0.014072</td>\n",
       "      <td>0.013995</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.014012</td>\n",
       "      <td>0.013842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013982</td>\n",
       "      <td>0.013925</td>\n",
       "      <td>0.014008</td>\n",
       "      <td>0.013842</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.013938</td>\n",
       "      <td>0.013765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013854</td>\n",
       "      <td>0.013849</td>\n",
       "      <td>0.013932</td>\n",
       "      <td>0.013765</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.013849</td>\n",
       "      <td>0.013829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215274</th>\n",
       "      <td>0.909090</td>\n",
       "      <td>0.912342</td>\n",
       "      <td>0.908120</td>\n",
       "      <td>0.907848</td>\n",
       "      <td>0.048951</td>\n",
       "      <td>0.909874</td>\n",
       "      <td>0.907247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215275</th>\n",
       "      <td>0.907850</td>\n",
       "      <td>0.906884</td>\n",
       "      <td>0.905907</td>\n",
       "      <td>0.907247</td>\n",
       "      <td>0.023624</td>\n",
       "      <td>0.907493</td>\n",
       "      <td>0.908231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215276</th>\n",
       "      <td>0.907160</td>\n",
       "      <td>0.906437</td>\n",
       "      <td>0.907455</td>\n",
       "      <td>0.908231</td>\n",
       "      <td>0.015199</td>\n",
       "      <td>0.907841</td>\n",
       "      <td>0.907464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215277</th>\n",
       "      <td>0.908233</td>\n",
       "      <td>0.908261</td>\n",
       "      <td>0.908222</td>\n",
       "      <td>0.907464</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.908567</td>\n",
       "      <td>0.907055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215278</th>\n",
       "      <td>0.907518</td>\n",
       "      <td>0.906845</td>\n",
       "      <td>0.908030</td>\n",
       "      <td>0.907055</td>\n",
       "      <td>0.012087</td>\n",
       "      <td>0.907883</td>\n",
       "      <td>0.907183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215279 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            open      high       low     close    volume  avg_price   after10\n",
       "0       0.014033  0.014027  0.014034  0.014059  0.000061   0.014037  0.013919\n",
       "1       0.014085  0.014027  0.014072  0.013919  0.000105   0.014024  0.013995\n",
       "2       0.014033  0.013951  0.014072  0.013995  0.000015   0.014012  0.013842\n",
       "3       0.013982  0.013925  0.014008  0.013842  0.000007   0.013938  0.013765\n",
       "4       0.013854  0.013849  0.013932  0.013765  0.000006   0.013849  0.013829\n",
       "...          ...       ...       ...       ...       ...        ...       ...\n",
       "215274  0.909090  0.912342  0.908120  0.907848  0.048951   0.909874  0.907247\n",
       "215275  0.907850  0.906884  0.905907  0.907247  0.023624   0.907493  0.908231\n",
       "215276  0.907160  0.906437  0.907455  0.908231  0.015199   0.907841  0.907464\n",
       "215277  0.908233  0.908261  0.908222  0.907464  0.016565   0.908567  0.907055\n",
       "215278  0.907518  0.906845  0.908030  0.907055  0.012087   0.907883  0.907183\n",
       "\n",
       "[215279 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm = MinMaxScaler()\n",
    "norm_np = norm.fit_transform(dropped_merge_df)\n",
    "norm_df = pd.DataFrame(norm_np, columns=list(dropped_merge_df.columns))\n",
    "norm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e698bc",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdd55174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193751, 6) (193751,)\n",
      "            open      high       low     close    volume  avg_price\n",
      "0       0.014033  0.014027  0.014034  0.014059  0.000061   0.014037\n",
      "1       0.014085  0.014027  0.014072  0.013919  0.000105   0.014024\n",
      "2       0.014033  0.013951  0.014072  0.013995  0.000015   0.014012\n",
      "3       0.013982  0.013925  0.014008  0.013842  0.000007   0.013938\n",
      "4       0.013854  0.013849  0.013932  0.013765  0.000006   0.013849\n",
      "...          ...       ...       ...       ...       ...        ...\n",
      "193746  0.496447  0.495664  0.496207  0.496306  0.008322   0.496436\n",
      "193747  0.496319  0.495792  0.496322  0.496702  0.006949   0.496564\n",
      "193748  0.496715  0.495549  0.495746  0.495156  0.008271   0.496072\n",
      "193749  0.495169  0.494542  0.495657  0.495527  0.005174   0.495503\n",
      "193750  0.495578  0.495141  0.495567  0.495974  0.006810   0.495845\n",
      "\n",
      "[193751 rows x 6 columns]\n",
      "0         0.013919\n",
      "1         0.013995\n",
      "2         0.013842\n",
      "3         0.013765\n",
      "4         0.013829\n",
      "            ...   \n",
      "193746    0.496702\n",
      "193747    0.495156\n",
      "193748    0.495527\n",
      "193749    0.495974\n",
      "193750    0.495322\n",
      "Name: after10, Length: 193751, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    norm_df.drop('after10', 1), \n",
    "    norm_df['after10'], \n",
    "    test_size=0.1, \n",
    "    random_state=0, \n",
    "    shuffle=False)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6dfe2a",
   "metadata": {},
   "source": [
    "### Tensorflow Dataset 활용하여 시퀀스 데이터셋 구성\n",
    "[출처:https://teddylee777.github.io/tensorflow/lstm-stock-forecast]\n",
    "\n",
    "- window_size : 과거 몇 개의 데이터를 기준으로 다음에 오는 데이터를 예측할 것인가를 결정\n",
    "    - 만약 window_size=6 이면, 6개(1시간 치 데이터)를 기준으로 다음에 10분 후에 나오는 데이터의 after10을 예측함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a59effb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(data, label, window_size, batch_size, shuffle):\n",
    "\n",
    "    ds_x = tf.data.Dataset.from_tensor_slices(data)\n",
    "    ds_x = ds_x.window(window_size, shift=1, stride=1, drop_remainder=True)\n",
    "    ds_x = ds_x.flat_map(lambda x: x.batch(window_size))\n",
    "\n",
    "    ds_y = tf.data.Dataset.from_tensor_slices(label[window_size:])\n",
    "    ds = tf.data.Dataset.zip((ds_x, ds_y))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000)\n",
    "    return ds.batch(batch_size).prefetch(1)\n",
    "\n",
    "WINDOW_SIZE = 12\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_data = windowed_dataset(x_train, y_train, WINDOW_SIZE, BATCH_SIZE, True)\n",
    "test_data = windowed_dataset(x_test, y_test, WINDOW_SIZE, BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3909354a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋(X) 구성(batch_size, window_size, feature갯수): (128, 12, 6)\n",
      "데이터셋(Y) 구성(batch_size, window_size, feature갯수): (128,)\n",
      "tf.Tensor(\n",
      "[0.01667945 0.01749744 0.01800869 0.01685838 0.01412321 0.01791922\n",
      " 0.01565695 0.01882669 0.01716513 0.01740798 0.01871166 0.01756135\n",
      " 0.01689673 0.01841769 0.01791922 0.01742076 0.01785532 0.01506902\n",
      " 0.01505624 0.01756135 0.01376534 0.0137909  0.01520961 0.017932\n",
      " 0.01839213 0.01551636 0.01841769 0.01621933 0.01880112 0.01687117\n",
      " 0.01733129 0.01439162 0.01743354 0.01685838 0.01782975 0.01767638\n",
      " 0.0169862  0.01690951 0.01674335 0.01763804 0.01851994 0.01728016\n",
      " 0.01857106 0.01676892 0.01694785 0.01867331 0.01529908 0.01713957\n",
      " 0.01480061 0.01524796 0.01687117 0.01519683 0.0171907  0.01372699\n",
      " 0.01710123 0.01674335 0.0192229  0.0178681  0.01676892 0.0171907\n",
      " 0.01669223 0.01735685 0.01648773 0.01673057 0.01931237 0.01768916\n",
      " 0.01696063 0.01837935 0.01768916 0.01843047 0.01701176 0.01402096\n",
      " 0.01860941 0.01722904 0.01765082 0.01776585 0.01851994 0.0176636\n",
      " 0.01703732 0.01775307 0.01749744 0.01501789 0.01506902 0.01641104\n",
      " 0.01685838 0.01770194 0.01554192 0.01506902 0.01377812 0.01777863\n",
      " 0.01682004 0.01432771 0.0172546  0.01739519 0.01388037 0.01788088\n",
      " 0.0168456  0.01728016 0.01726738 0.01639826 0.01738241 0.01751022\n",
      " 0.01703732 0.01662832 0.01754857 0.01762526 0.01780419 0.01615542\n",
      " 0.01669223 0.01826431 0.0176636  0.01450665 0.01756135 0.01708845\n",
      " 0.01890337 0.01662832 0.01702454 0.01566973 0.0165772  0.0166411\n",
      " 0.01780419 0.01380368 0.01658998 0.01828988 0.01409765 0.01867331\n",
      " 0.01929959 0.01656442], shape=(128,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "for data in train_data.take(1):\n",
    "    print(f'데이터셋(X) 구성(batch_size, window_size, feature갯수): {data[0].shape}')\n",
    "#     print(data[0])\n",
    "    print(f'데이터셋(Y) 구성(batch_size, window_size, feature갯수): {data[1].shape}')\n",
    "    print(data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5720683f",
   "metadata": {},
   "source": [
    "### Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0314ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, Lambda, Input, GlobalAveragePooling1D\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63fb2ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x254b618e828>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model(input_shape):\n",
    "    input = Input(shape=input_shape)\n",
    "    x = LSTM(128, return_sequences=True, activation='tanh', dropout=0.2)(input)\n",
    "    x = LSTM(64, return_sequences=True, activation='tanh', dropout=0.2)(x)\n",
    "    x = LSTM(32, return_sequences=True, activation='tanh', dropout=0.2)(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    output = Dense(1)(x)\n",
    "    model = Model(input, output)\n",
    "    return model\n",
    "\n",
    "feature_n = 6\n",
    "model = get_model((WINDOW_SIZE, feature_n))\n",
    "model\n",
    "\n",
    "# model = Sequential([\n",
    "#     # 1차원 feature map 생성\n",
    "#     Conv1D(filters=32, kernel_size=5,\n",
    "#            padding=\"causal\",\n",
    "#            activation=\"relu\",\n",
    "#            input_shape=[WINDOW_SIZE, 1]),\n",
    "#     # LSTM\n",
    "#     LSTM(16, activation='tanh'),\n",
    "#     Dense(16, activation=\"relu\"),\n",
    "#     Dense(1),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e7bb01",
   "metadata": {},
   "source": [
    "### model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bd8adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = Huber()\n",
    "optimizer = Adam(0.0001)\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=40)\n",
    "\n",
    "filename = os.path.join('./checkpoints', 'ckeckpointer.ckpt')\n",
    "checkpoint = ModelCheckpoint(filename, \n",
    "                             save_weights_only=True, \n",
    "                             save_best_only=True, \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a03e24",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a2e477b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1514/1514 [==============================] - 38s 23ms/step - loss: 5.6238e-05 - mse: 1.1248e-04 - val_loss: 0.0023 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00229, saving model to ./checkpoints\\ckeckpointer.ckpt\n",
      "Epoch 2/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 2.3127e-04 - mse: 4.6253e-04 - val_loss: 0.0019 - val_mse: 0.0037\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00229 to 0.00187, saving model to ./checkpoints\\ckeckpointer.ckpt\n",
      "Epoch 3/150\n",
      "1514/1514 [==============================] - 30s 20ms/step - loss: 1.1211e-04 - mse: 2.2423e-04 - val_loss: 0.0017 - val_mse: 0.0033\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00187 to 0.00166, saving model to ./checkpoints\\ckeckpointer.ckpt\n",
      "Epoch 4/150\n",
      "1514/1514 [==============================] - 30s 20ms/step - loss: 9.1073e-05 - mse: 1.8215e-04 - val_loss: 0.0016 - val_mse: 0.0032\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00166 to 0.00158, saving model to ./checkpoints\\ckeckpointer.ckpt\n",
      "Epoch 5/150\n",
      "1514/1514 [==============================] - 30s 20ms/step - loss: 7.4010e-05 - mse: 1.4802e-04 - val_loss: 0.0017 - val_mse: 0.0035\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00158\n",
      "Epoch 6/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 7.4687e-05 - mse: 1.4937e-04 - val_loss: 0.0020 - val_mse: 0.0040\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00158\n",
      "Epoch 7/150\n",
      "1514/1514 [==============================] - 30s 20ms/step - loss: 6.9836e-05 - mse: 1.3967e-04 - val_loss: 0.0015 - val_mse: 0.0029\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00158 to 0.00145, saving model to ./checkpoints\\ckeckpointer.ckpt\n",
      "Epoch 8/150\n",
      "1514/1514 [==============================] - 31s 20ms/step - loss: 7.5149e-05 - mse: 1.5030e-04 - val_loss: 0.0013 - val_mse: 0.0027\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00145 to 0.00133, saving model to ./checkpoints\\ckeckpointer.ckpt\n",
      "Epoch 9/150\n",
      "1514/1514 [==============================] - 30s 20ms/step - loss: 6.8701e-05 - mse: 1.3740e-04 - val_loss: 0.0020 - val_mse: 0.0040\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00133\n",
      "Epoch 10/150\n",
      "1514/1514 [==============================] - 31s 20ms/step - loss: 6.5554e-05 - mse: 1.3111e-04 - val_loss: 0.0026 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00133\n",
      "Epoch 11/150\n",
      "1514/1514 [==============================] - 30s 19ms/step - loss: 7.1365e-05 - mse: 1.4273e-04 - val_loss: 0.0035 - val_mse: 0.0070\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00133\n",
      "Epoch 12/150\n",
      "1514/1514 [==============================] - 31s 20ms/step - loss: 7.1679e-05 - mse: 1.4336e-04 - val_loss: 0.0044 - val_mse: 0.0088\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00133\n",
      "Epoch 13/150\n",
      "1514/1514 [==============================] - 30s 20ms/step - loss: 6.7150e-05 - mse: 1.3430e-04 - val_loss: 0.0053 - val_mse: 0.0106\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00133\n",
      "Epoch 14/150\n",
      "1514/1514 [==============================] - 32s 21ms/step - loss: 6.9369e-05 - mse: 1.3874e-04 - val_loss: 0.0056 - val_mse: 0.0112\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00133\n",
      "Epoch 15/150\n",
      "1514/1514 [==============================] - 32s 21ms/step - loss: 6.7011e-05 - mse: 1.3402e-04 - val_loss: 0.0057 - val_mse: 0.0115\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00133\n",
      "Epoch 16/150\n",
      "1514/1514 [==============================] - 31s 21ms/step - loss: 6.0322e-05 - mse: 1.2064e-04 - val_loss: 0.0073 - val_mse: 0.0147\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00133\n",
      "Epoch 17/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 5.8269e-05 - mse: 1.1654e-04 - val_loss: 0.0075 - val_mse: 0.0150\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00133\n",
      "Epoch 18/150\n",
      "1514/1514 [==============================] - 31s 20ms/step - loss: 5.6061e-05 - mse: 1.1212e-04 - val_loss: 0.0067 - val_mse: 0.0133\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00133\n",
      "Epoch 19/150\n",
      "1514/1514 [==============================] - 31s 20ms/step - loss: 5.6194e-05 - mse: 1.1239e-04 - val_loss: 0.0080 - val_mse: 0.0161\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00133\n",
      "Epoch 20/150\n",
      "1514/1514 [==============================] - 31s 20ms/step - loss: 5.8885e-05 - mse: 1.1777e-04 - val_loss: 0.0097 - val_mse: 0.0194\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00133\n",
      "Epoch 21/150\n",
      "1514/1514 [==============================] - 30s 20ms/step - loss: 5.4045e-05 - mse: 1.0809e-04 - val_loss: 0.0088 - val_mse: 0.0175\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00133\n",
      "Epoch 22/150\n",
      "1514/1514 [==============================] - 31s 21ms/step - loss: 4.9633e-05 - mse: 9.9265e-05 - val_loss: 0.0076 - val_mse: 0.0151\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00133\n",
      "Epoch 23/150\n",
      "1514/1514 [==============================] - 31s 21ms/step - loss: 5.2744e-05 - mse: 1.0549e-04 - val_loss: 0.0101 - val_mse: 0.0202\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00133\n",
      "Epoch 24/150\n",
      "1514/1514 [==============================] - 31s 20ms/step - loss: 5.1093e-05 - mse: 1.0219e-04 - val_loss: 0.0101 - val_mse: 0.0202\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00133\n",
      "Epoch 25/150\n",
      "1514/1514 [==============================] - 31s 20ms/step - loss: 4.7752e-05 - mse: 9.5503e-05 - val_loss: 0.0095 - val_mse: 0.0191\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00133\n",
      "Epoch 26/150\n",
      "1514/1514 [==============================] - 31s 20ms/step - loss: 4.5763e-05 - mse: 9.1525e-05 - val_loss: 0.0079 - val_mse: 0.0158\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00133\n",
      "Epoch 27/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 4.7328e-05 - mse: 9.4656e-05 - val_loss: 0.0103 - val_mse: 0.0206\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00133\n",
      "Epoch 28/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 5.2629e-05 - mse: 1.0526e-04 - val_loss: 0.0098 - val_mse: 0.0196\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00133\n",
      "Epoch 29/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 4.8062e-05 - mse: 9.6123e-05 - val_loss: 0.0097 - val_mse: 0.0194\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00133\n",
      "Epoch 30/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 4.7940e-05 - mse: 9.5880e-05 - val_loss: 0.0088 - val_mse: 0.0177\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00133\n",
      "Epoch 31/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 4.6660e-05 - mse: 9.3320e-05 - val_loss: 0.0088 - val_mse: 0.0175\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00133\n",
      "Epoch 32/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 4.9052e-05 - mse: 9.8104e-05 - val_loss: 0.0098 - val_mse: 0.0197\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00133\n",
      "Epoch 33/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 4.7352e-05 - mse: 9.4703e-05 - val_loss: 0.0096 - val_mse: 0.0192\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00133\n",
      "Epoch 34/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 4.4428e-05 - mse: 8.8855e-05 - val_loss: 0.0104 - val_mse: 0.0208\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00133\n",
      "Epoch 35/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 4.3799e-05 - mse: 8.7598e-05 - val_loss: 0.0097 - val_mse: 0.0193\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00133\n",
      "Epoch 36/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 4.2258e-05 - mse: 8.4517e-05 - val_loss: 0.0090 - val_mse: 0.0179\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00133\n",
      "Epoch 37/150\n",
      "1514/1514 [==============================] - 30s 20ms/step - loss: 4.0843e-05 - mse: 8.1686e-05 - val_loss: 0.0098 - val_mse: 0.0195\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00133\n",
      "Epoch 38/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 4.0108e-05 - mse: 8.0216e-05 - val_loss: 0.0101 - val_mse: 0.0202\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00133\n",
      "Epoch 39/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 3.9690e-05 - mse: 7.9379e-05 - val_loss: 0.0095 - val_mse: 0.0189\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00133\n",
      "Epoch 40/150\n",
      "1514/1514 [==============================] - 30s 20ms/step - loss: 4.0399e-05 - mse: 8.0798e-05 - val_loss: 0.0096 - val_mse: 0.0192\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00133\n",
      "Epoch 41/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1514/1514 [==============================] - 29s 19ms/step - loss: 3.6647e-05 - mse: 7.3294e-05 - val_loss: 0.0106 - val_mse: 0.0212\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00133\n",
      "Epoch 42/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 3.5331e-05 - mse: 7.0661e-05 - val_loss: 0.0099 - val_mse: 0.0198\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00133\n",
      "Epoch 43/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 3.5344e-05 - mse: 7.0687e-05 - val_loss: 0.0093 - val_mse: 0.0186\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00133\n",
      "Epoch 44/150\n",
      "1514/1514 [==============================] - 28s 19ms/step - loss: 3.3715e-05 - mse: 6.7430e-05 - val_loss: 0.0097 - val_mse: 0.0194\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00133\n",
      "Epoch 45/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 3.3760e-05 - mse: 6.7519e-05 - val_loss: 0.0087 - val_mse: 0.0173\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00133\n",
      "Epoch 46/150\n",
      "1514/1514 [==============================] - 30s 20ms/step - loss: 3.0890e-05 - mse: 6.1780e-05 - val_loss: 0.0087 - val_mse: 0.0174\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00133\n",
      "Epoch 47/150\n",
      "1514/1514 [==============================] - 30s 20ms/step - loss: 2.9809e-05 - mse: 5.9619e-05 - val_loss: 0.0093 - val_mse: 0.0186\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00133\n",
      "Epoch 48/150\n",
      "1514/1514 [==============================] - 30s 20ms/step - loss: 2.9609e-05 - mse: 5.9217e-05 - val_loss: 0.0095 - val_mse: 0.0189\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00133\n",
      "Epoch 49/150\n",
      "1514/1514 [==============================] - 30s 19ms/step - loss: 2.9572e-05 - mse: 5.9144e-05 - val_loss: 0.0086 - val_mse: 0.0172\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00133\n",
      "Epoch 50/150\n",
      "1514/1514 [==============================] - 31s 21ms/step - loss: 2.7075e-05 - mse: 5.4149e-05 - val_loss: 0.0094 - val_mse: 0.0187\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00133\n",
      "Epoch 51/150\n",
      "1514/1514 [==============================] - 32s 21ms/step - loss: 2.5816e-05 - mse: 5.1631e-05 - val_loss: 0.0091 - val_mse: 0.0182\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00133\n",
      "Epoch 52/150\n",
      "1514/1514 [==============================] - 33s 22ms/step - loss: 2.4942e-05 - mse: 4.9884e-05 - val_loss: 0.0097 - val_mse: 0.0195\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00133\n",
      "Epoch 53/150\n",
      "1514/1514 [==============================] - 33s 21ms/step - loss: 2.4362e-05 - mse: 4.8725e-05 - val_loss: 0.0091 - val_mse: 0.0182\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00133\n",
      "Epoch 54/150\n",
      "1514/1514 [==============================] - 30s 20ms/step - loss: 2.2718e-05 - mse: 4.5436e-05 - val_loss: 0.0091 - val_mse: 0.0183\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00133\n",
      "Epoch 55/150\n",
      "1514/1514 [==============================] - 32s 21ms/step - loss: 2.3314e-05 - mse: 4.6628e-05 - val_loss: 0.0094 - val_mse: 0.0187\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00133\n",
      "Epoch 56/150\n",
      "1514/1514 [==============================] - 31s 21ms/step - loss: 2.1336e-05 - mse: 4.2673e-05 - val_loss: 0.0092 - val_mse: 0.0183\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00133\n",
      "Epoch 57/150\n",
      "1514/1514 [==============================] - 30s 20ms/step - loss: 2.2104e-05 - mse: 4.4207e-05 - val_loss: 0.0086 - val_mse: 0.0172\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00133\n",
      "Epoch 58/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 2.0420e-05 - mse: 4.0841e-05 - val_loss: 0.0088 - val_mse: 0.0175\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00133\n",
      "Epoch 59/150\n",
      "1514/1514 [==============================] - 31s 20ms/step - loss: 2.0694e-05 - mse: 4.1389e-05 - val_loss: 0.0093 - val_mse: 0.0187\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00133\n",
      "Epoch 60/150\n",
      "1514/1514 [==============================] - 31s 20ms/step - loss: 2.1149e-05 - mse: 4.2297e-05 - val_loss: 0.0090 - val_mse: 0.0179\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00133\n",
      "Epoch 61/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.9659e-05 - mse: 3.9317e-05 - val_loss: 0.0088 - val_mse: 0.0177\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00133\n",
      "Epoch 62/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.9182e-05 - mse: 3.8365e-05 - val_loss: 0.0093 - val_mse: 0.0185\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00133\n",
      "Epoch 63/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.7704e-05 - mse: 3.5407e-05 - val_loss: 0.0093 - val_mse: 0.0186\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00133\n",
      "Epoch 64/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.7974e-05 - mse: 3.5948e-05 - val_loss: 0.0092 - val_mse: 0.0183\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00133\n",
      "Epoch 65/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.8465e-05 - mse: 3.6931e-05 - val_loss: 0.0087 - val_mse: 0.0175\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00133\n",
      "Epoch 66/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.6238e-05 - mse: 3.2476e-05 - val_loss: 0.0096 - val_mse: 0.0191\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00133\n",
      "Epoch 67/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.7192e-05 - mse: 3.4384e-05 - val_loss: 0.0093 - val_mse: 0.0187\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00133\n",
      "Epoch 68/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.6014e-05 - mse: 3.2029e-05 - val_loss: 0.0091 - val_mse: 0.0181\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00133\n",
      "Epoch 69/150\n",
      "1514/1514 [==============================] - 28s 19ms/step - loss: 1.5767e-05 - mse: 3.1535e-05 - val_loss: 0.0081 - val_mse: 0.0162\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00133\n",
      "Epoch 70/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.5516e-05 - mse: 3.1033e-05 - val_loss: 0.0089 - val_mse: 0.0178\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00133\n",
      "Epoch 71/150\n",
      "1514/1514 [==============================] - 28s 19ms/step - loss: 1.5413e-05 - mse: 3.0827e-05 - val_loss: 0.0089 - val_mse: 0.0178\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00133\n",
      "Epoch 72/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.4253e-05 - mse: 2.8506e-05 - val_loss: 0.0085 - val_mse: 0.0171\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00133\n",
      "Epoch 73/150\n",
      "1514/1514 [==============================] - 28s 19ms/step - loss: 1.3726e-05 - mse: 2.7452e-05 - val_loss: 0.0081 - val_mse: 0.0162\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00133\n",
      "Epoch 74/150\n",
      "1514/1514 [==============================] - 28s 19ms/step - loss: 1.4292e-05 - mse: 2.8584e-05 - val_loss: 0.0084 - val_mse: 0.0168\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00133\n",
      "Epoch 75/150\n",
      "1514/1514 [==============================] - 28s 19ms/step - loss: 1.4700e-05 - mse: 2.9400e-05 - val_loss: 0.0086 - val_mse: 0.0172\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00133\n",
      "Epoch 76/150\n",
      "1514/1514 [==============================] - 28s 19ms/step - loss: 1.2603e-05 - mse: 2.5205e-05 - val_loss: 0.0086 - val_mse: 0.0172\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00133\n",
      "Epoch 77/150\n",
      "1514/1514 [==============================] - 28s 19ms/step - loss: 1.3944e-05 - mse: 2.7887e-05 - val_loss: 0.0084 - val_mse: 0.0167\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00133\n",
      "Epoch 78/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.3271e-05 - mse: 2.6542e-05 - val_loss: 0.0088 - val_mse: 0.0175\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00133\n",
      "Epoch 79/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.3032e-05 - mse: 2.6065e-05 - val_loss: 0.0084 - val_mse: 0.0168\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00133\n",
      "Epoch 80/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.2915e-05 - mse: 2.5830e-05 - val_loss: 0.0087 - val_mse: 0.0173\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00133\n",
      "Epoch 81/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.3096e-05 - mse: 2.6192e-05 - val_loss: 0.0087 - val_mse: 0.0174\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00133\n",
      "Epoch 82/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.2453e-05 - mse: 2.4905e-05 - val_loss: 0.0088 - val_mse: 0.0175\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00133\n",
      "Epoch 83/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.1912e-05 - mse: 2.3825e-05 - val_loss: 0.0085 - val_mse: 0.0171\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00133\n",
      "Epoch 84/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.2040e-05 - mse: 2.4081e-05 - val_loss: 0.0087 - val_mse: 0.0175\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00133\n",
      "Epoch 85/150\n",
      "1514/1514 [==============================] - 28s 19ms/step - loss: 1.2441e-05 - mse: 2.4881e-05 - val_loss: 0.0077 - val_mse: 0.0154\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00133\n",
      "Epoch 86/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.2373e-05 - mse: 2.4746e-05 - val_loss: 0.0094 - val_mse: 0.0187\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.00133\n",
      "Epoch 87/150\n",
      "1514/1514 [==============================] - 28s 19ms/step - loss: 1.3262e-05 - mse: 2.6523e-05 - val_loss: 0.0080 - val_mse: 0.0160\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.00133\n",
      "Epoch 88/150\n",
      "1514/1514 [==============================] - 28s 19ms/step - loss: 1.0549e-05 - mse: 2.1098e-05 - val_loss: 0.0089 - val_mse: 0.0178\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.00133\n",
      "Epoch 89/150\n",
      "1514/1514 [==============================] - 28s 19ms/step - loss: 1.2872e-05 - mse: 2.5743e-05 - val_loss: 0.0093 - val_mse: 0.0187\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.00133\n",
      "Epoch 90/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.0241e-05 - mse: 2.0483e-05 - val_loss: 0.0086 - val_mse: 0.0173\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.00133\n",
      "Epoch 91/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.0904e-05 - mse: 2.1807e-05 - val_loss: 0.0092 - val_mse: 0.0183\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.00133\n",
      "Epoch 92/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.1575e-05 - mse: 2.3149e-05 - val_loss: 0.0091 - val_mse: 0.0181\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.00133\n",
      "Epoch 93/150\n",
      "1514/1514 [==============================] - 28s 19ms/step - loss: 1.0308e-05 - mse: 2.0617e-05 - val_loss: 0.0092 - val_mse: 0.0184\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.00133\n",
      "Epoch 94/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.1044e-05 - mse: 2.2087e-05 - val_loss: 0.0092 - val_mse: 0.0184\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.00133\n",
      "Epoch 95/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.0428e-05 - mse: 2.0856e-05 - val_loss: 0.0093 - val_mse: 0.0186\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.00133\n",
      "Epoch 96/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.0352e-05 - mse: 2.0703e-05 - val_loss: 0.0091 - val_mse: 0.0182\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.00133\n",
      "Epoch 97/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.0333e-05 - mse: 2.0667e-05 - val_loss: 0.0088 - val_mse: 0.0176\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.00133\n",
      "Epoch 98/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 9.6958e-06 - mse: 1.9392e-05 - val_loss: 0.0090 - val_mse: 0.0180\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.00133\n",
      "Epoch 99/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.1200e-05 - mse: 2.2399e-05 - val_loss: 0.0088 - val_mse: 0.0176\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.00133\n",
      "Epoch 100/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 9.4313e-06 - mse: 1.8863e-05 - val_loss: 0.0094 - val_mse: 0.0187\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.00133\n",
      "Epoch 101/150\n",
      "1514/1514 [==============================] - 28s 19ms/step - loss: 9.5668e-06 - mse: 1.9134e-05 - val_loss: 0.0093 - val_mse: 0.0185\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.00133\n",
      "Epoch 102/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 9.3409e-06 - mse: 1.8682e-05 - val_loss: 0.0086 - val_mse: 0.0173\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.00133\n",
      "Epoch 103/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 9.9192e-06 - mse: 1.9838e-05 - val_loss: 0.0089 - val_mse: 0.0178\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.00133\n",
      "Epoch 104/150\n",
      "1514/1514 [==============================] - 30s 20ms/step - loss: 1.0494e-05 - mse: 2.0989e-05 - val_loss: 0.0087 - val_mse: 0.0175\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.00133\n",
      "Epoch 105/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.0114e-05 - mse: 2.0227e-05 - val_loss: 0.0082 - val_mse: 0.0163\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.00133\n",
      "Epoch 106/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 9.1177e-06 - mse: 1.8235e-05 - val_loss: 0.0083 - val_mse: 0.0166\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.00133\n",
      "Epoch 107/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 9.5154e-06 - mse: 1.9031e-05 - val_loss: 0.0086 - val_mse: 0.0172\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.00133\n",
      "Epoch 108/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 1.0315e-05 - mse: 2.0630e-05 - val_loss: 0.0089 - val_mse: 0.0179\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.00133\n",
      "Epoch 109/150\n",
      "1514/1514 [==============================] - 28s 19ms/step - loss: 9.4041e-06 - mse: 1.8808e-05 - val_loss: 0.0089 - val_mse: 0.0179\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.00133\n",
      "Epoch 110/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 9.7194e-06 - mse: 1.9439e-05 - val_loss: 0.0088 - val_mse: 0.0175\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.00133\n",
      "Epoch 111/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 8.4821e-06 - mse: 1.6964e-05 - val_loss: 0.0092 - val_mse: 0.0184\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.00133\n",
      "Epoch 112/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 8.9872e-06 - mse: 1.7974e-05 - val_loss: 0.0088 - val_mse: 0.0175\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.00133\n",
      "Epoch 113/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 9.0084e-06 - mse: 1.8017e-05 - val_loss: 0.0091 - val_mse: 0.0181\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.00133\n",
      "Epoch 114/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 9.4361e-06 - mse: 1.8872e-05 - val_loss: 0.0090 - val_mse: 0.0180\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.00133\n",
      "Epoch 115/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 8.7150e-06 - mse: 1.7430e-05 - val_loss: 0.0089 - val_mse: 0.0179\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.00133\n",
      "Epoch 116/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 9.2026e-06 - mse: 1.8405e-05 - val_loss: 0.0091 - val_mse: 0.0183\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.00133\n",
      "Epoch 117/150\n",
      "1514/1514 [==============================] - 28s 19ms/step - loss: 8.7773e-06 - mse: 1.7555e-05 - val_loss: 0.0091 - val_mse: 0.0182\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.00133\n",
      "Epoch 118/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 8.4695e-06 - mse: 1.6939e-05 - val_loss: 0.0087 - val_mse: 0.0175\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.00133\n",
      "Epoch 119/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 8.7298e-06 - mse: 1.7460e-05 - val_loss: 0.0091 - val_mse: 0.0183\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.00133\n",
      "Epoch 120/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 8.8042e-06 - mse: 1.7608e-05 - val_loss: 0.0091 - val_mse: 0.0183\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.00133\n",
      "Epoch 121/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 9.0758e-06 - mse: 1.8152e-05 - val_loss: 0.0091 - val_mse: 0.0181\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.00133\n",
      "Epoch 122/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 8.0647e-06 - mse: 1.6129e-05 - val_loss: 0.0091 - val_mse: 0.0181\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.00133\n",
      "Epoch 123/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1514/1514 [==============================] - 29s 19ms/step - loss: 8.1175e-06 - mse: 1.6235e-05 - val_loss: 0.0085 - val_mse: 0.0171\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.00133\n",
      "Epoch 124/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 8.6783e-06 - mse: 1.7357e-05 - val_loss: 0.0093 - val_mse: 0.0187\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.00133\n",
      "Epoch 125/150\n",
      "1514/1514 [==============================] - 28s 19ms/step - loss: 8.5850e-06 - mse: 1.7170e-05 - val_loss: 0.0093 - val_mse: 0.0187\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.00133\n",
      "Epoch 126/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 8.2694e-06 - mse: 1.6539e-05 - val_loss: 0.0087 - val_mse: 0.0174\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.00133\n",
      "Epoch 127/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 8.0845e-06 - mse: 1.6169e-05 - val_loss: 0.0086 - val_mse: 0.0171\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.00133\n",
      "Epoch 128/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 8.7391e-06 - mse: 1.7478e-05 - val_loss: 0.0087 - val_mse: 0.0175\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.00133\n",
      "Epoch 129/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 8.5888e-06 - mse: 1.7178e-05 - val_loss: 0.0087 - val_mse: 0.0175\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.00133\n",
      "Epoch 130/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 8.1799e-06 - mse: 1.6360e-05 - val_loss: 0.0090 - val_mse: 0.0181\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.00133\n",
      "Epoch 131/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 8.6442e-06 - mse: 1.7288e-05 - val_loss: 0.0084 - val_mse: 0.0168\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.00133\n",
      "Epoch 132/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 7.9122e-06 - mse: 1.5824e-05 - val_loss: 0.0090 - val_mse: 0.0181\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.00133\n",
      "Epoch 133/150\n",
      "1514/1514 [==============================] - 28s 19ms/step - loss: 8.5420e-06 - mse: 1.7084e-05 - val_loss: 0.0089 - val_mse: 0.0177\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.00133\n",
      "Epoch 134/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 7.8509e-06 - mse: 1.5702e-05 - val_loss: 0.0088 - val_mse: 0.0176\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.00133\n",
      "Epoch 135/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 8.2973e-06 - mse: 1.6595e-05 - val_loss: 0.0085 - val_mse: 0.0170\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.00133\n",
      "Epoch 136/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 8.1263e-06 - mse: 1.6253e-05 - val_loss: 0.0086 - val_mse: 0.0172\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.00133\n",
      "Epoch 137/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 7.7841e-06 - mse: 1.5568e-05 - val_loss: 0.0091 - val_mse: 0.0182\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.00133\n",
      "Epoch 138/150\n",
      "1514/1514 [==============================] - 30s 20ms/step - loss: 7.7987e-06 - mse: 1.5597e-05 - val_loss: 0.0086 - val_mse: 0.0172\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.00133\n",
      "Epoch 139/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 7.5268e-06 - mse: 1.5054e-05 - val_loss: 0.0086 - val_mse: 0.0172\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.00133\n",
      "Epoch 140/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 7.7531e-06 - mse: 1.5506e-05 - val_loss: 0.0087 - val_mse: 0.0174\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.00133\n",
      "Epoch 141/150\n",
      "1514/1514 [==============================] - 28s 19ms/step - loss: 7.9402e-06 - mse: 1.5880e-05 - val_loss: 0.0089 - val_mse: 0.0178\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.00133\n",
      "Epoch 142/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 7.8817e-06 - mse: 1.5763e-05 - val_loss: 0.0094 - val_mse: 0.0188\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.00133\n",
      "Epoch 143/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 8.4100e-06 - mse: 1.6820e-05 - val_loss: 0.0093 - val_mse: 0.0186\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.00133\n",
      "Epoch 144/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 7.7097e-06 - mse: 1.5419e-05 - val_loss: 0.0092 - val_mse: 0.0183\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.00133\n",
      "Epoch 145/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 7.6951e-06 - mse: 1.5390e-05 - val_loss: 0.0088 - val_mse: 0.0175\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.00133\n",
      "Epoch 146/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 7.9771e-06 - mse: 1.5954e-05 - val_loss: 0.0087 - val_mse: 0.0175\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.00133\n",
      "Epoch 147/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 8.6033e-06 - mse: 1.7207e-05 - val_loss: 0.0085 - val_mse: 0.0171\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.00133\n",
      "Epoch 148/150\n",
      "1514/1514 [==============================] - 29s 19ms/step - loss: 7.5417e-06 - mse: 1.5083e-05 - val_loss: 0.0086 - val_mse: 0.0172\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.00133\n",
      "Epoch 149/150\n",
      "1514/1514 [==============================] - 28s 19ms/step - loss: 7.5442e-06 - mse: 1.5088e-05 - val_loss: 0.0089 - val_mse: 0.0178\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.00133\n",
      "Epoch 150/150\n",
      "1514/1514 [==============================] - 28s 19ms/step - loss: 7.6414e-06 - mse: 1.5283e-05 - val_loss: 0.0091 - val_mse: 0.0182\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.00133\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, \n",
    "                    validation_data=(test_data), \n",
    "                    epochs=150, \n",
    "                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73f8544d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x254b2832780>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcc485c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21516, 1)\n",
      "(21516, 1)\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(filename)\n",
    "pred = model.predict(test_data)\n",
    "actual = np.asarray(y_test)[WINDOW_SIZE:]\n",
    "actual = np.reshape(actual, (len(actual), 1))\n",
    "print(pred.shape)\n",
    "print(actual.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30231525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(actual, label='actual')\n",
    "plt.plot(pred, label='prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a35ee9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
