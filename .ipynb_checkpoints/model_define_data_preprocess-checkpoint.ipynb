{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32ad471e",
   "metadata": {},
   "source": [
    "# Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0cb1a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, Lambda, Input, GlobalAveragePooling1D\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6abf6ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Model() :\n",
    "    def __init__(self, weight, input_shape) :\n",
    "        self.checkpoint = weight\n",
    "        self.model = self.build_model(input_shape)\n",
    "        \n",
    "    def build_model(self, input_shape : tuple):\n",
    "        input = Input(shape=input_shape)\n",
    "        x = LSTM(128, return_sequences=True, activation='tanh', dropout=0.2)(input)\n",
    "        x = LSTM(64, return_sequences=True, activation='tanh', dropout=0.2)(x)\n",
    "        x = LSTM(32, return_sequences=True, activation='tanh', dropout=0.2)(x)\n",
    "        x = GlobalAveragePooling1D()(x)\n",
    "        output = Dense(1)(x)\n",
    "        return Model(input, output)\n",
    "        \n",
    "    \n",
    "    def load_model(self) :\n",
    "        self.model.load_weights(self.checkpoint)\n",
    "        return self.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3fb21423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 6, 6)]            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 6, 128)            69120     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 6, 64)             49408     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 6, 32)             12416     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 130,977\n",
      "Trainable params: 130,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "window_size = 6\n",
    "n_feature = 6\n",
    "\n",
    "weight = './checkpoints/ckeckpointer.ckpt'\n",
    "input_shape = (window_size, n_feature)\n",
    "\n",
    "model = Custom_Model(weight, input_shape)\n",
    "lstm_model = model.load_model()\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae09625e",
   "metadata": {},
   "source": [
    "# Inference Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0206f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pyupbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f8111da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_preprocess() :\n",
    "    def __init__(self, ticker, interval, to, count) :\n",
    "        self.data, self.label, self.dataset = self.preprocess(pyupbit.get_ohlcv(ticker=ticker, interval=interval, to=to, count=count))\n",
    "    \n",
    "    def MinMax(self, dataset_df) :\n",
    "        norm = MinMaxScaler()\n",
    "        norm_dataset = norm.fit_transform(dataset_df)\n",
    "        return pd.DataFrame(norm_dataset, columns=list(dataset_df.columns))\n",
    "    \n",
    "    \n",
    "    def add_after10(self, dataset_df) :\n",
    "        after10 = np.zeros_like(self.norm_dataset['close'])\n",
    "        for i in range(len(dataset_df['close']) - 1) :\n",
    "            after10[i] = dataset_df['close'][i + 1]\n",
    "        return after10\n",
    "    \n",
    "    \n",
    "    def drop_feature(self, dataset_df) :\n",
    "        # index(시간) 제거\n",
    "        dataset_df = dataset_df.reset_index(drop=True)\n",
    "        # value 제거\n",
    "        dataset_df = dataset_df.drop(columns=['value'])\n",
    "        return dataset_df\n",
    "    \n",
    "    \n",
    "    def add_avgPrice(self, dataset_df) :\n",
    "        return (dataset_df['high'] + dataset_df['low'] + \n",
    "                dataset_df['open'] + dataset_df['close']) // 4\n",
    "       \n",
    "    \n",
    "    def preprocess(self, dataset) :\n",
    "        \n",
    "        # drop feature\n",
    "        dataset_df = self.drop_feature(dataset)\n",
    "        \n",
    "        # avg_price 추가\n",
    "        dataset_df['avg_price'] = self.add_avgPrice(dataset_df)\n",
    "        \n",
    "        # min max 정규화 (MinMaxScaler) 적용\n",
    "        self.norm_dataset = self.MinMax(dataset_df)\n",
    "        \n",
    "        # 예측될 값(label)인 10분 후 가격\n",
    "        self.norm_dataset['after10'] = self.add_after10(self.norm_dataset)\n",
    "        dataset_df['after10'] = self.add_after10(dataset_df)\n",
    "        \n",
    "        return self.norm_dataset.drop(columns=['after10']), self.norm_dataset['after10'], dataset_df\n",
    "        \n",
    "        \n",
    "    def add_latest_data(self, latest_data) :\n",
    "        # 가장 예전 데이터 삭제 - norm이랑 original 둘 다 적용\n",
    "        self.dataset = self.dataset.drop([self.dataset.index[0]])\n",
    "        self.norm_dataset = self.norm_dataset.drop([self.norm_dataset.index[0]])\n",
    "\n",
    "        latest_data = self.drop_feature(latest_data)\n",
    "        latest_data['avg_price'] = self.add_avgPrice(latest_data)\n",
    "        \n",
    "        # latest data가 들어오면 original dataframe에도 추가하고\n",
    "        # norm_dataset에도 추가해줘야힘.\n",
    "        # 여기서 그 과정을 만들어줘야함.\n",
    "        norm_latest_data = self.MinMax(latest_data)\n",
    "        \n",
    "        latest_data['after10'] = self.add_after10(latest_data)\n",
    "        self.dataset = pd.concat([self.dataset, latest_data])\n",
    "        \n",
    "            \n",
    "    \n",
    "        \n",
    "    # dataset에 window 적용\n",
    "    def windowed_dataset(self, window_size, batch_size) :\n",
    "        sliced_data = tf.data.Dataset.from_tensor_slices(self.data)\n",
    "        sliced_data = sliced_data.window(window_size, shift=1, stride=1, drop_remainder=True)\n",
    "        sliced_data = sliced_data.flat_map(lambda x : x.batch(window_size))\n",
    "        \n",
    "        sliced_label = tf.data.Dataset.from_tensor_slices(self.label[window_size:])\n",
    "        \n",
    "        sliced_dataset = tf.data.Dataset.zip((sliced_data, sliced_label))\n",
    "        \n",
    "        return sliced_dataset.batch(batch_size).prefetch(1)\n",
    "    \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0b6cf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data == \n",
      "tf.Tensor(\n",
      "[[[0.22419028 0.21817058 0.23657237 0.203964   0.12238874 0.21419267]\n",
      "  [0.2041498  0.20220437 0.23677737 0.20993023 0.07456903 0.20658573]\n",
      "  [0.21012146 0.2092089  0.24446494 0.21266053 0.07799429 0.21255145]\n",
      "  [0.21295547 0.20879687 0.24395244 0.21963798 0.0829506  0.21484395]\n",
      "  [0.21973684 0.20488257 0.22539975 0.19445849 0.06683506 0.20439744]\n",
      "  [0.19463563 0.1894314  0.20110701 0.17382951 0.11533618 0.18254051]]], shape=(1, 6, 6), dtype=float64)\n",
      "\n",
      "Label == \n",
      "tf.Tensor([0.16988573], shape=(1,), dtype=float64)\n",
      "           open        high         low       close      volume   avg_price  \\\n",
      "0    75025000.0  75110000.0  74808000.0  74827000.0   42.323616  74942500.0   \n",
      "1    74827000.0  74955000.0  74810000.0  74886000.0   26.774901  74869500.0   \n",
      "2    74886000.0  75023000.0  74885000.0  74913000.0   27.888634  74926750.0   \n",
      "3    74914000.0  75019000.0  74880000.0  74982000.0   29.500190  74948750.0   \n",
      "4    74981000.0  74981000.0  74699000.0  74733000.0   24.260177  74848500.0   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "995  81359000.0  81359000.0  81166000.0  81203000.0   54.985089  81271750.0   \n",
      "996  81203000.0  81265000.0  81080000.0  81118000.0   46.954699  81166500.0   \n",
      "997  81118000.0  81385000.0  80756000.0  80776000.0   60.260760  81008750.0   \n",
      "998  80776000.0  80999000.0  80550000.0  80650000.0   99.310089  80743750.0   \n",
      "999  80650000.0  80688000.0  80277000.0  80441000.0  167.911427  80514000.0   \n",
      "\n",
      "        after10  \n",
      "0    74886000.0  \n",
      "1    74913000.0  \n",
      "2    74982000.0  \n",
      "3    74733000.0  \n",
      "4    74529000.0  \n",
      "..          ...  \n",
      "995  81118000.0  \n",
      "996  80776000.0  \n",
      "997  80650000.0  \n",
      "998  80441000.0  \n",
      "999         0.0  \n",
      "\n",
      "[1000 rows x 7 columns]\n",
      "         open      high       low     close    volume  avg_price   after10\n",
      "0    0.224190  0.218171  0.236572  0.203964  0.122389   0.214193  0.209930\n",
      "1    0.204150  0.202204  0.236777  0.209930  0.074569   0.206586  0.212661\n",
      "2    0.210121  0.209209  0.244465  0.212661  0.077994   0.212551  0.219638\n",
      "3    0.212955  0.208797  0.243952  0.219638  0.082951   0.214844  0.194458\n",
      "4    0.219737  0.204883  0.225400  0.194458  0.066835   0.204397  0.173830\n",
      "..        ...       ...       ...       ...       ...        ...       ...\n",
      "995  0.865283  0.861867  0.888274  0.848721  0.161329   0.873730  0.840125\n",
      "996  0.849494  0.852184  0.879459  0.840125  0.136632   0.862762  0.805542\n",
      "997  0.840891  0.864545  0.846248  0.805542  0.177554   0.846324  0.792800\n",
      "998  0.806275  0.824784  0.825133  0.792800  0.297649   0.818710  0.771665\n",
      "999  0.793522  0.792748  0.797150  0.771665  0.508631   0.794769  0.000000\n",
      "\n",
      "[1000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "ticker = 'KRW-BTC'\n",
    "interval ='minute10'\n",
    "to = f'2021-11-10 00:10'\n",
    "count = 1000\n",
    "\n",
    "window_size = 6\n",
    "batch_size = 1\n",
    "\n",
    "processed_data =  Data_preprocess(ticker, interval, to, count)\n",
    "dataset = processed_data.windowed_dataset(window_size, batch_size)\n",
    "\n",
    "\n",
    "for data in dataset.take(1):\n",
    "    print(\"Data ==> \")\n",
    "    print(data[0])\n",
    "    \n",
    "    print(\"\\nLabel ==> \")\n",
    "    print(data[1])\n",
    "    \n",
    "print(processed_data.dataset)\n",
    "print(processed_data.norm_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "746af75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(994,)\n",
      "(994,)\n"
     ]
    }
   ],
   "source": [
    "pred = lstm_model.predict(dataset)\n",
    "actual = np.asarray(processed_data.label)[6:]\n",
    "\n",
    "pred = pred[:, 0]\n",
    "\n",
    "print(pred.shape)\n",
    "print(actual.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2871fe9",
   "metadata": {},
   "source": [
    "# Data Parsing every 10 min\n",
    "# Delete First Line and add latest data at last line  \n",
    "\n",
    "### LIKE A QUEUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e57aaea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "2021-11-11 23:26\n"
     ]
    }
   ],
   "source": [
    "# 현재 시간 문자열로 가져오기\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "str_now = now.strftime('%Y-%m-%d %H:%M')\n",
    "print(type(str_now))\n",
    "print(str_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1ab39e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "현재 시간 :  2021-11-12 10:03:28.042872\n",
      "다음 10분 :  2021-11-12 10:10:28.042872\n"
     ]
    }
   ],
   "source": [
    "# 다음 10분 찾기\n",
    "import datetime\n",
    "current_t = datetime.datetime.now()\n",
    "remainder_min = 10 - current_t.minute % 10\n",
    "\n",
    "print(remainder_min)\n",
    "print(\"현재 시간 : \", current_t)\n",
    "\n",
    "coming_10m = current_t + datetime.timedelta(minutes=int(remainder_min))\n",
    "print(\"다음 10분 : \",coming_10m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7052ef96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-11-12 10:10:00</th>\n",
       "      <td>78640000.0</td>\n",
       "      <td>78640000.0</td>\n",
       "      <td>78239000.0</td>\n",
       "      <td>78315000.0</td>\n",
       "      <td>153.887487</td>\n",
       "      <td>1.207792e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-12 10:10:00</th>\n",
       "      <td>78640000.0</td>\n",
       "      <td>78640000.0</td>\n",
       "      <td>78239000.0</td>\n",
       "      <td>78315000.0</td>\n",
       "      <td>153.887487</td>\n",
       "      <td>1.207792e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           open        high         low       close  \\\n",
       "2021-11-12 10:10:00  78640000.0  78640000.0  78239000.0  78315000.0   \n",
       "2021-11-12 10:10:00  78640000.0  78640000.0  78239000.0  78315000.0   \n",
       "\n",
       "                         volume         value  \n",
       "2021-11-12 10:10:00  153.887487  1.207792e+10  \n",
       "2021-11-12 10:10:00  153.887487  1.207792e+10  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyupbit\n",
    "\n",
    "ticker = 'KRW-BTC'\n",
    "interval ='minute10'\n",
    "to = coming_10m\n",
    "count = 1\n",
    "\n",
    "latest_data = pyupbit.get_ohlcv(ticker=ticker, interval=interval, to=to, count=count)\n",
    "_latest_data = pyupbit.get_ohlcv(ticker=ticker, interval=interval, to=to, count=count)\n",
    "\n",
    "pd.concat([latest_data, _latest_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442e491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
