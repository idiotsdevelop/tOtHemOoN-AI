{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fb574fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pyupbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79055f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, Lambda, Input, GlobalAveragePooling1D, Bidirectional\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77bb5439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 6, 6)]            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 6, 128)            69120     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 6, 64)             49408     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 6, 32)             12416     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 130,977\n",
      "Trainable params: 130,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model(input_shape):\n",
    "    input = Input(shape=input_shape)\n",
    "    x = LSTM(128, return_sequences=True, activation='tanh', dropout=0.2)(input)\n",
    "    x = LSTM(64, return_sequences=True, activation='tanh', dropout=0.2)(x)\n",
    "    x = LSTM(32, return_sequences=True, activation='tanh', dropout=0.2)(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    output = Dense(1)(x)\n",
    "    model = Model(input, output)\n",
    "    return model\n",
    "\n",
    "WINDOW_SIZE = 6\n",
    "feature_n = 6\n",
    "\n",
    "Input_shape = (WINDOW_SIZE, feature_n)\n",
    "model = get_model(Input_shape)\n",
    "model.load_weights('../checkpoints/ckeckpointer.ckpt')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c53e898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyupbit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "class Data_preprocess():\n",
    "    def __init__(self, args):\n",
    "        if not hasattr(args, 'data') or args.data is None:\n",
    "            print(args)\n",
    "            self.data, self.label, self.dataset = self.preprocess(\n",
    "                pyupbit.get_ohlcv(ticker=args.ticker, interval=args.interval, to=args.to, count=args.count))\n",
    "        else :\n",
    "            self.data, self.label, self.dataset = self.csv_parsing(args.data)\n",
    "\n",
    "    def MinMax(self, dataset_df):\n",
    "        norm = MinMaxScaler()\n",
    "        norm_dataset = norm.fit_transform(dataset_df)\n",
    "        return pd.DataFrame(norm_dataset, columns=list(dataset_df.columns))\n",
    "\n",
    "    def add_after10(self, dataset_df):\n",
    "        after10 = np.zeros_like(self.norm_dataset['close'])\n",
    "        for i in range(len(dataset_df['close']) - 1):\n",
    "            after10[i] = dataset_df['close'][i + 1]\n",
    "        return after10\n",
    "\n",
    "    def drop_feature(self, dataset_df):\n",
    "        # index(시간) 제거\n",
    "        dataset_df = dataset_df.reset_index(drop=True)\n",
    "        # value 제거\n",
    "        dataset_df = dataset_df.drop(columns=['value'])\n",
    "        return dataset_df\n",
    "\n",
    "    def add_avgPrice(self, dataset_df):\n",
    "        return (dataset_df['high'] + dataset_df['low'] +\n",
    "                dataset_df['open'] + dataset_df['close']) // 4\n",
    "\n",
    "    def preprocess(self, dataset, latest=False):\n",
    "\n",
    "        # drop feature\n",
    "        #dataset_df = self.drop_feature(dataset)\n",
    "        dataset_df = dataset\n",
    "\n",
    "        # avg_price 추가\n",
    "        dataset_df['avg_price'] = self.add_avgPrice(dataset_df)\n",
    "\n",
    "        if latest == True:\n",
    "            # 가장 예전 데이터 삭제 - norm이랑 original 둘 다 적용\n",
    "            self.dataset = self.dataset.drop([self.dataset.index[0]]).drop(columns=['after10'])\n",
    "            self.norm_dataset = self.norm_dataset.drop([self.norm_dataset.index[0]])\n",
    "\n",
    "            # ori dataset에 추가\n",
    "            self.dataset = pd.concat([self.dataset, dataset_df])\n",
    "            self.dataset = self.dataset.reset_index(drop=True)\n",
    "\n",
    "            # min max 정규화 (MinMaxScaler) 적용\n",
    "            self.norm_dataset = self.MinMax(self.dataset)\n",
    "\n",
    "            # after10 추가\n",
    "            self.dataset['after10'] = self.add_after10(self.dataset)\n",
    "\n",
    "\n",
    "        else:\n",
    "            # min max 정규화 (MinMaxScaler) 적용\n",
    "            self.norm_dataset = self.MinMax(dataset_df)\n",
    "\n",
    "            # after10 추가\n",
    "            dataset_df['after10'] = self.add_after10(dataset_df)\n",
    "\n",
    "        # 예측될 값(label)인 10분 후 가격\n",
    "        self.norm_dataset['after10'] = self.add_after10(self.norm_dataset)\n",
    "\n",
    "        return self.norm_dataset.drop(columns=['after10']), self.norm_dataset['after10'], dataset_df\n",
    "\n",
    "    def csv_parsing(self, data_path):\n",
    "        merge_df = pd.DataFrame()\n",
    "        data_folders = glob(os.path.join(data_path, '*'))\n",
    "\n",
    "        for data_folder in tqdm(data_folders):\n",
    "            data_csvs = glob(os.path.join(data_folder,'*.csv'))\n",
    "\n",
    "            for data_csv in data_csvs :\n",
    "                csv_df = pd.read_csv(data_csv).drop(columns=[\"Unnamed: 0\"])\n",
    "                merge_df = pd.concat([merge_df, csv_df], ignore_index=True)\n",
    "\n",
    "        return self.preprocess(merge_df)\n",
    "\n",
    "\n",
    "    # dataset에 window 적용\n",
    "    def windowed_dataset(self, data, label, window_size, batch_size):\n",
    "        sliced_data = tf.data.Dataset.from_tensor_slices(data)\n",
    "        sliced_data = sliced_data.window(window_size, shift=1, stride=1, drop_remainder=True)\n",
    "        sliced_data = sliced_data.flat_map(lambda x: x.batch(window_size))\n",
    "\n",
    "        sliced_label = tf.data.Dataset.from_tensor_slices(label[window_size:])\n",
    "\n",
    "        sliced_dataset = tf.data.Dataset.zip((sliced_data, sliced_label))\n",
    "\n",
    "        return sliced_dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdc92de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 12, 7)]           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 12, 256)           139264    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 12, 128)           164352    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 12, 64)            41216     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 344,897\n",
      "Trainable params: 344,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model_BiLSTM(input_shape):\n",
    "    input = Input(shape=input_shape)\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True, activation='tanh', dropout=0.3))(input)\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True, activation='tanh', dropout=0.3))(x)\n",
    "    x = Bidirectional(LSTM(32, return_sequences=True, activation='tanh', dropout=0.3))(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    output = Dense(1)(x)\n",
    "    model = Model(input, output)\n",
    "    return model\n",
    "\n",
    "def get_model(input_shape):\n",
    "    input = Input(shape=input_shape)\n",
    "    x = LSTM(128, return_sequences=True, activation='tanh', dropout=0.2)(input)\n",
    "    x = LSTM(64, return_sequences=True, activation='tanh', dropout=0.2)(x)\n",
    "    x = LSTM(32, return_sequences=True, activation='tanh', dropout=0.2)(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    output = Dense(1)(x)\n",
    "    model = Model(input, output)\n",
    "    return model\n",
    "\n",
    "\n",
    "WINDOW_SIZE = 6\n",
    "feature_n = 6\n",
    "\n",
    "Bi_WINDOW_SIZE = 12\n",
    "Bi_feature_n = 7\n",
    "\n",
    "Input_shape = (Bi_WINDOW_SIZE, Bi_feature_n)\n",
    "model = get_model_BiLSTM(Input_shape)\n",
    "model.load_weights('../checkpoints/BiLSTM/ckeckpointer.ckpt')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9e7cb12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ticker': 'KRW-BTC', 'interval': 'minute10', 'to': '2021-11-24 00:40', 'count': 2000}\n"
     ]
    }
   ],
   "source": [
    "from easydict import EasyDict\n",
    "import datetime\n",
    "\n",
    "options = {\n",
    "    'ticker' : 'KRW-BTC',\n",
    "    'interval' : 'minute10',\n",
    "#     'to' : '2021-10-01 00:00',\n",
    "    'to' : datetime.datetime.now().strftime('%Y-%m-%d %H:%M'),\n",
    "    'count' : 2000\n",
    "}\n",
    "\n",
    "args = EasyDict(options)\n",
    "\n",
    "processed_data = Data_preprocess(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2c84e7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          open      high       low     close    volume     value  avg_price\n",
      "0     0.850951  0.825273  0.847061  0.850486  0.060696  0.066349   0.850742\n",
      "1     0.852688  0.826131  0.854009  0.842430  0.041252  0.045141   0.851139\n",
      "2     0.844241  0.822777  0.851589  0.837454  0.069364  0.075852   0.846293\n",
      "3     0.837531  0.843916  0.853931  0.853566  0.069715  0.076439   0.854635\n",
      "4     0.853635  0.838534  0.856741  0.842035  0.029963  0.032841   0.855131\n",
      "...        ...       ...       ...       ...       ...       ...        ...\n",
      "1995  0.134839  0.151326  0.157936  0.169734  0.101392  0.098817   0.152476\n",
      "1996  0.170601  0.163027  0.168866  0.166338  0.096907  0.094651   0.166379\n",
      "1997  0.167048  0.155850  0.172613  0.151568  0.061285  0.059795   0.160897\n",
      "1998  0.151970  0.143682  0.170583  0.150541  0.061014  0.059442   0.153230\n",
      "1999  0.157022  0.143058  0.160981  0.150462  0.054595  0.053174   0.151880\n",
      "\n",
      "[2000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(processed_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3b6cac5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.842430\n",
      "1       0.837454\n",
      "2       0.853566\n",
      "3       0.842035\n",
      "4       0.838243\n",
      "          ...   \n",
      "1995    0.166338\n",
      "1996    0.151568\n",
      "1997    0.150541\n",
      "1998    0.150462\n",
      "1999    0.000000\n",
      "Name: after10, Length: 2000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(processed_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8523026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(lstm_model, processed_data, window_size, batch_size):\n",
    "    dataset = processed_data.windowed_dataset(processed_data.data, processed_data.label, window_size, batch_size)\n",
    "    pred = lstm_model.predict(dataset)\n",
    "    pred = pred[:, 0]\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "41894a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bi_WINDOW_SIZE = 12\n",
    "\n",
    "WINDOW_SIZE = 6\n",
    "BATCH_SIZE=1\n",
    "\n",
    "pred = inference(model, processed_data, Bi_WINDOW_SIZE, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "01efc3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = processed_data.label[WINDOW_SIZE:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "281b90b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.838875\n",
       "1       0.847484\n",
       "2       0.847879\n",
       "3       0.848274\n",
       "4       0.874654\n",
       "          ...   \n",
       "1989    0.166338\n",
       "1990    0.151568\n",
       "1991    0.150541\n",
       "1992    0.150462\n",
       "1993    0.000000\n",
       "Name: after10, Length: 1994, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ef29809d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sub\\anaconda3\\envs\\coin\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "pred_rate_val = []\n",
    "act_rate_val = []\n",
    "accuracy = []\n",
    "\n",
    "for i in range(0, len(pred) - 2) :\n",
    "    rate_pred = pred[i + 1]/pred[i]\n",
    "    pred_rate_val.append(rate_pred)\n",
    "    \n",
    "    if rate_pred < 1:\n",
    "        # Down\n",
    "        pred_tmp = 0\n",
    "    else:\n",
    "        # Up\n",
    "        pred_tmp = 1\n",
    "        \n",
    "    rate_act = actual[i + 2] / actual[i + 1]\n",
    "    act_rate_val.append(rate_act)\n",
    "    \n",
    "    if rate_act < 1:\n",
    "        # Down\n",
    "        act_tmp = 0\n",
    "    else:\n",
    "        # Up\n",
    "        act_tmp = 1\n",
    "        \n",
    "    if pred_tmp == act_tmp :\n",
    "        accuracy.append(1)\n",
    "    else :\n",
    "        accuracy.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "564770b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5936555891238671"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도\n",
    "sum(accuracy) / len(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9126b024",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np_pred_rate_val = np.array(pred_rate_val)\n",
    "np_accuracy = np.array(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a095de42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0018128 1.001249  1.0015295 ... 1.0224224 1.0245037 1.0220371]\n",
      "(1986,)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "print(np_pred_rate_val)\n",
    "print(np_accuracy.shape)\n",
    "\n",
    "a_np_pred_rate_val =  copy.deepcopy(np_pred_rate_val)\n",
    "b_np_pred_rate_val =  copy.deepcopy(np_pred_rate_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f636775b",
   "metadata": {},
   "source": [
    "# 몇 퍼센트 올랐는지 구하기 - 절대값 없이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3ff6e9c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18128157, 0.12489557, 0.15294552, ..., 2.2422433 , 2.4503708 ,\n",
       "       2.2037148 ], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_np_pred_rate_val = a_np_pred_rate_val - 1\n",
    "a_np_pred_rate_val = a_np_pred_rate_val * 100\n",
    "a_np_pred_rate_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d8904",
   "metadata": {},
   "source": [
    "### 정답이 값 중에서 가장 큰 값과 가장 작은 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "73be2d91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1179,)\n",
      "-10.621738\n",
      "9.616459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.18128157, 0.12489557, 0.15294552, ..., 1.9035697 , 2.2422433 ,\n",
       "       2.2037148 ], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = a_np_pred_rate_val[ np_accuracy[:]==1 ]\n",
    "print(correct.shape)\n",
    "print(min(correct))\n",
    "print(max(correct))\n",
    "correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce02bbbf",
   "metadata": {},
   "source": [
    "### % 구간 정리 - 대체적으로 -10 ~ +10 사이인듯 (최근 데이터 기준)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8f7d6b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.62173843383789 ~ -0.0010371208190917969\n",
      "(639,)\n",
      "0.0005841255187988281 ~ 9.616458892822266\n",
      "(540,)\n"
     ]
    }
   ],
   "source": [
    "correct_down = correct[correct[:] < 0]\n",
    "print(f\"{min(correct_down)} ~ {max(correct_down)}\")\n",
    "print(correct_down.shape)\n",
    "\n",
    "correct_up = correct[correct[:] > 0]\n",
    "print(f\"{min(correct_up)} ~ {max(correct_up)}\")\n",
    "print(correct_up.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6c4cfc",
   "metadata": {},
   "source": [
    "### 각 1퍼센트 기준으로 구간을 나누고 정답 개수 출력\n",
    "- 0 ~ 1 사이에 모든 정답의 77%가 있음 (2021-11-23 23:55 기준)\n",
    "- 0 ~ 2 사이에 모든 정답의 87%가 있음 (2021-11-23 23:55 기준)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0e4c8c59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ~ 1 : 416\n",
      "누적 개수 : 416\n",
      "1 ~ 2 : 54\n",
      "누적 개수 : 470\n",
      "2 ~ 3 : 32\n",
      "누적 개수 : 502\n",
      "3 ~ 4 : 21\n",
      "누적 개수 : 523\n",
      "4 ~ 5 : 5\n",
      "누적 개수 : 528\n",
      "5 ~ 6 : 3\n",
      "누적 개수 : 531\n",
      "6 ~ 7 : 4\n",
      "누적 개수 : 535\n",
      "7 ~ 8 : 3\n",
      "누적 개수 : 538\n",
      "8 ~ 9 : 1\n",
      "누적 개수 : 539\n",
      "9 ~ 10 : 1\n",
      "누적 개수 : 540\n"
     ]
    }
   ],
   "source": [
    "correct_tmp = correct[correct[:] > 0 ]\n",
    "tmp_shape = 0\n",
    "for i in range(1, 11) :\n",
    "    correct_1 = correct_tmp[correct_tmp[:] < (i) ]\n",
    "    correct_UP = correct_tmp[correct_tmp[:] < (i + 1) ]\n",
    "    print(f\"{i-1} ~ {i} : {correct_1.shape[0] - tmp_shape}\")\n",
    "    tmp_shape = correct_1.shape[0]\n",
    "    print(f\"누적 개수 : {tmp_shape}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaad6365",
   "metadata": {},
   "source": [
    "### 구간 별 개수 찾기\n",
    "- 0 ~ 1 사이에 모든 값들 기준 78%가 있음. (2021-11-23 23:55 기준)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77af90f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total = (921,)\n",
      "0.0 ~ 0.1 : 193\n",
      "193\n",
      "0.1 ~ 0.2 : 160\n",
      "353\n",
      "0.2 ~ 0.3 : 92\n",
      "445\n",
      "0.3 ~ 0.4 : 64\n",
      "509\n",
      "0.4 ~ 0.5 : 44\n",
      "553\n",
      "0.5 ~ 0.6 : 53\n",
      "606\n",
      "0.6 ~ 0.7 : 44\n",
      "650\n",
      "0.7 ~ 0.8 : 27\n",
      "677\n",
      "0.8 ~ 0.9 : 27\n",
      "704\n",
      "0.9 ~ 1.0 : 21\n",
      "725\n",
      "1.0 ~ 1.1 : 16\n",
      "741\n",
      "1.1 ~ 1.2 : 9\n",
      "750\n",
      "1.2 ~ 1.3 : 10\n",
      "760\n",
      "1.3 ~ 1.4 : 9\n",
      "769\n",
      "1.4 ~ 1.5 : 13\n",
      "782\n",
      "1.5 ~ 1.6 : 10\n",
      "792\n",
      "1.6 ~ 1.7 : 3\n",
      "795\n",
      "1.7 ~ 1.8 : 5\n",
      "800\n",
      "1.8 ~ 1.9 : 4\n",
      "804\n",
      "1.9 ~ 2.0 : 5\n",
      "809\n",
      "2.0 ~ 2.1 : 4\n",
      "813\n",
      "2.1 ~ 2.2 : 5\n",
      "818\n",
      "2.2 ~ 2.3 : 7\n",
      "825\n",
      "2.3 ~ 2.4 : 3\n",
      "828\n",
      "2.4 ~ 2.5 : 10\n",
      "838\n",
      "2.5 ~ 2.6 : 4\n",
      "842\n",
      "2.6 ~ 2.7 : 3\n",
      "845\n",
      "2.7 ~ 2.8 : 6\n",
      "851\n",
      "2.8 ~ 2.9 : 3\n",
      "854\n",
      "2.9 ~ 3.0 : 6\n",
      "860\n",
      "3.0 ~ 3.1 : 3\n",
      "863\n",
      "3.1 ~ 3.2 : 6\n",
      "869\n",
      "3.2 ~ 3.3 : 2\n",
      "871\n",
      "3.3 ~ 3.4 : 2\n",
      "873\n",
      "3.4 ~ 3.5 : 2\n",
      "875\n",
      "3.5 ~ 3.6 : 4\n",
      "879\n",
      "3.6 ~ 3.7 : 2\n",
      "881\n",
      "3.7 ~ 3.8 : 3\n",
      "884\n",
      "3.8 ~ 3.9 : 7\n",
      "891\n",
      "3.9 ~ 4.0 : 2\n",
      "893\n",
      "4.0 ~ 4.1 : 1\n",
      "894\n",
      "4.1 ~ 4.2 : 1\n",
      "895\n",
      "4.2 ~ 4.3 : 2\n",
      "897\n",
      "4.3 ~ 4.4 : 0\n",
      "897\n",
      "4.4 ~ 4.5 : 0\n",
      "897\n",
      "4.5 ~ 4.6 : 1\n",
      "898\n",
      "4.6 ~ 4.7 : 0\n",
      "898\n",
      "4.7 ~ 4.8 : 2\n",
      "900\n",
      "4.8 ~ 4.9 : 1\n",
      "901\n"
     ]
    }
   ],
   "source": [
    "all_data = copy.deepcopy(a_np_pred_rate_val)\n",
    "correct_tmp = all_data[all_data[:] > 0 ]\n",
    "print(f\"total = {correct_tmp.shape}\")\n",
    "tmp_shape = 0\n",
    "for i in range(1 , 50) :\n",
    "    correct_1 = correct_tmp[correct_tmp[:] < (i/10) ]\n",
    "    correct_UP = correct_tmp[correct_tmp[:] < (i/10 + 0.1) ]\n",
    "    print(f\"{i/10 - 0.1:.1f} ~ {i/10} : {correct_1.shape[0] - tmp_shape}\")\n",
    "    tmp_shape = correct_1.shape[0]\n",
    "    print(tmp_shape)\n",
    "\n",
    "    \n",
    "# correct_1 = correct_tmp[correct_tmp[:] < 1 ]\n",
    "# correct_UP = correct_tmp[correct_tmp[:] < 2 ]\n",
    "# print(correct_1.shape)\n",
    "# print(correct_UP.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e41be3",
   "metadata": {},
   "source": [
    "### 모든 값들 중 가장 변화율이 큰 값과 작은 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1517c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1986,)\n",
      "-11.454636\n",
      "10.437751\n"
     ]
    }
   ],
   "source": [
    "print(a_np_pred_rate_val.shape)\n",
    "print(min(a_np_pred_rate_val))\n",
    "print(max(a_np_pred_rate_val))\n",
    "a_correct = copy.deepcopy(a_np_pred_rate_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767e6db8",
   "metadata": {},
   "source": [
    "### % 구간 정리 - 대체적으로 -10 ~ +10 사이인듯 (최근 데이터 기준)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a22194e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-11.454635620117188 ~ -0.0010371208190917969\n",
      "(1065,)\n",
      "0.0003457069396972656 ~ 10.437750816345215\n",
      "(921,)\n"
     ]
    }
   ],
   "source": [
    "correct_down = a_correct[a_correct[:] < 0]\n",
    "print(f\"{min(correct_down)} ~ {max(correct_down)}\")\n",
    "print(correct_down.shape)\n",
    "\n",
    "correct_up = a_correct[a_correct[:] > 0]\n",
    "print(f\"{min(correct_up)} ~ {max(correct_up)}\")\n",
    "print(correct_up.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef89435",
   "metadata": {},
   "source": [
    "### 각 1퍼센트 기준으로 구간을 나누고 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "508b7b54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(725,)\n",
      "(809,)\n",
      "\n",
      "(84,)\n",
      "(860,)\n",
      "\n",
      "(51,)\n",
      "(893,)\n",
      "\n",
      "(33,)\n",
      "(902,)\n",
      "\n",
      "(9,)\n",
      "(905,)\n",
      "\n",
      "(3,)\n",
      "(910,)\n",
      "\n",
      "(5,)\n",
      "(914,)\n",
      "\n",
      "(4,)\n",
      "(918,)\n",
      "\n",
      "(4,)\n",
      "(920,)\n",
      "\n",
      "(2,)\n",
      "(921,)\n",
      "\n",
      "(1,)\n",
      "(921,)\n",
      "\n",
      "(0,)\n",
      "(921,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correct_tmp = a_correct[a_correct[:] > 0 ]\n",
    "\n",
    "correct_1 = correct_tmp[correct_tmp[:] < 1 ]\n",
    "correct_UP = correct_tmp[correct_tmp[:] < 2 ]\n",
    "print(correct_1.shape)\n",
    "print(correct_UP.shape)\n",
    "print()\n",
    "\n",
    "correct_2 = correct_UP[correct_UP[:] > 1 ]\n",
    "correct_UP = correct_tmp[correct_tmp[:] < 3 ]\n",
    "print(correct_2.shape)\n",
    "print(correct_UP.shape)\n",
    "print()\n",
    "\n",
    "correct_3 = correct_UP[correct_UP[:] > 2 ]\n",
    "correct_UP = correct_tmp[correct_tmp[:] < 4 ]\n",
    "print(correct_3.shape)\n",
    "print(correct_UP.shape)\n",
    "print()\n",
    "\n",
    "correct_4 = correct_UP[correct_UP[:] > 3 ]\n",
    "correct_UP = correct_tmp[correct_tmp[:] < 5 ]\n",
    "print(correct_4.shape)\n",
    "print(correct_UP.shape)\n",
    "print()\n",
    "\n",
    "correct_5 = correct_UP[correct_UP[:] > 4 ]\n",
    "correct_UP = correct_tmp[correct_tmp[:] < 6 ]\n",
    "print(correct_5.shape)\n",
    "print(correct_UP.shape)\n",
    "print()\n",
    "\n",
    "correct_6 = correct_UP[correct_UP[:] > 5 ]\n",
    "correct_UP = correct_tmp[correct_tmp[:] < 7 ]\n",
    "print(correct_6.shape)\n",
    "print(correct_UP.shape)\n",
    "print()\n",
    "\n",
    "correct_7 = correct_UP[correct_UP[:] > 6 ]\n",
    "correct_UP = correct_tmp[correct_tmp[:] < 8 ]\n",
    "print(correct_7.shape)\n",
    "print(correct_UP.shape)\n",
    "print()\n",
    "\n",
    "correct_8 = correct_UP[correct_UP[:] > 7 ]\n",
    "correct_UP = correct_tmp[correct_tmp[:] < 9 ]\n",
    "print(correct_8.shape)\n",
    "print(correct_UP.shape)\n",
    "print()\n",
    "\n",
    "correct_9 = correct_UP[correct_UP[:] > 8 ]\n",
    "correct_UP = correct_tmp[correct_tmp[:] < 10 ]\n",
    "print(correct_9.shape)\n",
    "print(correct_UP.shape)\n",
    "print()\n",
    "\n",
    "correct_10 = correct_UP[correct_UP[:] > 9 ]\n",
    "correct_UP = correct_tmp[correct_tmp[:] < 11 ]\n",
    "print(correct_10.shape)\n",
    "print(correct_UP.shape)\n",
    "print()\n",
    "\n",
    "correct_11 = correct_UP[correct_UP[:] > 10 ]\n",
    "correct_UP = correct_tmp[correct_tmp[:] < 12 ]\n",
    "print(correct_11.shape)\n",
    "print(correct_UP.shape)\n",
    "print()\n",
    "\n",
    "correct_12 = correct_UP[correct_UP[:] > 11 ]\n",
    "correct_UP = correct_tmp[correct_tmp[:] < 13 ]\n",
    "print(correct_12.shape)\n",
    "print(correct_UP.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c645dc04",
   "metadata": {},
   "source": [
    "### 구간 별 누적그래프 그려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13991dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c5153e6",
   "metadata": {},
   "source": [
    "### 각 구간 별 정답 개수 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5e5c42c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(699,)\n",
      "(876,)\n",
      "\n",
      "(1986,)\n",
      "-10.377079\n",
      "10.152971\n",
      "[-1.         -1.          0.21060705 ... -1.         -0.52125454\n",
      " -1.        ]\n"
     ]
    }
   ],
   "source": [
    "correct_tmp = a_correct[a_correct[:] > 0 ]\n",
    "\n",
    "correct_1 = correct_tmp[correct_tmp[:] < 1 ]\n",
    "correct_UP = correct_tmp[correct_tmp[:] < 2 ]\n",
    "print(correct_1.shape)\n",
    "print(correct_UP.shape)\n",
    "print()\n",
    "\n",
    "bool_correct = copy.deepcopy(correct_tmp)\n",
    "bool_correct[ np_accuracy[:]==1 ] = -1\n",
    "print(bool_correct.shape)\n",
    "print(min(bool_correct))\n",
    "print(max(bool_correct))\n",
    "print(bool_correct)\n",
    "\n",
    "correct_1[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06235254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af7b17c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4594713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "768a6f62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.       , 0.       , 0.       , ..., 1.0102553, 1.0171678,\n",
       "       1.0174936], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_np_pred_rate_val[ np_accuracy[:]==1 ] = 0\n",
    "a_np_pred_rate_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a796550a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9923874 , 0.99104947, 0.98621666, ..., 0.        , 0.        ,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_np_pred_rate_val[ np_accuracy[:]==False ] = 0\n",
    "b_np_pred_rate_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ad710d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_pred_rate_val[ np_accuracy[:]==1 ] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b6532fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n"
     ]
    }
   ],
   "source": [
    "print(992 - np.count_nonzero(np_pred_rate_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "078d868a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1149"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0\n",
    "for i in np_pred_rate_val:\n",
    "    if i == 0:\n",
    "        c += 1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "533a5b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1570996978851964"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c/993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c6f571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8928e886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
