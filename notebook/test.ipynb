{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b9665fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pyupbit\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a62a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_preprocess() :\n",
    "    def __init__(self, ticker, interval, to, count, norm) :\n",
    "        self.norm = {\"minmax\" : self.MinMax,\n",
    "                    \"stand\" : self.standarization,\n",
    "                    \"diff\" : self.diff}\n",
    "        \n",
    "        self.data, self.label, self.dataset = self.preprocess(pyupbit.get_ohlcv(ticker=ticker, interval=interval, to=to, count=count),\n",
    "                                                             normalization=norm)\n",
    "        \n",
    "    def MinMax(self, df) :\n",
    "        norm = MinMaxScaler()\n",
    "        norm_dataset = norm.fit_transform(df)\n",
    "        return pd.DataFrame(norm_dataset, columns=list(df.columns))\n",
    "    \n",
    "    def standarization(self, df) :\n",
    "        for col in df:\n",
    "            df[col] = (df[col] - df[col].mean()) / df[col].std()\n",
    "        return df\n",
    "    \n",
    "    def diff(self, df) :\n",
    "        for col in (df):\n",
    "            log_y = np.log(df[col])\n",
    "            df[col][1:] = np.diff(log_y)\n",
    "        return df[1:]\n",
    "    \n",
    "\n",
    "    def add_label(self, dataset_df) :\n",
    "        after10 = np.zeros_like(dataset_df['close'])\n",
    "        for i in range(len(dataset_df['close']) - 1) :\n",
    "            if dataset_df['close'][i + 1] > dataset_df['close'][i] :\n",
    "                after10[i] = 1\n",
    "            else : \n",
    "                after10[i] = 0\n",
    "            \n",
    "        return pd.DataFrame(after10,columns=['label'])\n",
    "    \n",
    "    \n",
    "    def drop_feature(self, dataset_df) :\n",
    "        # index(시간) 제거\n",
    "        dataset_df = dataset_df.reset_index(drop=True)\n",
    "        # value 제거\n",
    "#         dataset_df = dataset_df.drop(columns=['value'])\n",
    "        return dataset_df\n",
    "    \n",
    "    \n",
    "    def add_avgPrice(self, dataset_df) :\n",
    "        return (dataset_df['high'] + dataset_df['low'] + \n",
    "                dataset_df['open'] + dataset_df['close']) // 4\n",
    "       \n",
    "    \n",
    "    def preprocess(self, dataset, normalization) :\n",
    "        \n",
    "        # drop feature\n",
    "        dataset_df = self.drop_feature(dataset)\n",
    "        \n",
    "        # avg_price 추가\n",
    "        dataset_df['avg_price'] = self.add_avgPrice(dataset_df)\n",
    "        \n",
    "        # label 추가\n",
    "        if normalization == \"diff\" :\n",
    "            label = self.add_label(dataset_df)[1:-1]\n",
    "        else :\n",
    "            label = self.add_label(dataset_df)[:-1]\n",
    "        \n",
    "        norm_df = self.norm[normalization](dataset_df.copy())[:-1]\n",
    "        \n",
    "        return norm_df, label, dataset_df[:-1]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e11418ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>value</th>\n",
       "      <th>avg_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.854681</td>\n",
       "      <td>-0.853338</td>\n",
       "      <td>-0.854432</td>\n",
       "      <td>-0.853480</td>\n",
       "      <td>-0.472213</td>\n",
       "      <td>-0.496971</td>\n",
       "      <td>-0.853985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.854029</td>\n",
       "      <td>-0.853199</td>\n",
       "      <td>-0.853731</td>\n",
       "      <td>-0.853480</td>\n",
       "      <td>-0.469498</td>\n",
       "      <td>-0.496541</td>\n",
       "      <td>-0.853613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.854029</td>\n",
       "      <td>-0.853292</td>\n",
       "      <td>-0.854618</td>\n",
       "      <td>-0.853759</td>\n",
       "      <td>-0.470259</td>\n",
       "      <td>-0.496697</td>\n",
       "      <td>-0.853927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.853843</td>\n",
       "      <td>-0.853292</td>\n",
       "      <td>-0.854105</td>\n",
       "      <td>-0.852781</td>\n",
       "      <td>-0.453105</td>\n",
       "      <td>-0.494194</td>\n",
       "      <td>-0.853508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.853470</td>\n",
       "      <td>-0.853710</td>\n",
       "      <td>-0.854245</td>\n",
       "      <td>-0.853620</td>\n",
       "      <td>-0.441865</td>\n",
       "      <td>-0.492584</td>\n",
       "      <td>-0.853764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236104</th>\n",
       "      <td>1.613274</td>\n",
       "      <td>1.607807</td>\n",
       "      <td>1.605662</td>\n",
       "      <td>1.602654</td>\n",
       "      <td>0.695077</td>\n",
       "      <td>2.058569</td>\n",
       "      <td>1.607356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236105</th>\n",
       "      <td>1.602747</td>\n",
       "      <td>1.601996</td>\n",
       "      <td>1.607856</td>\n",
       "      <td>1.602328</td>\n",
       "      <td>-0.077394</td>\n",
       "      <td>0.548755</td>\n",
       "      <td>1.603735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236106</th>\n",
       "      <td>1.602281</td>\n",
       "      <td>1.600648</td>\n",
       "      <td>1.600948</td>\n",
       "      <td>1.606194</td>\n",
       "      <td>0.091435</td>\n",
       "      <td>0.876071</td>\n",
       "      <td>1.602524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236107</th>\n",
       "      <td>1.606147</td>\n",
       "      <td>1.602461</td>\n",
       "      <td>1.606969</td>\n",
       "      <td>1.601769</td>\n",
       "      <td>-0.255885</td>\n",
       "      <td>0.200173</td>\n",
       "      <td>1.604340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236108</th>\n",
       "      <td>1.601722</td>\n",
       "      <td>1.603855</td>\n",
       "      <td>1.606969</td>\n",
       "      <td>1.608011</td>\n",
       "      <td>-0.340474</td>\n",
       "      <td>0.034996</td>\n",
       "      <td>1.605144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236109 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            open      high       low     close    volume     value  avg_price\n",
       "0      -0.854681 -0.853338 -0.854432 -0.853480 -0.472213 -0.496971  -0.853985\n",
       "1      -0.854029 -0.853199 -0.853731 -0.853480 -0.469498 -0.496541  -0.853613\n",
       "2      -0.854029 -0.853292 -0.854618 -0.853759 -0.470259 -0.496697  -0.853927\n",
       "3      -0.853843 -0.853292 -0.854105 -0.852781 -0.453105 -0.494194  -0.853508\n",
       "4      -0.853470 -0.853710 -0.854245 -0.853620 -0.441865 -0.492584  -0.853764\n",
       "...          ...       ...       ...       ...       ...       ...        ...\n",
       "236104  1.613274  1.607807  1.605662  1.602654  0.695077  2.058569   1.607356\n",
       "236105  1.602747  1.601996  1.607856  1.602328 -0.077394  0.548755   1.603735\n",
       "236106  1.602281  1.600648  1.600948  1.606194  0.091435  0.876071   1.602524\n",
       "236107  1.606147  1.602461  1.606969  1.601769 -0.255885  0.200173   1.604340\n",
       "236108  1.601722  1.603855  1.606969  1.608011 -0.340474  0.034996   1.605144\n",
       "\n",
       "[236109 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236104</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236105</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236106</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236107</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236108</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236109 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label\n",
       "0         0.0\n",
       "1         0.0\n",
       "2         1.0\n",
       "3         0.0\n",
       "4         0.0\n",
       "...       ...\n",
       "236104    0.0\n",
       "236105    1.0\n",
       "236106    0.0\n",
       "236107    1.0\n",
       "236108    0.0\n",
       "\n",
       "[236109 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>value</th>\n",
       "      <th>avg_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4201000.0</td>\n",
       "      <td>4241000.0</td>\n",
       "      <td>4195000.0</td>\n",
       "      <td>4227000.0</td>\n",
       "      <td>15.940028</td>\n",
       "      <td>6.722878e+07</td>\n",
       "      <td>4216000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4215000.0</td>\n",
       "      <td>4244000.0</td>\n",
       "      <td>4210000.0</td>\n",
       "      <td>4227000.0</td>\n",
       "      <td>16.224769</td>\n",
       "      <td>6.854317e+07</td>\n",
       "      <td>4224000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4215000.0</td>\n",
       "      <td>4242000.0</td>\n",
       "      <td>4191000.0</td>\n",
       "      <td>4221000.0</td>\n",
       "      <td>16.144995</td>\n",
       "      <td>6.806705e+07</td>\n",
       "      <td>4217250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4219000.0</td>\n",
       "      <td>4242000.0</td>\n",
       "      <td>4202000.0</td>\n",
       "      <td>4242000.0</td>\n",
       "      <td>17.943481</td>\n",
       "      <td>7.572972e+07</td>\n",
       "      <td>4226250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4227000.0</td>\n",
       "      <td>4233000.0</td>\n",
       "      <td>4199000.0</td>\n",
       "      <td>4224000.0</td>\n",
       "      <td>19.122032</td>\n",
       "      <td>8.065820e+07</td>\n",
       "      <td>4220750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236104</th>\n",
       "      <td>57184000.0</td>\n",
       "      <td>57185000.0</td>\n",
       "      <td>56901000.0</td>\n",
       "      <td>56955000.0</td>\n",
       "      <td>138.327126</td>\n",
       "      <td>7.890153e+09</td>\n",
       "      <td>57056250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236105</th>\n",
       "      <td>56958000.0</td>\n",
       "      <td>57060000.0</td>\n",
       "      <td>56948000.0</td>\n",
       "      <td>56948000.0</td>\n",
       "      <td>57.335712</td>\n",
       "      <td>3.268367e+09</td>\n",
       "      <td>56978500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236106</th>\n",
       "      <td>56948000.0</td>\n",
       "      <td>57031000.0</td>\n",
       "      <td>56800000.0</td>\n",
       "      <td>57031000.0</td>\n",
       "      <td>75.036941</td>\n",
       "      <td>4.270333e+09</td>\n",
       "      <td>56952500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236107</th>\n",
       "      <td>57031000.0</td>\n",
       "      <td>57070000.0</td>\n",
       "      <td>56929000.0</td>\n",
       "      <td>56936000.0</td>\n",
       "      <td>38.621467</td>\n",
       "      <td>2.201300e+09</td>\n",
       "      <td>56991500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236108</th>\n",
       "      <td>56936000.0</td>\n",
       "      <td>57100000.0</td>\n",
       "      <td>56929000.0</td>\n",
       "      <td>57070000.0</td>\n",
       "      <td>29.752570</td>\n",
       "      <td>1.695665e+09</td>\n",
       "      <td>57008750.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236109 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              open        high         low       close      volume  \\\n",
       "0        4201000.0   4241000.0   4195000.0   4227000.0   15.940028   \n",
       "1        4215000.0   4244000.0   4210000.0   4227000.0   16.224769   \n",
       "2        4215000.0   4242000.0   4191000.0   4221000.0   16.144995   \n",
       "3        4219000.0   4242000.0   4202000.0   4242000.0   17.943481   \n",
       "4        4227000.0   4233000.0   4199000.0   4224000.0   19.122032   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "236104  57184000.0  57185000.0  56901000.0  56955000.0  138.327126   \n",
       "236105  56958000.0  57060000.0  56948000.0  56948000.0   57.335712   \n",
       "236106  56948000.0  57031000.0  56800000.0  57031000.0   75.036941   \n",
       "236107  57031000.0  57070000.0  56929000.0  56936000.0   38.621467   \n",
       "236108  56936000.0  57100000.0  56929000.0  57070000.0   29.752570   \n",
       "\n",
       "               value   avg_price  \n",
       "0       6.722878e+07   4216000.0  \n",
       "1       6.854317e+07   4224000.0  \n",
       "2       6.806705e+07   4217250.0  \n",
       "3       7.572972e+07   4226250.0  \n",
       "4       8.065820e+07   4220750.0  \n",
       "...              ...         ...  \n",
       "236104  7.890153e+09  57056250.0  \n",
       "236105  3.268367e+09  56978500.0  \n",
       "236106  4.270333e+09  56952500.0  \n",
       "236107  2.201300e+09  56991500.0  \n",
       "236108  1.695665e+09  57008750.0  \n",
       "\n",
       "[236109 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ticker = 'KRW-BTC'\n",
    "interval ='minute10'\n",
    "to = f'2022-03-29 00:00'\n",
    "count = 288000\n",
    "\n",
    "processed_data =  Data_preprocess(ticker, interval, to, count, \"stand\")\n",
    "display(processed_data.data)\n",
    "display(processed_data.label)\n",
    "display(processed_data.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa1ea221",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.dataset.to_csv('../data/288000_data.csv')\n",
    "processed_data.label.to_csv('../data/288000_label.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aab023d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = pd.read_csv('../data/144000_data.csv').drop(columns=['Unnamed: 0'])\n",
    "csv_label = pd.read_csv('../data/144000_label.csv').drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06414f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EachColumnMinMax(df) :\n",
    "    norm = MinMaxScaler()\n",
    "    df = norm.fit_transform(np.array(df).reshape(-1, 1)).squeeze(1)\n",
    "    return df\n",
    "\n",
    "def EachColumnStand(df) :\n",
    "    df = (df - df.mean()) / df.std()\n",
    "    return df\n",
    "\n",
    "def EachColumnDiff(df) :\n",
    "    log_y = np.log(df)\n",
    "    df[1:] = np.diff(log_y)\n",
    "    return df[1:]\n",
    "\n",
    "\n",
    "def WindowDataGenerator(df_data, df_label, window_size, stride, norm) :\n",
    "    \n",
    "    if norm == \"diff\" :\n",
    "        num_sample = ((df_data.shape[0] - 1) - window_size) // stride + 1\n",
    "        data = np.zeros([window_size - 1, df_data.shape[1], num_sample])\n",
    "    else : \n",
    "        num_sample = (df_data.shape[0] - window_size) // stride + 1\n",
    "        data = np.zeros([window_size, df_data.shape[1], num_sample])\n",
    "\n",
    "    \n",
    "    labels = np.zeros([num_sample])\n",
    "\n",
    "    for i in tqdm(range(num_sample)) :\n",
    "        tmp = {}\n",
    "        data_start = stride * i\n",
    "        data_end = data_start + window_size\n",
    "        \n",
    "        for col in df_data.columns :\n",
    "            if norm == \"diff\" :\n",
    "                tmp[col] = EachColumnDiff(df_data[col][data_start : data_end])\n",
    "            elif norm == \"stand\" :\n",
    "                tmp[col] = EachColumnStand(df_data[col][data_start : data_end])\n",
    "            elif norm == \"minmax\" :\n",
    "                tmp[col] = EachColumnMinMax(df_data[col][data_start : data_end])\n",
    "\n",
    "        data[:, :, i] = pd.DataFrame(tmp).values\n",
    "        labels[i] = df_label.values[data_end - 1]\n",
    "        \n",
    "        \n",
    "    data = data.transpose((2, 0, 1))\n",
    "    print(\"dataset shape ==== \",data.shape)\n",
    "    \n",
    "    # data shape (80, 600, 6), label shape (80,)\n",
    "    return torch.Tensor(data), torch.Tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1060139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(csv_data[1:-1].shape)\n",
    "\n",
    "# a,b = WindowDataGenerator(csv_data[:-1], csv_label, 24 * 6, 117, \"diff\")\n",
    "# print(a.shape)\n",
    "# print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d37d0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer2FC(nn.Module) :\n",
    "    def __init__(self, input_shape, d_model, n_head, num_layer, dropout, num_class=2):\n",
    "        super(Transformer2FC, self).__init__()\n",
    "        \n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=n_head, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layer)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        \n",
    "        self.Encoder = nn.Sequential(\n",
    "            nn.Linear(input_shape[1], d_model//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model//2, d_model)\n",
    "        )\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model//2, 1)\n",
    "        )\n",
    "\n",
    "        self.linear2 = nn.Sequential(\n",
    "            nn.Linear(input_shape[0], input_shape[0]//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_shape[0]//2, num_class)\n",
    "        )\n",
    "        \n",
    "#         self.sigmoid = nn.Softmax()\n",
    "    \n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "    \n",
    "    def forward(self, x, masked_x) :\n",
    "        # (batch, data, dim)\n",
    "#         print(\"input shape : \", x.shape)\n",
    "        x = self.Encoder(x)\n",
    "#         print(\"Encoder shape : \", x.shape)\n",
    "        x = self.pos_encoder(x)\n",
    "#         print(\"pos_encoder shape : \", x.shape)\n",
    "#         print(\"masked_x shape : \", masked_x.shape)\n",
    "        x = self.transformer_encoder(x.transpose(0,1), masked_x).transpose(0, 1)\n",
    "#         print(\"transformer_encoder shape : \", x.shape)\n",
    "        x = self.linear(x)\n",
    "#         print(\"linear shape : \", x.shape)\n",
    "        x = x.squeeze(2)\n",
    "#         print(\"squeeze shape : \", x.shape)\n",
    "        x = self.linear2(x)\n",
    "#         print(\"linear2 shape : \", x.shape)\n",
    "        x = x.squeeze(1)\n",
    "#         print(\"squeeze shape : \", x.shape)\n",
    "        return x\n",
    "\n",
    "class PositionalEncoding(nn.Module) :\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000) :\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        \n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "\n",
    "        return self.dropout(x)\n",
    "\n",
    "def get_attention_mask(x) :\n",
    "    mask = torch.eq(x, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3245cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowDataset(Dataset) :\n",
    "    def __init__(self, df_data, df_label, window_size=144, stride=6, norm=\"diff\") :\n",
    "        self.data, self.label = self.WindowDataGenerator(df_data, df_label, window_size, stride, norm)\n",
    "        \n",
    "    def __getitem__(self, i) :\n",
    "        return self.data[i], self.label[i]\n",
    "                \n",
    "    def __len__(self) :\n",
    "        assert len(self.data) == len(self.label), \"data와 label의 길이가 다름\"\n",
    "        return len(self.data)\n",
    "        \n",
    "    \n",
    "    def EachColumnMinMax(self, df) :\n",
    "        norm = MinMaxScaler()\n",
    "        df = norm.fit_transform(np.array(df).reshape(-1, 1)).squeeze(1)\n",
    "        return df\n",
    "\n",
    "    def EachColumnStand(self, df) :\n",
    "        df = (df - df.mean()) / df.std()\n",
    "        return df\n",
    "\n",
    "    def EachColumnDiff(self, df) :\n",
    "        log_y = np.log(df)\n",
    "        df[1:] = np.diff(log_y)\n",
    "        return df[1:]\n",
    "\n",
    "\n",
    "    def WindowDataGenerator(self, df_data, df_label, window_size, stride, norm) :\n",
    "        if norm == \"diff\" :\n",
    "            num_sample = ((df_data.shape[0] - 1) - window_size) // stride + 1\n",
    "            data = np.zeros([window_size - 1, df_data.shape[1], num_sample])\n",
    "        else : \n",
    "            num_sample = (df_data.shape[0] - window_size) // stride + 1\n",
    "            data = np.zeros([window_size, df_data.shape[1], num_sample])\n",
    "            \n",
    "        labels = np.zeros([num_sample])\n",
    "\n",
    "        for i in tqdm(range(num_sample)) :\n",
    "            tmp = {}\n",
    "            data_start = stride * i\n",
    "            data_end = data_start + window_size\n",
    "            for col in df_data.columns :\n",
    "                if norm == \"diff\" :\n",
    "                    tmp[col] = self.EachColumnDiff(df_data[col][data_start : data_end].copy())\n",
    "                elif norm == \"stand\" :\n",
    "                    tmp[col] = self.EachColumnStand(df_data[col][data_start : data_end].copy())\n",
    "                elif norm == \"minmax\" :\n",
    "                    tmp[col] = self.EachColumnMinMax(df_data[col][data_start : data_end].copy())\n",
    "\n",
    "#                 tmp[col] = self.EachColumnMinMax(df_data.loc[data_start : data_end - 1, col])\n",
    "\n",
    "            data[:, :, i] = pd.DataFrame(tmp).values\n",
    "            labels[i] = df_label.values[data_end - 1]\n",
    "\n",
    "        data = data.transpose((2, 0, 1))\n",
    "        print(\"dataset shape ==== \",data.shape)\n",
    "\n",
    "        # data shape (80, 600, 6), label shape (80,)\n",
    "        return torch.Tensor(data), torch.Tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8c1cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "lr = 1e-4\n",
    "epochs = 500\n",
    "window_size = 24 * 6\n",
    "window_stride = 12\n",
    "feature_len = 7\n",
    "batch_size = 128\n",
    "num_class = 1\n",
    "\n",
    "model = Transformer2FC(input_shape=(window_size, feature_len), \n",
    "                       d_model=512, \n",
    "                       n_head=8, \n",
    "                       num_layer=4, \n",
    "                       dropout=0.3, \n",
    "                       num_class = num_class).to(device)\n",
    "# model = MLSTMfcn(max_seq_len=window_size, num_features=feature_len).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.HuberLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8119f5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 11988/11988 [00:52<00:00, 228.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape ====  (11988, 144, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = WindowDataset(csv_data, \n",
    "                        csv_label,\n",
    "                       window_size = window_size, \n",
    "                       stride = window_stride, norm=\"stand\")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16348b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accuracy(pred, label, threshold=0) :\n",
    "    acc = torch.zeros(pred.shape[0])\n",
    "    acc[pred > threshold] = 1\n",
    "    acc[pred < threshold] = 0\n",
    "    score = [1 if acc[i] == label[i] else 0 for i in range(pred.shape[0])]\n",
    "    return sum(score) / pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c235a38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[0/500]   mean loss : 0.6936983   mean acc : 0.5092373: 100%|█████████████████████| 94/94 [00:31<00:00,  3.01it/s]\n",
      "Epoch[1/500]   mean loss : 0.6933019   mean acc : 0.5047928: 100%|█████████████████████| 94/94 [00:31<00:00,  2.97it/s]\n",
      "Epoch[2/500]   mean loss : 0.6932199   mean acc : 0.5068468: 100%|█████████████████████| 94/94 [00:32<00:00,  2.92it/s]\n",
      "Epoch[3/500]   mean loss : 0.6930321   mean acc : 0.5067004: 100%|█████████████████████| 94/94 [00:32<00:00,  2.90it/s]\n",
      "Epoch[4/500]   mean loss : 0.6932335   mean acc : 0.5102069: 100%|█████████████████████| 94/94 [00:33<00:00,  2.82it/s]\n",
      "Epoch[5/500]   mean loss : 0.6930441   mean acc : 0.5057466: 100%|█████████████████████| 94/94 [00:34<00:00,  2.71it/s]\n",
      "Epoch[6/500]   mean loss : 0.6931260   mean acc : 0.5086159: 100%|█████████████████████| 94/94 [00:33<00:00,  2.81it/s]\n",
      "Epoch[7/500]   mean loss : 0.6931648   mean acc : 0.5065935: 100%|█████████████████████| 94/94 [00:33<00:00,  2.78it/s]\n",
      "Epoch[8/500]   mean loss : 0.6928288   mean acc : 0.5130604: 100%|█████████████████████| 94/94 [00:34<00:00,  2.76it/s]\n",
      "Epoch[9/500]   mean loss : 0.6930538   mean acc : 0.5088613: 100%|█████████████████████| 94/94 [00:34<00:00,  2.76it/s]\n",
      "Epoch[10/500]   mean loss : 0.6928268   mean acc : 0.5129496: 100%|████████████████████| 94/94 [00:34<00:00,  2.75it/s]\n",
      "Epoch[11/500]   mean loss : 0.6927643   mean acc : 0.5134760: 100%|████████████████████| 94/94 [00:34<00:00,  2.74it/s]\n",
      "Epoch[12/500]   mean loss : 0.6926332   mean acc : 0.5154311: 100%|████████████████████| 94/94 [00:34<00:00,  2.70it/s]\n",
      "Epoch[13/500]   mean loss : 0.6926964   mean acc : 0.5125301: 100%|████████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[14/500]   mean loss : 0.6924971   mean acc : 0.5125736: 100%|████████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[15/500]   mean loss : 0.6918093   mean acc : 0.5170102: 100%|████████████████████| 94/94 [00:35<00:00,  2.68it/s]\n",
      "Epoch[16/500]   mean loss : 0.6922153   mean acc : 0.5209877: 100%|████████████████████| 94/94 [00:35<00:00,  2.67it/s]\n",
      "Epoch[17/500]   mean loss : 0.6930902   mean acc : 0.5077848: 100%|████████████████████| 94/94 [00:35<00:00,  2.63it/s]\n",
      "Epoch[18/500]   mean loss : 0.6928191   mean acc : 0.5069537: 100%|████████████████████| 94/94 [00:35<00:00,  2.68it/s]\n",
      "Epoch[19/500]   mean loss : 0.6921476   mean acc : 0.5176790: 100%|████████████████████| 94/94 [00:35<00:00,  2.68it/s]\n",
      "Epoch[20/500]   mean loss : 0.6921608   mean acc : 0.5108124: 100%|████████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[21/500]   mean loss : 0.6915888   mean acc : 0.5227409: 100%|████████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[22/500]   mean loss : 0.6909283   mean acc : 0.5320930: 100%|████████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[23/500]   mean loss : 0.6916176   mean acc : 0.5242330: 100%|████████████████████| 94/94 [00:35<00:00,  2.63it/s]\n",
      "Epoch[24/500]   mean loss : 0.6899650   mean acc : 0.5305495: 100%|████████████████████| 94/94 [00:35<00:00,  2.67it/s]\n",
      "Epoch[25/500]   mean loss : 0.6909493   mean acc : 0.5313450: 100%|████████████████████| 94/94 [00:35<00:00,  2.67it/s]\n",
      "Epoch[26/500]   mean loss : 0.6925370   mean acc : 0.5106106: 100%|████████████████████| 94/94 [00:35<00:00,  2.61it/s]\n",
      "Epoch[27/500]   mean loss : 0.6907776   mean acc : 0.5197489: 100%|████████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[28/500]   mean loss : 0.6910882   mean acc : 0.5246525: 100%|████████████████████| 94/94 [00:38<00:00,  2.46it/s]\n",
      "Epoch[29/500]   mean loss : 0.6893210   mean acc : 0.5339175: 100%|████████████████████| 94/94 [00:41<00:00,  2.28it/s]\n",
      "Epoch[30/500]   mean loss : 0.6920596   mean acc : 0.5175405: 100%|████████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[31/500]   mean loss : 0.6920176   mean acc : 0.5153361: 100%|████████████████████| 94/94 [00:35<00:00,  2.62it/s]\n",
      "Epoch[32/500]   mean loss : 0.6900310   mean acc : 0.5281036: 100%|████████████████████| 94/94 [00:35<00:00,  2.61it/s]\n",
      "Epoch[33/500]   mean loss : 0.6892592   mean acc : 0.5306761: 100%|████████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[34/500]   mean loss : 0.6908964   mean acc : 0.5256578: 100%|████████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[35/500]   mean loss : 0.6885350   mean acc : 0.5334624: 100%|████████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[36/500]   mean loss : 0.6881733   mean acc : 0.5374913: 100%|████████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[37/500]   mean loss : 0.6882754   mean acc : 0.5350415: 100%|████████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[38/500]   mean loss : 0.6873878   mean acc : 0.5393949: 100%|████████████████████| 94/94 [00:36<00:00,  2.54it/s]\n",
      "Epoch[39/500]   mean loss : 0.6874230   mean acc : 0.5367789: 100%|████████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[40/500]   mean loss : 0.6874642   mean acc : 0.5412353: 100%|████████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[41/500]   mean loss : 0.6866533   mean acc : 0.5391258: 100%|████████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[42/500]   mean loss : 0.6851238   mean acc : 0.5422049: 100%|████████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[43/500]   mean loss : 0.6840088   mean acc : 0.5454898: 100%|████████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[44/500]   mean loss : 0.6828110   mean acc : 0.5502549: 100%|████████████████████| 94/94 [00:35<00:00,  2.63it/s]\n",
      "Epoch[45/500]   mean loss : 0.6823921   mean acc : 0.5478803: 100%|████████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[46/500]   mean loss : 0.6821710   mean acc : 0.5495108: 100%|████████████████████| 94/94 [00:35<00:00,  2.62it/s]\n",
      "Epoch[47/500]   mean loss : 0.6812541   mean acc : 0.5527997: 100%|████████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[48/500]   mean loss : 0.6800974   mean acc : 0.5583602: 100%|████████████████████| 94/94 [00:35<00:00,  2.62it/s]\n",
      "Epoch[49/500]   mean loss : 0.6815147   mean acc : 0.5518300: 100%|████████████████████| 94/94 [00:36<00:00,  2.61it/s]\n",
      "Epoch[50/500]   mean loss : 0.6792969   mean acc : 0.5584434: 100%|████████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[51/500]   mean loss : 0.6771140   mean acc : 0.5606122: 100%|████████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[52/500]   mean loss : 0.6767412   mean acc : 0.5589183: 100%|████████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[53/500]   mean loss : 0.6776086   mean acc : 0.5652664: 100%|████████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[54/500]   mean loss : 0.6734241   mean acc : 0.5721687: 100%|████████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[55/500]   mean loss : 0.6754429   mean acc : 0.5672532: 100%|████████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[56/500]   mean loss : 0.6722088   mean acc : 0.5766171: 100%|████████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[57/500]   mean loss : 0.6736430   mean acc : 0.5770643: 100%|████████████████████| 94/94 [00:37<00:00,  2.53it/s]\n",
      "Epoch[58/500]   mean loss : 0.6723592   mean acc : 0.5724576: 100%|████████████████████| 94/94 [00:37<00:00,  2.53it/s]\n",
      "Epoch[59/500]   mean loss : 0.6700924   mean acc : 0.5793558: 100%|████████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[60/500]   mean loss : 0.6683551   mean acc : 0.5764430: 100%|████████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[61/500]   mean loss : 0.6652635   mean acc : 0.5846275: 100%|████████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[62/500]   mean loss : 0.6634182   mean acc : 0.5874058: 100%|████████████████████| 94/94 [00:37<00:00,  2.53it/s]\n",
      "Epoch[63/500]   mean loss : 0.6695163   mean acc : 0.5725367: 100%|████████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[64/500]   mean loss : 0.6671971   mean acc : 0.5788255: 100%|████████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[65/500]   mean loss : 0.6616957   mean acc : 0.5887475: 100%|████████████████████| 94/94 [00:37<00:00,  2.53it/s]\n",
      "Epoch[66/500]   mean loss : 0.6596063   mean acc : 0.5916603: 100%|████████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[67/500]   mean loss : 0.6559052   mean acc : 0.6046297: 100%|████████████████████| 94/94 [00:36<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[68/500]   mean loss : 0.6574719   mean acc : 0.5980639: 100%|████████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[69/500]   mean loss : 0.6567771   mean acc : 0.5967737: 100%|████████████████████| 94/94 [00:37<00:00,  2.51it/s]\n",
      "Epoch[70/500]   mean loss : 0.6538646   mean acc : 0.6025955: 100%|████████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[71/500]   mean loss : 0.6519352   mean acc : 0.6010955: 100%|████████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[72/500]   mean loss : 0.6518768   mean acc : 0.6023817: 100%|████████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[73/500]   mean loss : 0.6486421   mean acc : 0.6023065: 100%|████████████████████| 94/94 [00:35<00:00,  2.67it/s]\n",
      "Epoch[74/500]   mean loss : 0.6466603   mean acc : 0.6057537: 100%|████████████████████| 94/94 [00:35<00:00,  2.64it/s]\n",
      "Epoch[75/500]   mean loss : 0.6453840   mean acc : 0.6129330: 100%|████████████████████| 94/94 [00:35<00:00,  2.65it/s]\n",
      "Epoch[76/500]   mean loss : 0.6460321   mean acc : 0.6111955: 100%|████████████████████| 94/94 [00:35<00:00,  2.65it/s]\n",
      "Epoch[77/500]   mean loss : 0.6420825   mean acc : 0.6165938: 100%|████████████████████| 94/94 [00:35<00:00,  2.62it/s]\n",
      "Epoch[78/500]   mean loss : 0.6416261   mean acc : 0.6203457: 100%|████████████████████| 94/94 [00:35<00:00,  2.64it/s]\n",
      "Epoch[79/500]   mean loss : 0.6390944   mean acc : 0.6176783: 100%|████████████████████| 94/94 [00:35<00:00,  2.64it/s]\n",
      "Epoch[80/500]   mean loss : 0.6375167   mean acc : 0.6197640: 100%|████████████████████| 94/94 [00:35<00:00,  2.64it/s]\n",
      "Epoch[81/500]   mean loss : 0.6370582   mean acc : 0.6220040: 100%|████████████████████| 94/94 [00:35<00:00,  2.64it/s]\n",
      "Epoch[82/500]   mean loss : 0.6349207   mean acc : 0.6189249: 100%|████████████████████| 94/94 [00:35<00:00,  2.64it/s]\n",
      "Epoch[83/500]   mean loss : 0.6328325   mean acc : 0.6236663: 100%|████████████████████| 94/94 [00:35<00:00,  2.64it/s]\n",
      "Epoch[84/500]   mean loss : 0.6338203   mean acc : 0.6276042: 100%|████████████████████| 94/94 [00:35<00:00,  2.64it/s]\n",
      "Epoch[85/500]   mean loss : 0.6292425   mean acc : 0.6360855: 100%|████████████████████| 94/94 [00:35<00:00,  2.67it/s]\n",
      "Epoch[86/500]   mean loss : 0.6267026   mean acc : 0.6347597: 100%|████████████████████| 94/94 [00:35<00:00,  2.68it/s]\n",
      "Epoch[87/500]   mean loss : 0.6278034   mean acc : 0.6317202: 100%|████████████████████| 94/94 [00:35<00:00,  2.62it/s]\n",
      "Epoch[88/500]   mean loss : 0.6289316   mean acc : 0.6348903: 100%|████████████████████| 94/94 [00:35<00:00,  2.66it/s]\n",
      "Epoch[89/500]   mean loss : 0.6231854   mean acc : 0.6346410: 100%|████████████████████| 94/94 [00:35<00:00,  2.68it/s]\n",
      "Epoch[90/500]   mean loss : 0.6227289   mean acc : 0.6387095: 100%|████████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[91/500]   mean loss : 0.6216700   mean acc : 0.6415709: 100%|████████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[92/500]   mean loss : 0.6183496   mean acc : 0.6422872: 100%|████████████████████| 94/94 [00:37<00:00,  2.51it/s]\n",
      "Epoch[93/500]   mean loss : 0.6157463   mean acc : 0.6433281: 100%|████████████████████| 94/94 [00:39<00:00,  2.36it/s]\n",
      "Epoch[94/500]   mean loss : 0.6146035   mean acc : 0.6474402: 100%|████████████████████| 94/94 [00:40<00:00,  2.35it/s]\n",
      "Epoch[95/500]   mean loss : 0.6140516   mean acc : 0.6463201: 100%|████████████████████| 94/94 [00:39<00:00,  2.39it/s]\n",
      "Epoch[96/500]   mean loss : 0.6120506   mean acc : 0.6459481: 100%|████████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[97/500]   mean loss : 0.6115461   mean acc : 0.6466090: 100%|████████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[98/500]   mean loss : 0.6103021   mean acc : 0.6482713: 100%|████████████████████| 94/94 [00:37<00:00,  2.48it/s]\n",
      "Epoch[99/500]   mean loss : 0.6062069   mean acc : 0.6518451: 100%|████████████████████| 94/94 [00:37<00:00,  2.50it/s]\n",
      "Epoch[100/500]   mean loss : 0.6062355   mean acc : 0.6536379: 100%|███████████████████| 94/94 [00:38<00:00,  2.42it/s]\n",
      "Epoch[101/500]   mean loss : 0.6027221   mean acc : 0.6586563: 100%|███████████████████| 94/94 [00:37<00:00,  2.48it/s]\n",
      "Epoch[102/500]   mean loss : 0.6014664   mean acc : 0.6552131: 100%|███████████████████| 94/94 [00:39<00:00,  2.38it/s]\n",
      "Epoch[103/500]   mean loss : 0.5999411   mean acc : 0.6579914: 100%|███████████████████| 94/94 [00:37<00:00,  2.47it/s]\n",
      "Epoch[104/500]   mean loss : 0.5990493   mean acc : 0.6596615: 100%|███████████████████| 94/94 [00:38<00:00,  2.42it/s]\n",
      "Epoch[105/500]   mean loss : 0.5982641   mean acc : 0.6623963: 100%|███████████████████| 94/94 [00:39<00:00,  2.41it/s]\n",
      "Epoch[106/500]   mean loss : 0.5955449   mean acc : 0.6650994: 100%|███████████████████| 94/94 [00:38<00:00,  2.45it/s]\n",
      "Epoch[107/500]   mean loss : 0.5910839   mean acc : 0.6632274: 100%|███████████████████| 94/94 [00:38<00:00,  2.46it/s]\n",
      "Epoch[108/500]   mean loss : 0.5909662   mean acc : 0.6639359: 100%|███████████████████| 94/94 [00:38<00:00,  2.45it/s]\n",
      "Epoch[109/500]   mean loss : 0.5895869   mean acc : 0.6685545: 100%|███████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[110/500]   mean loss : 0.5863562   mean acc : 0.6743644: 100%|███████████████████| 94/94 [00:38<00:00,  2.47it/s]\n",
      "Epoch[111/500]   mean loss : 0.5882536   mean acc : 0.6646047: 100%|███████████████████| 94/94 [00:38<00:00,  2.44it/s]\n",
      "Epoch[112/500]   mean loss : 0.5837719   mean acc : 0.6705848: 100%|███████████████████| 94/94 [00:37<00:00,  2.49it/s]\n",
      "Epoch[113/500]   mean loss : 0.5828338   mean acc : 0.6749976: 100%|███████████████████| 94/94 [00:37<00:00,  2.49it/s]\n",
      "Epoch[114/500]   mean loss : 0.5800068   mean acc : 0.6745781: 100%|███████████████████| 94/94 [00:39<00:00,  2.38it/s]\n",
      "Epoch[115/500]   mean loss : 0.5811832   mean acc : 0.6698803: 100%|███████████████████| 94/94 [00:39<00:00,  2.40it/s]\n",
      "Epoch[116/500]   mean loss : 0.5780166   mean acc : 0.6772298: 100%|███████████████████| 94/94 [00:38<00:00,  2.46it/s]\n",
      "Epoch[117/500]   mean loss : 0.5768982   mean acc : 0.6738657: 100%|███████████████████| 94/94 [00:38<00:00,  2.47it/s]\n",
      "Epoch[118/500]   mean loss : 0.5713389   mean acc : 0.6827626: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[119/500]   mean loss : 0.5729201   mean acc : 0.6761533: 100%|███████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[120/500]   mean loss : 0.5724444   mean acc : 0.6771071: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[121/500]   mean loss : 0.5716126   mean acc : 0.6803049: 100%|███████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[122/500]   mean loss : 0.5672165   mean acc : 0.6831347: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[123/500]   mean loss : 0.5675226   mean acc : 0.6835542: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[124/500]   mean loss : 0.5642138   mean acc : 0.6888377: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[125/500]   mean loss : 0.5644901   mean acc : 0.6872467: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[126/500]   mean loss : 0.5575664   mean acc : 0.6867520: 100%|███████████████████| 94/94 [00:37<00:00,  2.49it/s]\n",
      "Epoch[127/500]   mean loss : 0.5575834   mean acc : 0.6904960: 100%|███████████████████| 94/94 [00:39<00:00,  2.38it/s]\n",
      "Epoch[128/500]   mean loss : 0.5579057   mean acc : 0.6890910: 100%|███████████████████| 94/94 [00:37<00:00,  2.47it/s]\n",
      "Epoch[129/500]   mean loss : 0.5568195   mean acc : 0.6925619: 100%|███████████████████| 94/94 [00:38<00:00,  2.45it/s]\n",
      "Epoch[130/500]   mean loss : 0.5549814   mean acc : 0.6958468: 100%|███████████████████| 94/94 [00:38<00:00,  2.47it/s]\n",
      "Epoch[131/500]   mean loss : 0.5538107   mean acc : 0.6927360: 100%|███████████████████| 94/94 [00:37<00:00,  2.50it/s]\n",
      "Epoch[132/500]   mean loss : 0.5540247   mean acc : 0.6915329: 100%|███████████████████| 94/94 [00:38<00:00,  2.47it/s]\n",
      "Epoch[133/500]   mean loss : 0.5513660   mean acc : 0.6949801: 100%|███████████████████| 94/94 [00:37<00:00,  2.51it/s]\n",
      "Epoch[134/500]   mean loss : 0.5559972   mean acc : 0.6928587: 100%|███████████████████| 94/94 [00:37<00:00,  2.49it/s]\n",
      "Epoch[135/500]   mean loss : 0.5465447   mean acc : 0.6956845: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[136/500]   mean loss : 0.5438196   mean acc : 0.7027530: 100%|███████████████████| 94/94 [00:36<00:00,  2.61it/s]\n",
      "Epoch[137/500]   mean loss : 0.5411794   mean acc : 0.7024957: 100%|███████████████████| 94/94 [00:36<00:00,  2.61it/s]\n",
      "Epoch[138/500]   mean loss : 0.5430478   mean acc : 0.6986409: 100%|███████████████████| 94/94 [00:35<00:00,  2.62it/s]\n",
      "Epoch[139/500]   mean loss : 0.5431919   mean acc : 0.7017992: 100%|███████████████████| 94/94 [00:35<00:00,  2.63it/s]\n",
      "Epoch[140/500]   mean loss : 0.5395853   mean acc : 0.7041580: 100%|███████████████████| 94/94 [00:35<00:00,  2.63it/s]\n",
      "Epoch[141/500]   mean loss : 0.5374361   mean acc : 0.7037899: 100%|███████████████████| 94/94 [00:35<00:00,  2.63it/s]\n",
      "Epoch[142/500]   mean loss : 0.5375249   mean acc : 0.7019139: 100%|███████████████████| 94/94 [00:36<00:00,  2.61it/s]\n",
      "Epoch[143/500]   mean loss : 0.5317895   mean acc : 0.7103557: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[144/500]   mean loss : 0.5316780   mean acc : 0.7106921: 100%|███████████████████| 94/94 [00:36<00:00,  2.61it/s]\n",
      "Epoch[145/500]   mean loss : 0.5262768   mean acc : 0.7152197: 100%|███████████████████| 94/94 [00:36<00:00,  2.61it/s]\n",
      "Epoch[146/500]   mean loss : 0.5288642   mean acc : 0.7155126: 100%|███████████████████| 94/94 [00:36<00:00,  2.61it/s]\n",
      "Epoch[147/500]   mean loss : 0.5291139   mean acc : 0.7178437: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[148/500]   mean loss : 0.5233955   mean acc : 0.7187144: 100%|███████████████████| 94/94 [00:36<00:00,  2.61it/s]\n",
      "Epoch[149/500]   mean loss : 0.5221693   mean acc : 0.7163398: 100%|███████████████████| 94/94 [00:35<00:00,  2.61it/s]\n",
      "Epoch[150/500]   mean loss : 0.5229607   mean acc : 0.7163002: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[151/500]   mean loss : 0.5195890   mean acc : 0.7168028: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[152/500]   mean loss : 0.5140288   mean acc : 0.7218726: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[153/500]   mean loss : 0.5184329   mean acc : 0.7202539: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[154/500]   mean loss : 0.5098453   mean acc : 0.7218805: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[155/500]   mean loss : 0.5141018   mean acc : 0.7256522: 100%|███████████████████| 94/94 [00:36<00:00,  2.61it/s]\n",
      "Epoch[156/500]   mean loss : 0.5121638   mean acc : 0.7282247: 100%|███████████████████| 94/94 [00:35<00:00,  2.64it/s]\n",
      "Epoch[157/500]   mean loss : 0.5087197   mean acc : 0.7246628: 100%|███████████████████| 94/94 [00:35<00:00,  2.64it/s]\n",
      "Epoch[158/500]   mean loss : 0.5116177   mean acc : 0.7229570: 100%|███████████████████| 94/94 [00:35<00:00,  2.64it/s]\n",
      "Epoch[159/500]   mean loss : 0.5066053   mean acc : 0.7261549: 100%|███████████████████| 94/94 [00:35<00:00,  2.63it/s]\n",
      "Epoch[160/500]   mean loss : 0.5022567   mean acc : 0.7269860: 100%|███████████████████| 94/94 [00:35<00:00,  2.64it/s]\n",
      "Epoch[161/500]   mean loss : 0.5049703   mean acc : 0.7268989: 100%|███████████████████| 94/94 [00:35<00:00,  2.64it/s]\n",
      "Epoch[162/500]   mean loss : 0.5046833   mean acc : 0.7271007: 100%|███████████████████| 94/94 [00:35<00:00,  2.63it/s]\n",
      "Epoch[163/500]   mean loss : 0.5011988   mean acc : 0.7328038: 100%|███████████████████| 94/94 [00:35<00:00,  2.63it/s]\n",
      "Epoch[164/500]   mean loss : 0.4960148   mean acc : 0.7374620: 100%|███████████████████| 94/94 [00:35<00:00,  2.63it/s]\n",
      "Epoch[165/500]   mean loss : 0.5014544   mean acc : 0.7283197: 100%|███████████████████| 94/94 [00:35<00:00,  2.63it/s]\n",
      "Epoch[166/500]   mean loss : 0.4931752   mean acc : 0.7357167: 100%|███████████████████| 94/94 [00:35<00:00,  2.63it/s]\n",
      "Epoch[167/500]   mean loss : 0.4953646   mean acc : 0.7379211: 100%|███████████████████| 94/94 [00:35<00:00,  2.63it/s]\n",
      "Epoch[168/500]   mean loss : 0.4917939   mean acc : 0.7360095: 100%|███████████████████| 94/94 [00:35<00:00,  2.63it/s]\n",
      "Epoch[169/500]   mean loss : 0.4921236   mean acc : 0.7420767: 100%|███████████████████| 94/94 [00:35<00:00,  2.63it/s]\n",
      "Epoch[170/500]   mean loss : 0.4871606   mean acc : 0.7426941: 100%|███████████████████| 94/94 [00:35<00:00,  2.63it/s]\n",
      "Epoch[171/500]   mean loss : 0.4926763   mean acc : 0.7358789: 100%|███████████████████| 94/94 [00:35<00:00,  2.63it/s]\n",
      "Epoch[172/500]   mean loss : 0.4824731   mean acc : 0.7441466: 100%|███████████████████| 94/94 [00:35<00:00,  2.62it/s]\n",
      "Epoch[173/500]   mean loss : 0.4832941   mean acc : 0.7406084: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[174/500]   mean loss : 0.4847626   mean acc : 0.7392865: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[175/500]   mean loss : 0.4802106   mean acc : 0.7438220: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[176/500]   mean loss : 0.4811884   mean acc : 0.7455199: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[177/500]   mean loss : 0.4758667   mean acc : 0.7472692: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[178/500]   mean loss : 0.4755605   mean acc : 0.7472731: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[179/500]   mean loss : 0.4711715   mean acc : 0.7547492: 100%|███████████████████| 94/94 [00:40<00:00,  2.33it/s]\n",
      "Epoch[180/500]   mean loss : 0.4772959   mean acc : 0.7501781: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[181/500]   mean loss : 0.4767322   mean acc : 0.7456544: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[182/500]   mean loss : 0.4750939   mean acc : 0.7502612: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[183/500]   mean loss : 0.4704722   mean acc : 0.7544168: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[184/500]   mean loss : 0.4724239   mean acc : 0.7492639: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[185/500]   mean loss : 0.4687881   mean acc : 0.7536727: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[186/500]   mean loss : 0.4625279   mean acc : 0.7549234: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[187/500]   mean loss : 0.4636212   mean acc : 0.7573297: 100%|███████████████████| 94/94 [00:37<00:00,  2.49it/s]\n",
      "Epoch[188/500]   mean loss : 0.4665840   mean acc : 0.7569062: 100%|███████████████████| 94/94 [00:37<00:00,  2.51it/s]\n",
      "Epoch[189/500]   mean loss : 0.4545888   mean acc : 0.7648968: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[190/500]   mean loss : 0.4604474   mean acc : 0.7590236: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[191/500]   mean loss : 0.4636442   mean acc : 0.7574603: 100%|███████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[192/500]   mean loss : 0.4521129   mean acc : 0.7647622: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[193/500]   mean loss : 0.4506976   mean acc : 0.7646079: 100%|███████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[194/500]   mean loss : 0.4510565   mean acc : 0.7661435: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[195/500]   mean loss : 0.4504547   mean acc : 0.7660999: 100%|███████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[196/500]   mean loss : 0.4532163   mean acc : 0.7647701: 100%|███████████████████| 94/94 [00:36<00:00,  2.54it/s]\n",
      "Epoch[197/500]   mean loss : 0.4512169   mean acc : 0.7647345: 100%|███████████████████| 94/94 [00:37<00:00,  2.50it/s]\n",
      "Epoch[198/500]   mean loss : 0.4461482   mean acc : 0.7643942: 100%|███████████████████| 94/94 [00:38<00:00,  2.47it/s]\n",
      "Epoch[199/500]   mean loss : 0.4418258   mean acc : 0.7738214: 100%|███████████████████| 94/94 [00:38<00:00,  2.46it/s]\n",
      "Epoch[200/500]   mean loss : 0.4418318   mean acc : 0.7739203: 100%|███████████████████| 94/94 [00:38<00:00,  2.45it/s]\n",
      "Epoch[201/500]   mean loss : 0.4429991   mean acc : 0.7710035: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[202/500]   mean loss : 0.4437797   mean acc : 0.7713835: 100%|███████████████████| 94/94 [00:37<00:00,  2.53it/s]\n",
      "Epoch[203/500]   mean loss : 0.4401023   mean acc : 0.7772804: 100%|███████████████████| 94/94 [00:37<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[204/500]   mean loss : 0.4462168   mean acc : 0.7702159: 100%|███████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[205/500]   mean loss : 0.4404943   mean acc : 0.7757013: 100%|███████████████████| 94/94 [00:37<00:00,  2.53it/s]\n",
      "Epoch[206/500]   mean loss : 0.4386292   mean acc : 0.7744546: 100%|███████████████████| 94/94 [00:36<00:00,  2.54it/s]\n",
      "Epoch[207/500]   mean loss : 0.4341259   mean acc : 0.7797302: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[208/500]   mean loss : 0.4312088   mean acc : 0.7771063: 100%|███████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[209/500]   mean loss : 0.4298224   mean acc : 0.7816379: 100%|███████████████████| 94/94 [00:37<00:00,  2.50it/s]\n",
      "Epoch[210/500]   mean loss : 0.4349422   mean acc : 0.7762039: 100%|███████████████████| 94/94 [00:37<00:00,  2.51it/s]\n",
      "Epoch[211/500]   mean loss : 0.4325761   mean acc : 0.7789070: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[212/500]   mean loss : 0.4277103   mean acc : 0.7796511: 100%|███████████████████| 94/94 [00:36<00:00,  2.54it/s]\n",
      "Epoch[213/500]   mean loss : 0.4320065   mean acc : 0.7798608: 100%|███████████████████| 94/94 [00:37<00:00,  2.53it/s]\n",
      "Epoch[214/500]   mean loss : 0.4256663   mean acc : 0.7820178: 100%|███████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[215/500]   mean loss : 0.4211278   mean acc : 0.7869293: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[216/500]   mean loss : 0.4258231   mean acc : 0.7826866: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[217/500]   mean loss : 0.4154954   mean acc : 0.7894939: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[218/500]   mean loss : 0.4240533   mean acc : 0.7846774: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[219/500]   mean loss : 0.4239782   mean acc : 0.7863040: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[220/500]   mean loss : 0.4176210   mean acc : 0.7861734: 100%|███████████████████| 94/94 [00:39<00:00,  2.38it/s]\n",
      "Epoch[221/500]   mean loss : 0.4136879   mean acc : 0.7915004: 100%|███████████████████| 94/94 [00:38<00:00,  2.43it/s]\n",
      "Epoch[222/500]   mean loss : 0.4156832   mean acc : 0.7902894: 100%|███████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[223/500]   mean loss : 0.4160547   mean acc : 0.7924938: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[224/500]   mean loss : 0.4175555   mean acc : 0.7870916: 100%|███████████████████| 94/94 [00:37<00:00,  2.53it/s]\n",
      "Epoch[225/500]   mean loss : 0.4111025   mean acc : 0.7927867: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[226/500]   mean loss : 0.4163974   mean acc : 0.7874201: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[227/500]   mean loss : 0.4024845   mean acc : 0.8001836: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[228/500]   mean loss : 0.4119158   mean acc : 0.7919912: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[229/500]   mean loss : 0.4048846   mean acc : 0.7968987: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[230/500]   mean loss : 0.4114118   mean acc : 0.7904556: 100%|███████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[231/500]   mean loss : 0.4064944   mean acc : 0.7933962: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[232/500]   mean loss : 0.4132091   mean acc : 0.7897116: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[233/500]   mean loss : 0.4019542   mean acc : 0.7973539: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[234/500]   mean loss : 0.4045608   mean acc : 0.7956402: 100%|███████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[235/500]   mean loss : 0.4071286   mean acc : 0.7963961: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[236/500]   mean loss : 0.3994768   mean acc : 0.8009237: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[237/500]   mean loss : 0.4025946   mean acc : 0.7989726: 100%|███████████████████| 94/94 [00:36<00:00,  2.61it/s]\n",
      "Epoch[238/500]   mean loss : 0.4048199   mean acc : 0.7962734: 100%|███████████████████| 94/94 [00:36<00:00,  2.61it/s]\n",
      "Epoch[239/500]   mean loss : 0.4003906   mean acc : 0.7996731: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[240/500]   mean loss : 0.3999825   mean acc : 0.7973935: 100%|███████████████████| 94/94 [00:39<00:00,  2.38it/s]\n",
      "Epoch[241/500]   mean loss : 0.3992851   mean acc : 0.8036268: 100%|███████████████████| 94/94 [00:37<00:00,  2.48it/s]\n",
      "Epoch[242/500]   mean loss : 0.3983988   mean acc : 0.8011374: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[243/500]   mean loss : 0.3935754   mean acc : 0.8005557: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[244/500]   mean loss : 0.3946868   mean acc : 0.8069553: 100%|███████████████████| 94/94 [00:36<00:00,  2.61it/s]\n",
      "Epoch[245/500]   mean loss : 0.3932543   mean acc : 0.8001282: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[246/500]   mean loss : 0.3968609   mean acc : 0.8045015: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[247/500]   mean loss : 0.4032452   mean acc : 0.7974370: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[248/500]   mean loss : 0.3919697   mean acc : 0.8018815: 100%|███████████████████| 94/94 [00:39<00:00,  2.35it/s]\n",
      "Epoch[249/500]   mean loss : 0.3916353   mean acc : 0.8005082: 100%|███████████████████| 94/94 [00:37<00:00,  2.51it/s]\n",
      "Epoch[250/500]   mean loss : 0.3872276   mean acc : 0.8068247: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[251/500]   mean loss : 0.3932394   mean acc : 0.8033340: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[252/500]   mean loss : 0.3865321   mean acc : 0.8067020: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[253/500]   mean loss : 0.3841707   mean acc : 0.8093655: 100%|███████████████████| 94/94 [00:37<00:00,  2.53it/s]\n",
      "Epoch[254/500]   mean loss : 0.3850301   mean acc : 0.8128918: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[255/500]   mean loss : 0.3805668   mean acc : 0.8151754: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[256/500]   mean loss : 0.3857231   mean acc : 0.8097811: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[257/500]   mean loss : 0.3835174   mean acc : 0.8122309: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[258/500]   mean loss : 0.3829217   mean acc : 0.8131491: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[259/500]   mean loss : 0.3830871   mean acc : 0.8105291: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[260/500]   mean loss : 0.3787923   mean acc : 0.8166358: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[261/500]   mean loss : 0.3788558   mean acc : 0.8122784: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[262/500]   mean loss : 0.3811860   mean acc : 0.8112296: 100%|███████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[263/500]   mean loss : 0.3844910   mean acc : 0.8063774: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[264/500]   mean loss : 0.3730948   mean acc : 0.8181753: 100%|███████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[265/500]   mean loss : 0.3788993   mean acc : 0.8134340: 100%|███████████████████| 94/94 [00:37<00:00,  2.53it/s]\n",
      "Epoch[266/500]   mean loss : 0.3696097   mean acc : 0.8157255: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[267/500]   mean loss : 0.3707521   mean acc : 0.8168772: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[268/500]   mean loss : 0.3668545   mean acc : 0.8207914: 100%|███████████████████| 94/94 [00:37<00:00,  2.51it/s]\n",
      "Epoch[269/500]   mean loss : 0.3675250   mean acc : 0.8184682: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[270/500]   mean loss : 0.3632545   mean acc : 0.8235776: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[271/500]   mean loss : 0.3664415   mean acc : 0.8184247: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[272/500]   mean loss : 0.3659332   mean acc : 0.8195526: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[273/500]   mean loss : 0.3643073   mean acc : 0.8223270: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[274/500]   mean loss : 0.3668053   mean acc : 0.8218679: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[275/500]   mean loss : 0.3663477   mean acc : 0.8177162: 100%|███████████████████| 94/94 [00:37<00:00,  2.50it/s]\n",
      "Epoch[276/500]   mean loss : 0.3637775   mean acc : 0.8213375: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[277/500]   mean loss : 0.3631153   mean acc : 0.8216265: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[278/500]   mean loss : 0.3624223   mean acc : 0.8222082: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[279/500]   mean loss : 0.3606522   mean acc : 0.8191331: 100%|███████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[280/500]   mean loss : 0.3633686   mean acc : 0.8227465: 100%|███████████████████| 94/94 [00:37<00:00,  2.53it/s]\n",
      "Epoch[281/500]   mean loss : 0.3623744   mean acc : 0.8208389: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[282/500]   mean loss : 0.3570433   mean acc : 0.8224101: 100%|███████████████████| 94/94 [00:39<00:00,  2.36it/s]\n",
      "Epoch[283/500]   mean loss : 0.3610922   mean acc : 0.8229602: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[284/500]   mean loss : 0.3552458   mean acc : 0.8267042: 100%|███████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[285/500]   mean loss : 0.3584709   mean acc : 0.8205460: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[286/500]   mean loss : 0.3504002   mean acc : 0.8291065: 100%|███████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[287/500]   mean loss : 0.3561176   mean acc : 0.8263955: 100%|███████████████████| 94/94 [00:37<00:00,  2.51it/s]\n",
      "Epoch[288/500]   mean loss : 0.3421190   mean acc : 0.8340497: 100%|███████████████████| 94/94 [00:37<00:00,  2.53it/s]\n",
      "Epoch[289/500]   mean loss : 0.3528382   mean acc : 0.8264430: 100%|███████████████████| 94/94 [00:37<00:00,  2.49it/s]\n",
      "Epoch[290/500]   mean loss : 0.3471050   mean acc : 0.8287305: 100%|███████████████████| 94/94 [00:37<00:00,  2.49it/s]\n",
      "Epoch[291/500]   mean loss : 0.3467203   mean acc : 0.8289363: 100%|███████████████████| 94/94 [00:37<00:00,  2.50it/s]\n",
      "Epoch[292/500]   mean loss : 0.3506857   mean acc : 0.8262332: 100%|███████████████████| 94/94 [00:37<00:00,  2.50it/s]\n",
      "Epoch[293/500]   mean loss : 0.3492212   mean acc : 0.8305155: 100%|███████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[294/500]   mean loss : 0.3470993   mean acc : 0.8335114: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[295/500]   mean loss : 0.3486008   mean acc : 0.8294746: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[296/500]   mean loss : 0.3407024   mean acc : 0.8363808: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[297/500]   mean loss : 0.3450263   mean acc : 0.8275630: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[298/500]   mean loss : 0.3387071   mean acc : 0.8345879: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[299/500]   mean loss : 0.3357217   mean acc : 0.8362937: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[300/500]   mean loss : 0.3296133   mean acc : 0.8411221: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[301/500]   mean loss : 0.3353550   mean acc : 0.8355892: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[302/500]   mean loss : 0.3314925   mean acc : 0.8381222: 100%|███████████████████| 94/94 [00:36<00:00,  2.54it/s]\n",
      "Epoch[303/500]   mean loss : 0.3360244   mean acc : 0.8359177: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[304/500]   mean loss : 0.3351191   mean acc : 0.8370377: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[305/500]   mean loss : 0.3272837   mean acc : 0.8405324: 100%|███████████████████| 94/94 [00:40<00:00,  2.34it/s]\n",
      "Epoch[306/500]   mean loss : 0.3288182   mean acc : 0.8420284: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[307/500]   mean loss : 0.3240811   mean acc : 0.8440231: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[308/500]   mean loss : 0.3271323   mean acc : 0.8431959: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[309/500]   mean loss : 0.3306326   mean acc : 0.8408609: 100%|███████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[310/500]   mean loss : 0.3190633   mean acc : 0.8479768: 100%|███████████████████| 94/94 [00:36<00:00,  2.54it/s]\n",
      "Epoch[311/500]   mean loss : 0.3174263   mean acc : 0.8488119: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[312/500]   mean loss : 0.3238932   mean acc : 0.8430693: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[313/500]   mean loss : 0.3296545   mean acc : 0.8417830: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[314/500]   mean loss : 0.3250677   mean acc : 0.8433582: 100%|███████████████████| 94/94 [00:37<00:00,  2.51it/s]\n",
      "Epoch[315/500]   mean loss : 0.3192453   mean acc : 0.8519227: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[316/500]   mean loss : 0.3187950   mean acc : 0.8491404: 100%|███████████████████| 94/94 [00:36<00:00,  2.54it/s]\n",
      "Epoch[317/500]   mean loss : 0.3128041   mean acc : 0.8527459: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[318/500]   mean loss : 0.3202687   mean acc : 0.8489346: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[319/500]   mean loss : 0.3215462   mean acc : 0.8473515: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[320/500]   mean loss : 0.3249878   mean acc : 0.8404493: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[321/500]   mean loss : 0.3265703   mean acc : 0.8382488: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[322/500]   mean loss : 0.3164597   mean acc : 0.8507116: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[323/500]   mean loss : 0.3132487   mean acc : 0.8508857: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[324/500]   mean loss : 0.3180664   mean acc : 0.8444386: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[325/500]   mean loss : 0.3093852   mean acc : 0.8572022: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[326/500]   mean loss : 0.3154439   mean acc : 0.8498686: 100%|███████████████████| 94/94 [00:37<00:00,  2.51it/s]\n",
      "Epoch[327/500]   mean loss : 0.3133385   mean acc : 0.8478462: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[328/500]   mean loss : 0.3165620   mean acc : 0.8488911: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[329/500]   mean loss : 0.3069557   mean acc : 0.8557418: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[330/500]   mean loss : 0.3121318   mean acc : 0.8522155: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[331/500]   mean loss : 0.3020466   mean acc : 0.8589911: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[332/500]   mean loss : 0.3024938   mean acc : 0.8606533: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[333/500]   mean loss : 0.3024407   mean acc : 0.8577484: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[334/500]   mean loss : 0.3042030   mean acc : 0.8529556: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[335/500]   mean loss : 0.3059754   mean acc : 0.8551640: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[336/500]   mean loss : 0.3025329   mean acc : 0.8589476: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[337/500]   mean loss : 0.3036858   mean acc : 0.8557458: 100%|███████████████████| 94/94 [00:38<00:00,  2.47it/s]\n",
      "Epoch[338/500]   mean loss : 0.2985353   mean acc : 0.8583223: 100%|███████████████████| 94/94 [00:35<00:00,  2.63it/s]\n",
      "Epoch[339/500]   mean loss : 0.2950478   mean acc : 0.8598143: 100%|███████████████████| 94/94 [00:36<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[340/500]   mean loss : 0.2963625   mean acc : 0.8580769: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[341/500]   mean loss : 0.2976076   mean acc : 0.8611441: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[342/500]   mean loss : 0.3006484   mean acc : 0.8609383: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[343/500]   mean loss : 0.3001036   mean acc : 0.8600241: 100%|███████████████████| 94/94 [00:36<00:00,  2.61it/s]\n",
      "Epoch[344/500]   mean loss : 0.2917108   mean acc : 0.8635543: 100%|███████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[345/500]   mean loss : 0.2847843   mean acc : 0.8667165: 100%|███████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[346/500]   mean loss : 0.2982540   mean acc : 0.8577365: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[347/500]   mean loss : 0.2927684   mean acc : 0.8643538: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[348/500]   mean loss : 0.2860763   mean acc : 0.8654224: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[349/500]   mean loss : 0.2964078   mean acc : 0.8611480: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[350/500]   mean loss : 0.2949940   mean acc : 0.8636058: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[351/500]   mean loss : 0.2870300   mean acc : 0.8640174: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[352/500]   mean loss : 0.2912945   mean acc : 0.8636414: 100%|███████████████████| 94/94 [00:35<00:00,  2.62it/s]\n",
      "Epoch[353/500]   mean loss : 0.2810358   mean acc : 0.8670965: 100%|███████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[354/500]   mean loss : 0.2816335   mean acc : 0.8675437: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[355/500]   mean loss : 0.2708705   mean acc : 0.8743232: 100%|███████████████████| 94/94 [00:35<00:00,  2.62it/s]\n",
      "Epoch[356/500]   mean loss : 0.2737894   mean acc : 0.8670806: 100%|███████████████████| 94/94 [00:35<00:00,  2.61it/s]\n",
      "Epoch[357/500]   mean loss : 0.2767121   mean acc : 0.8712006: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[358/500]   mean loss : 0.2806680   mean acc : 0.8717032: 100%|███████████████████| 94/94 [00:35<00:00,  2.61it/s]\n",
      "Epoch[359/500]   mean loss : 0.2930008   mean acc : 0.8607246: 100%|███████████████████| 94/94 [00:35<00:00,  2.62it/s]\n",
      "Epoch[360/500]   mean loss : 0.2788884   mean acc : 0.8687508: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[361/500]   mean loss : 0.2797599   mean acc : 0.8724077: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[362/500]   mean loss : 0.2716725   mean acc : 0.8761913: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[363/500]   mean loss : 0.2719345   mean acc : 0.8717389: 100%|███████████████████| 94/94 [00:37<00:00,  2.50it/s]\n",
      "Epoch[364/500]   mean loss : 0.2723413   mean acc : 0.8740660: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[365/500]   mean loss : 0.2720996   mean acc : 0.8771095: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[366/500]   mean loss : 0.2679465   mean acc : 0.8759776: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[367/500]   mean loss : 0.2710576   mean acc : 0.8731992: 100%|███████████████████| 94/94 [00:36<00:00,  2.54it/s]\n",
      "Epoch[368/500]   mean loss : 0.2722763   mean acc : 0.8736148: 100%|███████████████████| 94/94 [00:37<00:00,  2.53it/s]\n",
      "Epoch[369/500]   mean loss : 0.2703414   mean acc : 0.8741570: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[370/500]   mean loss : 0.2612158   mean acc : 0.8787202: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[371/500]   mean loss : 0.2633109   mean acc : 0.8785619: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[372/500]   mean loss : 0.2639085   mean acc : 0.8787242: 100%|███████████████████| 94/94 [00:37<00:00,  2.53it/s]\n",
      "Epoch[373/500]   mean loss : 0.2609283   mean acc : 0.8788904: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[374/500]   mean loss : 0.2631866   mean acc : 0.8776437: 100%|███████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[375/500]   mean loss : 0.2633871   mean acc : 0.8787677: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[376/500]   mean loss : 0.2705737   mean acc : 0.8753958: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[377/500]   mean loss : 0.2620383   mean acc : 0.8782611: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[378/500]   mean loss : 0.2598947   mean acc : 0.8790527: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[379/500]   mean loss : 0.2506199   mean acc : 0.8873639: 100%|███████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[380/500]   mean loss : 0.2591548   mean acc : 0.8803033: 100%|███████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[381/500]   mean loss : 0.2615571   mean acc : 0.8751900: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[382/500]   mean loss : 0.2598794   mean acc : 0.8799313: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[383/500]   mean loss : 0.2527933   mean acc : 0.8849497: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[384/500]   mean loss : 0.2580840   mean acc : 0.8817993: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[385/500]   mean loss : 0.2587615   mean acc : 0.8794366: 100%|███████████████████| 94/94 [00:36<00:00,  2.54it/s]\n",
      "Epoch[386/500]   mean loss : 0.2556312   mean acc : 0.8839642: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[387/500]   mean loss : 0.2566604   mean acc : 0.8825869: 100%|███████████████████| 94/94 [00:35<00:00,  2.64it/s]\n",
      "Epoch[388/500]   mean loss : 0.2468247   mean acc : 0.8897385: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[389/500]   mean loss : 0.2489391   mean acc : 0.8868731: 100%|███████████████████| 94/94 [00:38<00:00,  2.44it/s]\n",
      "Epoch[390/500]   mean loss : 0.2542899   mean acc : 0.8864892: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[391/500]   mean loss : 0.2623280   mean acc : 0.8818824: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[392/500]   mean loss : 0.2491884   mean acc : 0.8872451: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[393/500]   mean loss : 0.2522226   mean acc : 0.8866158: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[394/500]   mean loss : 0.2499957   mean acc : 0.8862834: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[395/500]   mean loss : 0.2515580   mean acc : 0.8864932: 100%|███████████████████| 94/94 [00:40<00:00,  2.29it/s]\n",
      "Epoch[396/500]   mean loss : 0.2429589   mean acc : 0.8886145: 100%|███████████████████| 94/94 [00:38<00:00,  2.47it/s]\n",
      "Epoch[397/500]   mean loss : 0.2466003   mean acc : 0.8854958: 100%|███████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[398/500]   mean loss : 0.2447987   mean acc : 0.8901936: 100%|███████████████████| 94/94 [00:37<00:00,  2.53it/s]\n",
      "Epoch[399/500]   mean loss : 0.2372280   mean acc : 0.8946421: 100%|███████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[400/500]   mean loss : 0.2418182   mean acc : 0.8889905: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[401/500]   mean loss : 0.2328503   mean acc : 0.8924416: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[402/500]   mean loss : 0.2388872   mean acc : 0.8925524: 100%|███████████████████| 94/94 [00:35<00:00,  2.62it/s]\n",
      "Epoch[403/500]   mean loss : 0.2388158   mean acc : 0.8940247: 100%|███████████████████| 94/94 [00:35<00:00,  2.62it/s]\n",
      "Epoch[404/500]   mean loss : 0.2447968   mean acc : 0.8899482: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[405/500]   mean loss : 0.2361725   mean acc : 0.8920300: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[406/500]   mean loss : 0.2378933   mean acc : 0.8912741: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[407/500]   mean loss : 0.2366321   mean acc : 0.8949745: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[408/500]   mean loss : 0.2374415   mean acc : 0.8944758: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[409/500]   mean loss : 0.2395293   mean acc : 0.8932331: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[410/500]   mean loss : 0.2290406   mean acc : 0.8972937: 100%|███████████████████| 94/94 [00:38<00:00,  2.46it/s]\n",
      "Epoch[411/500]   mean loss : 0.2366467   mean acc : 0.8958927: 100%|███████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[412/500]   mean loss : 0.2423599   mean acc : 0.8897345: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[413/500]   mean loss : 0.2222047   mean acc : 0.9005430: 100%|███████████████████| 94/94 [00:35<00:00,  2.65it/s]\n",
      "Epoch[414/500]   mean loss : 0.2329622   mean acc : 0.8951803: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[415/500]   mean loss : 0.2244153   mean acc : 0.8993399: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[416/500]   mean loss : 0.2224168   mean acc : 0.9002026: 100%|███████████████████| 94/94 [00:35<00:00,  2.64it/s]\n",
      "Epoch[417/500]   mean loss : 0.2254794   mean acc : 0.8989243: 100%|███████████████████| 94/94 [00:36<00:00,  2.54it/s]\n",
      "Epoch[418/500]   mean loss : 0.2230840   mean acc : 0.9001274: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[419/500]   mean loss : 0.2242529   mean acc : 0.9003332: 100%|███████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[420/500]   mean loss : 0.2371160   mean acc : 0.8921052: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[421/500]   mean loss : 0.2274849   mean acc : 0.8975549: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[422/500]   mean loss : 0.2237767   mean acc : 0.8994586: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[423/500]   mean loss : 0.2213130   mean acc : 0.8981763: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[424/500]   mean loss : 0.2157829   mean acc : 0.9034559: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[425/500]   mean loss : 0.2141518   mean acc : 0.9045759: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[426/500]   mean loss : 0.2143245   mean acc : 0.9023754: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[427/500]   mean loss : 0.2173794   mean acc : 0.9020825: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[428/500]   mean loss : 0.2193964   mean acc : 0.9031590: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[429/500]   mean loss : 0.2073590   mean acc : 0.9065231: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[430/500]   mean loss : 0.2181969   mean acc : 0.9018767: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[431/500]   mean loss : 0.2173875   mean acc : 0.9042395: 100%|███████████████████| 94/94 [00:37<00:00,  2.53it/s]\n",
      "Epoch[432/500]   mean loss : 0.2148056   mean acc : 0.9049083: 100%|███████████████████| 94/94 [00:37<00:00,  2.51it/s]\n",
      "Epoch[433/500]   mean loss : 0.2109389   mean acc : 0.9058621: 100%|███████████████████| 94/94 [00:38<00:00,  2.43it/s]\n",
      "Epoch[434/500]   mean loss : 0.2136817   mean acc : 0.9043305: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[435/500]   mean loss : 0.2098468   mean acc : 0.9071959: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[436/500]   mean loss : 0.2047263   mean acc : 0.9093133: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[437/500]   mean loss : 0.2013656   mean acc : 0.9109359: 100%|███████████████████| 94/94 [00:36<00:00,  2.54it/s]\n",
      "Epoch[438/500]   mean loss : 0.2105744   mean acc : 0.9058265: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[439/500]   mean loss : 0.2134761   mean acc : 0.9063173: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[440/500]   mean loss : 0.2042941   mean acc : 0.9108568: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[441/500]   mean loss : 0.2154169   mean acc : 0.9062817: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[442/500]   mean loss : 0.2145638   mean acc : 0.9063964: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[443/500]   mean loss : 0.2142862   mean acc : 0.9050746: 100%|███████████████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "Epoch[444/500]   mean loss : 0.2192584   mean acc : 0.9082249: 100%|███████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[445/500]   mean loss : 0.2055358   mean acc : 0.9120599: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[446/500]   mean loss : 0.2023585   mean acc : 0.9089808: 100%|███████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[447/500]   mean loss : 0.2049600   mean acc : 0.9109003: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[448/500]   mean loss : 0.2039654   mean acc : 0.9097328: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[449/500]   mean loss : 0.2045155   mean acc : 0.9101483: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[450/500]   mean loss : 0.1999172   mean acc : 0.9128871: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[451/500]   mean loss : 0.2033121   mean acc : 0.9123924: 100%|███████████████████| 94/94 [00:36<00:00,  2.54it/s]\n",
      "Epoch[452/500]   mean loss : 0.2013109   mean acc : 0.9123924: 100%|███████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[453/500]   mean loss : 0.2035716   mean acc : 0.9120639: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[454/500]   mean loss : 0.2021280   mean acc : 0.9088185: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[455/500]   mean loss : 0.2044008   mean acc : 0.9118976: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[456/500]   mean loss : 0.1956697   mean acc : 0.9176205: 100%|███████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[457/500]   mean loss : 0.1960279   mean acc : 0.9142960: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[458/500]   mean loss : 0.1930456   mean acc : 0.9160453: 100%|███████████████████| 94/94 [00:37<00:00,  2.51it/s]\n",
      "Epoch[459/500]   mean loss : 0.1943759   mean acc : 0.9160493: 100%|███████████████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "Epoch[460/500]   mean loss : 0.1949264   mean acc : 0.9153844: 100%|███████████████████| 94/94 [00:37<00:00,  2.53it/s]\n",
      "Epoch[461/500]   mean loss : 0.2029108   mean acc : 0.9111457: 100%|███████████████████| 94/94 [00:36<00:00,  2.54it/s]\n",
      "Epoch[462/500]   mean loss : 0.1891007   mean acc : 0.9177907: 100%|███████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[463/500]   mean loss : 0.1915133   mean acc : 0.9162115: 100%|███████████████████| 94/94 [00:37<00:00,  2.52it/s]\n",
      "Epoch[464/500]   mean loss : 0.1850088   mean acc : 0.9192510: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[465/500]   mean loss : 0.1883000   mean acc : 0.9203236: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[466/500]   mean loss : 0.1926837   mean acc : 0.9159226: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[467/500]   mean loss : 0.1941643   mean acc : 0.9168804: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[468/500]   mean loss : 0.1930535   mean acc : 0.9172880: 100%|███████████████████| 94/94 [00:37<00:00,  2.53it/s]\n",
      "Epoch[469/500]   mean loss : 0.1930072   mean acc : 0.9176680: 100%|███████████████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "Epoch[470/500]   mean loss : 0.1872283   mean acc : 0.9181666: 100%|███████████████████| 94/94 [00:37<00:00,  2.54it/s]\n",
      "Epoch[471/500]   mean loss : 0.1896152   mean acc : 0.9169595: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[472/500]   mean loss : 0.1935843   mean acc : 0.9155902: 100%|███████████████████| 94/94 [00:35<00:00,  2.63it/s]\n",
      "Epoch[473/500]   mean loss : 0.1843054   mean acc : 0.9204146: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n",
      "Epoch[474/500]   mean loss : 0.1837141   mean acc : 0.9199080: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[475/500]   mean loss : 0.1842873   mean acc : 0.9217365: 100%|███████████████████| 94/94 [00:36<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[476/500]   mean loss : 0.1811277   mean acc : 0.9219106: 100%|███████████████████| 94/94 [00:35<00:00,  2.61it/s]\n",
      "Epoch[477/500]   mean loss : 0.1789958   mean acc : 0.9232404: 100%|███████████████████| 94/94 [00:36<00:00,  2.55it/s]\n",
      "Epoch[478/500]   mean loss : 0.1802761   mean acc : 0.9234066: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[479/500]   mean loss : 0.1673740   mean acc : 0.9288485: 100%|███████████████████| 94/94 [00:37<00:00,  2.50it/s]\n",
      "Epoch[480/500]   mean loss : 0.1770084   mean acc : 0.9235293: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[481/500]   mean loss : 0.1907343   mean acc : 0.9177550: 100%|███████████████████| 94/94 [00:37<00:00,  2.49it/s]\n",
      "Epoch[482/500]   mean loss : 0.1772827   mean acc : 0.9234422: 100%|███████████████████| 94/94 [00:37<00:00,  2.53it/s]\n",
      "Epoch[483/500]   mean loss : 0.1825944   mean acc : 0.9220333: 100%|███████████████████| 94/94 [00:35<00:00,  2.63it/s]\n",
      "Epoch[484/500]   mean loss : 0.1945773   mean acc : 0.9182893: 100%|███████████████████| 94/94 [00:35<00:00,  2.65it/s]\n",
      "Epoch[485/500]   mean loss : 0.1825251   mean acc : 0.9216573: 100%|███████████████████| 94/94 [00:37<00:00,  2.49it/s]\n",
      "Epoch[486/500]   mean loss : 0.1798890   mean acc : 0.9229436: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[487/500]   mean loss : 0.1783752   mean acc : 0.9232364: 100%|███████████████████| 94/94 [00:35<00:00,  2.62it/s]\n",
      "Epoch[488/500]   mean loss : 0.1863252   mean acc : 0.9208658: 100%|███████████████████| 94/94 [00:36<00:00,  2.56it/s]\n",
      "Epoch[489/500]   mean loss : 0.1792547   mean acc : 0.9296875:  22%|████▏              | 21/94 [00:08<00:30,  2.41it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b7b3c2f0fa28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcal_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mbatchloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# progress = tqdm(range(epoch))\n",
    "mean_loss = []\n",
    "mean_acc = []\n",
    "\n",
    "model.train()\n",
    "for e in range(epochs) :\n",
    "    batchloss = 0\n",
    "    batchacc= 0\n",
    "    tqdm_dataloader = tqdm(dataloader)\n",
    "    for batch, (data, label) in enumerate(tqdm_dataloader, start=1) :\n",
    "        optim.zero_grad()\n",
    "        src_mask = model.generate_square_subsequent_mask(data.shape[1]).to(device)      \n",
    "        \n",
    "        pred = model(data.to(device), src_mask)\n",
    "        \n",
    "        loss = criterion(pred, label.to(device, dtype=torch.float64))\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        score = cal_accuracy(pred.cpu(), label.cpu())\n",
    "        \n",
    "        batchloss += loss.cpu().item()\n",
    "        batchacc += score        \n",
    "        \n",
    "        tqdm_dataloader.set_description(f\"Epoch[{e}/{epochs}]   mean loss : {batchloss/batch:0.7f}   mean acc : {batchacc/batch:0.7f}\")\n",
    "\n",
    "    mean_loss.append(batchloss/batch)\n",
    "    mean_acc.append(batchacc/batch)\n",
    "\n",
    "    \n",
    "torch.save(model.state_dict(), f'./{epochs}E_stand_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b370b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702c9d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6ade50",
   "metadata": {},
   "source": [
    "# 학습 성공 config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fc00ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'KRW-BTC'\n",
    "interval ='minute10'\n",
    "to = f'2022-03-29 00:00'\n",
    "count = 14400 # 144000 가 한계임 288000은 학습이 안됨\n",
    "\n",
    "lr = 1e-4\n",
    "epochs = 300\n",
    "window_size = 24 * 6\n",
    "window_stride = 12\n",
    "feature_len = 7\n",
    "batch_size = 128\n",
    "num_class = 1\n",
    "\n",
    "norm = \"stand\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
