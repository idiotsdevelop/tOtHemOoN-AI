{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dba110fb",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4505d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pyupbit\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1770f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\\2\\3\n",
      "1\\pre_2\\\n"
     ]
    }
   ],
   "source": [
    "a = \"1\\\\2\\\\3\"\n",
    "b = \"2\"\n",
    "c = \"3\"\n",
    "d = a.replace(b,'pre_'+b).replace(c, '')\n",
    "print(a)\n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d0d3b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_preprocess() :\n",
    "    def __init__(self, ticker=None, interval=None, to=None, count=None, df=None, csv_list=None) :\n",
    "        if ticker and interval and to and count :\n",
    "            self.data, self.label, self.dataset = self.preprocess(pyupbit.get_ohlcv(ticker=ticker, interval=interval, to=to, count=count))\n",
    "        elif  df :\n",
    "            self.data, self.label, self.dataset = self.preprocess(df)\n",
    "            \n",
    "        elif csv_list :\n",
    "            for csv_path in csv_list :\n",
    "                try :\n",
    "                    df = pd.read_csv(csv_path)\n",
    "                    csv_data, csv_label, _ = self.preprocess(df)\n",
    "\n",
    "                    fold_name = csv_path.split('\\\\')[-2]\n",
    "                    file_name = csv_path.split('\\\\')[-1]\n",
    "                    new_path = csv_path.replace(fold_name, 'preprocess_'+fold_name).replace(csv_path.split('\\\\')[-1],'')\n",
    "                    os.makedirs(new_path, exist_ok=True)\n",
    "                    \n",
    "                    csv_dataset = pd.concat([csv_data, csv_label], axis=1)\n",
    "                    csv_dataset.to_csv(os.path.join(new_path, file_name))\n",
    "                    \n",
    "                except :\n",
    "                    print(f\"ERROR from {csv_path}\")\n",
    "            \n",
    "            \n",
    "            \n",
    "    def MinMax(self, dataset_df) :\n",
    "        norm = MinMaxScaler()\n",
    "        norm_dataset = norm.fit_transform(dataset_df)\n",
    "        return pd.DataFrame(norm_dataset, columns=list(dataset_df.columns))\n",
    "    \n",
    "    \n",
    "#     def add_after10(self, dataset_df) :\n",
    "#         after10 = np.zeros_like(self.norm_dataset['close'])\n",
    "#         for i in range(len(dataset_df['close']) - 1) :\n",
    "#             after10[i] = dataset_df['close'][i + 1]\n",
    "#         return after10\n",
    "    def add_after10(self, dataset_df) :\n",
    "        after10 = np.zeros_like(self.norm_dataset['close'])\n",
    "        for i in range(len(dataset_df['close']) - 1) :\n",
    "            if dataset_df['close'][i + 1] > dataset_df['close'][i] :\n",
    "                after10[i] = 1\n",
    "            else : \n",
    "                after10[i] = 0\n",
    "            \n",
    "        return after10\n",
    "    \n",
    "    \n",
    "    def drop_feature(self, dataset_df) :\n",
    "        # index(시간) 제거 \n",
    "        dataset_df = dataset_df.drop(columns=['Unnamed: 0'])\n",
    "        # value 제거\n",
    "        dataset_df = dataset_df.drop(columns=['value'])\n",
    "        return dataset_df\n",
    "    \n",
    "    \n",
    "    def add_avgPrice(self, dataset_df) :\n",
    "        return (dataset_df['high'] + dataset_df['low'] + \n",
    "                dataset_df['open'] + dataset_df['close']) // 4\n",
    "       \n",
    "    \n",
    "    def preprocess(self, dataset, latest=False) :\n",
    "        \n",
    "        # drop feature\n",
    "        dataset_df = self.drop_feature(dataset)\n",
    "#         display(dataset_df)\n",
    "        # avg_price 추가\n",
    "        dataset_df['avg_price'] = self.add_avgPrice(dataset_df)\n",
    "        \n",
    "        if latest == True :\n",
    "            # 가장 예전 데이터 삭제 - norm이랑 original 둘 다 적용\n",
    "            self.dataset = self.dataset.drop([self.dataset.index[0]]).drop(columns=['after10'])\n",
    "            self.norm_dataset = self.norm_dataset.drop([self.norm_dataset.index[0]])\n",
    "\n",
    "            # ori dataset에 추가\n",
    "            self.dataset = pd.concat([self.dataset, dataset_df])\n",
    "            self.dataset = self.dataset.reset_index(drop=True)\n",
    "            \n",
    "            # min max 정규화 (MinMaxScaler) 적용\n",
    "            self.norm_dataset = self.MinMax(self.dataset)\n",
    "            \n",
    "            # after10 추가\n",
    "            self.dataset['after10'] = self.add_after10(self.dataset)\n",
    "            \n",
    "        \n",
    "        else :\n",
    "            # min max 정규화 (MinMaxScaler) 적용\n",
    "            self.norm_dataset = self.MinMax(dataset_df)\n",
    "            \n",
    "            # after10 추가\n",
    "            dataset_df['after10'] = self.add_after10(dataset_df)\n",
    "        \n",
    "        # 예측될 값(label)인 10분 후 가격\n",
    "        self.norm_dataset['after10'] = self.add_after10(self.norm_dataset)\n",
    "        \n",
    "        # 마지막 행 삭제 (다음 가격을 모르므로 라벨을 붙일 수 없음)\n",
    "        self.norm_dataset = self.norm_dataset.iloc[:-1]\n",
    "        \n",
    "        return self.norm_dataset.drop(columns=['after10']), self.norm_dataset['after10'], dataset_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c47998c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR from ../data\\preprocess_2017_10\\2017-10-01.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-02.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-03.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-04.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-05.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-06.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-07.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-08.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-09.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-10.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-11.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-12.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-13.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-14.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-15.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-16.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-17.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-18.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-19.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-20.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-21.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-22.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-23.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-24.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-25.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-26.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-27.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-28.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-29.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-30.csv\n",
      "ERROR from ../data\\preprocess_2017_10\\2017-10-31.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-01.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-02.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-03.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-04.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-05.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-06.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-07.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-08.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-09.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-10.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-11.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-12.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-13.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-14.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-15.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-16.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-17.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-18.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-19.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-20.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-21.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-22.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-23.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-24.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-25.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-26.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-27.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-28.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-29.csv\n",
      "ERROR from ../data\\preprocess_2017_11\\2017-11-30.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-01.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-02.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-03.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-04.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-05.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-06.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-07.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-08.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-09.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-10.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-11.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-12.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-13.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-14.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-15.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-16.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-17.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-18.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-19.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-20.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-21.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-22.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-23.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-24.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-25.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-26.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-27.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-28.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-29.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-30.csv\n",
      "ERROR from ../data\\preprocess_2017_12\\2017-12-31.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-01.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-02.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-03.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-04.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-05.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-06.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-07.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-08.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-09.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-10.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-11.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-12.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-13.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-14.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-15.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-16.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-17.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-18.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-19.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-20.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-21.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-22.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-23.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-24.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-25.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-26.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-27.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-28.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-29.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-30.csv\n",
      "ERROR from ../data\\preprocess_2018_01\\2018-01-31.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-01.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-02.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-03.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-04.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-05.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-06.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-07.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-08.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-09.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-10.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-11.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-12.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-13.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-14.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-15.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-16.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-17.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-18.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-19.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-20.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-21.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-22.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-23.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-24.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-25.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-26.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-27.csv\n",
      "ERROR from ../data\\preprocess_2018_02\\2018-02-28.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-01.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-02.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-03.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-04.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-05.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-06.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-07.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-08.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-09.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-10.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-11.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-12.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-13.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-14.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-15.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-16.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-17.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-18.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-19.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-20.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-21.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-22.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-23.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-24.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-25.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-26.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-27.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-28.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-29.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR from ../data\\preprocess_2018_03\\2018-03-30.csv\n",
      "ERROR from ../data\\preprocess_2018_03\\2018-03-31.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-01.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-02.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-03.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-04.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-05.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-06.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-07.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-08.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-09.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-10.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-11.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-12.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-13.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-14.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-15.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-16.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-17.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-18.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-19.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-20.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-21.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-22.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-23.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-24.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-25.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-26.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-27.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-28.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-29.csv\n",
      "ERROR from ../data\\preprocess_2018_04\\2018-04-30.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-01.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-02.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-03.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-04.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-05.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-06.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-07.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-08.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-09.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-10.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-11.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-12.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-13.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-14.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-15.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-16.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-17.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-18.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-19.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-20.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-21.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-22.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-23.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-24.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-25.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-26.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-27.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-28.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-29.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-30.csv\n",
      "ERROR from ../data\\preprocess_2018_05\\2018-05-31.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-01.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-02.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-03.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-04.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-05.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-06.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-07.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-08.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-09.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-10.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-11.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-12.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-13.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-14.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-15.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-16.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-17.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-18.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-19.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-20.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-21.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-22.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-23.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-24.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-25.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-26.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-27.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-28.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-29.csv\n",
      "ERROR from ../data\\preprocess_2018_06\\2018-06-30.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-01.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-02.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-03.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-04.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-05.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-06.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-07.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-08.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-09.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-10.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-11.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-12.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-13.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-14.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-15.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-16.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-17.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-18.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-19.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-20.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-21.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-22.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-23.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-24.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-25.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-26.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-27.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-28.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-29.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-30.csv\n",
      "ERROR from ../data\\preprocess_2018_07\\2018-07-31.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-01.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-02.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-03.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-04.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-05.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-06.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-07.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-08.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-09.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-10.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-11.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-12.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-13.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-14.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-15.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-16.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-17.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-18.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-19.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-20.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-21.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-22.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-23.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-24.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-25.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-26.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-27.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-28.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-29.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-30.csv\n",
      "ERROR from ../data\\preprocess_2018_08\\2018-08-31.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-01.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-02.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-03.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-04.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-05.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-06.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-07.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-08.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-09.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-10.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-11.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-12.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-13.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-14.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-15.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-16.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-17.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-18.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-19.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-20.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-21.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-22.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR from ../data\\preprocess_2018_09\\2018-09-23.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-24.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-25.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-26.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-27.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-28.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-29.csv\n",
      "ERROR from ../data\\preprocess_2018_09\\2018-09-30.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-01.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-02.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-03.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-04.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-05.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-06.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-07.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-08.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-09.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-10.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-11.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-12.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-13.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-14.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-15.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-16.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-17.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-18.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-19.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-20.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-21.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-22.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-23.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-24.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-25.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-26.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-27.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-28.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-29.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-30.csv\n",
      "ERROR from ../data\\preprocess_2018_10\\2018-10-31.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-01.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-02.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-03.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-04.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-05.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-06.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-07.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-08.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-09.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-10.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-11.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-12.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-13.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-14.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-15.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-16.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-17.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-18.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-19.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-20.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-21.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-22.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-23.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-24.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-25.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-26.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-27.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-28.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-29.csv\n",
      "ERROR from ../data\\preprocess_2018_11\\2018-11-30.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-01.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-02.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-03.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-04.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-05.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-06.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-07.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-08.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-09.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-10.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-11.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-12.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-13.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-14.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-15.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-16.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-17.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-18.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-19.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-20.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-21.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-22.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-23.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-24.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-25.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-26.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-27.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-28.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-29.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-30.csv\n",
      "ERROR from ../data\\preprocess_2018_12\\2018-12-31.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-01.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-02.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-03.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-04.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-05.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-06.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-07.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-08.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-09.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-10.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-11.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-12.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-13.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-14.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-15.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-16.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-17.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-18.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-19.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-20.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-21.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-22.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-23.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-24.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-25.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-26.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-27.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-28.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-29.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-30.csv\n",
      "ERROR from ../data\\preprocess_2019_01\\2019-01-31.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-01.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-02.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-03.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-04.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-05.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-06.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-07.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-08.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-09.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-10.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-11.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-12.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-13.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-14.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-15.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-16.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-17.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-18.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-19.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-20.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-21.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-22.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-23.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-24.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-25.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-26.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-27.csv\n",
      "ERROR from ../data\\preprocess_2019_02\\2019-02-28.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-01.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-02.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-03.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-04.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-05.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-06.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-07.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR from ../data\\preprocess_2019_03\\2019-03-08.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-09.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-10.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-11.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-12.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-13.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-14.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-15.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-16.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-17.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-18.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-19.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-20.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-21.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-22.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-23.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-24.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-25.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-26.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-27.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-28.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-29.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-30.csv\n",
      "ERROR from ../data\\preprocess_2019_03\\2019-03-31.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-01.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-02.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-03.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-04.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-05.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-06.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-07.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-08.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-09.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-10.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-11.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-12.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-13.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-14.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-15.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-16.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-17.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-18.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-19.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-20.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-21.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-22.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-23.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-24.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-25.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-26.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-27.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-28.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-29.csv\n",
      "ERROR from ../data\\preprocess_2019_04\\2019-04-30.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-01.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-02.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-03.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-04.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-05.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-06.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-07.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-08.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-09.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-10.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-11.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-12.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-13.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-14.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-15.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-16.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-17.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-18.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-19.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-20.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-21.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-22.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-23.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-24.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-25.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-26.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-27.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-28.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-29.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-30.csv\n",
      "ERROR from ../data\\preprocess_2019_05\\2019-05-31.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-01.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-02.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-03.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-04.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-05.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-06.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-07.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-08.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-09.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-10.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-11.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-12.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-13.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-14.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-15.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-16.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-17.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-18.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-19.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-20.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-21.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-22.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-23.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-24.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-25.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-26.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-27.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-28.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-29.csv\n",
      "ERROR from ../data\\preprocess_2019_06\\2019-06-30.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-01.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-02.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-03.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-04.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-05.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-06.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-07.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-08.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-09.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-10.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-11.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-12.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-13.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-14.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-15.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-16.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-17.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-18.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-19.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-20.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-21.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-22.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-23.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-24.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-25.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-26.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-27.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-28.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-29.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-30.csv\n",
      "ERROR from ../data\\preprocess_2019_07\\2019-07-31.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-01.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-02.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-03.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-04.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-05.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-06.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-07.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-08.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-09.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-10.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-11.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-12.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR from ../data\\preprocess_2019_08\\2019-08-13.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-14.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-15.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-16.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-17.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-18.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-19.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-20.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-21.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-22.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-23.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-24.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-25.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-26.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-27.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-28.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-29.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-30.csv\n",
      "ERROR from ../data\\preprocess_2019_08\\2019-08-31.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-01.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-02.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-03.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-04.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-05.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-06.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-07.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-08.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-09.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-10.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-11.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-12.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-13.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-14.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-15.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-16.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-17.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-18.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-19.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-20.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-21.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-22.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-23.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-24.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-25.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-26.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-27.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-28.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-29.csv\n",
      "ERROR from ../data\\preprocess_2019_09\\2019-09-30.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-01.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-02.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-03.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-04.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-05.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-06.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-07.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-08.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-09.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-10.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-11.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-12.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-13.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-14.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-15.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-16.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-17.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-18.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-19.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-20.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-21.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-22.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-23.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-24.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-25.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-26.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-27.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-28.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-29.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-30.csv\n",
      "ERROR from ../data\\preprocess_2019_10\\2019-10-31.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-01.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-02.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-03.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-04.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-05.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-06.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-07.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-08.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-09.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-10.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-11.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-12.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-13.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-14.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-15.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-16.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-17.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-18.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-19.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-20.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-21.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-22.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-23.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-24.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-25.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-26.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-27.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-28.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-29.csv\n",
      "ERROR from ../data\\preprocess_2019_11\\2019-11-30.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-01.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-02.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-03.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-04.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-05.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-06.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-07.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-08.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-09.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-10.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-11.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-12.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-13.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-14.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-15.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-16.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-17.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-18.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-19.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-20.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-21.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-22.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-23.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-24.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-25.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-26.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-27.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-28.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-29.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-30.csv\n",
      "ERROR from ../data\\preprocess_2019_12\\2019-12-31.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-01.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-02.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-03.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-04.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-05.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-06.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-07.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-08.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-09.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-10.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-11.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-12.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-13.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-14.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-15.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-16.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-17.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-18.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-19.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-20.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-21.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR from ../data\\preprocess_2020_01\\2020-01-22.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-23.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-24.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-25.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-26.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-27.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-28.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-29.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-30.csv\n",
      "ERROR from ../data\\preprocess_2020_01\\2020-01-31.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-01.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-02.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-03.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-04.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-05.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-06.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-07.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-08.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-09.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-10.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-11.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-12.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-13.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-14.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-15.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-16.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-17.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-18.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-19.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-20.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-21.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-22.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-23.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-24.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-25.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-26.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-27.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-28.csv\n",
      "ERROR from ../data\\preprocess_2020_02\\2020-02-29.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-01.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-02.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-03.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-04.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-05.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-06.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-07.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-08.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-09.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-10.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-11.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-12.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-13.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-14.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-15.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-16.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-17.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-18.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-19.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-20.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-21.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-22.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-23.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-24.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-25.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-26.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-27.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-28.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-29.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-30.csv\n",
      "ERROR from ../data\\preprocess_2020_03\\2020-03-31.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-01.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-02.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-03.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-04.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-05.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-06.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-07.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-08.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-09.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-10.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-11.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-12.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-13.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-14.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-15.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-16.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-17.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-18.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-19.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-20.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-21.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-22.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-23.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-24.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-25.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-26.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-27.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-28.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-29.csv\n",
      "ERROR from ../data\\preprocess_2020_04\\2020-04-30.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-01.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-02.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-03.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-04.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-05.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-06.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-07.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-08.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-09.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-10.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-11.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-12.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-13.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-14.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-15.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-16.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-17.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-18.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-19.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-20.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-21.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-22.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-23.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-24.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-25.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-26.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-27.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-28.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-29.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-30.csv\n",
      "ERROR from ../data\\preprocess_2020_05\\2020-05-31.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-01.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-02.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-03.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-04.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-05.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-06.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-07.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-08.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-09.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-10.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-11.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-12.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-13.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-14.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-15.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-16.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-17.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-18.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-19.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-20.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-21.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-22.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-23.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-24.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-25.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-26.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-27.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-28.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-29.csv\n",
      "ERROR from ../data\\preprocess_2020_06\\2020-06-30.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-01.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-02.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-03.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-04.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-05.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-06.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-07.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-08.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-09.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR from ../data\\preprocess_2020_07\\2020-07-10.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-11.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-12.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-13.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-14.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-15.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-16.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-17.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-18.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-19.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-20.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-21.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-22.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-23.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-24.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-25.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-26.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-27.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-28.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-29.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-30.csv\n",
      "ERROR from ../data\\preprocess_2020_07\\2020-07-31.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-01.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-02.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-03.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-04.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-05.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-06.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-07.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-08.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-09.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-10.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-11.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-12.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-13.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-14.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-15.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-16.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-17.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-18.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-19.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-20.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-21.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-22.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-23.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-24.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-25.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-26.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-27.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-28.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-29.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-30.csv\n",
      "ERROR from ../data\\preprocess_2020_08\\2020-08-31.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-01.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-02.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-03.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-04.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-05.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-06.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-07.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-08.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-09.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-10.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-11.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-12.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-13.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-14.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-15.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-16.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-17.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-18.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-19.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-20.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-21.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-22.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-23.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-24.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-25.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-26.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-27.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-28.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-29.csv\n",
      "ERROR from ../data\\preprocess_2020_09\\2020-09-30.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-01.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-02.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-03.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-04.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-05.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-06.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-07.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-08.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-09.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-10.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-11.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-12.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-13.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-14.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-15.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-16.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-17.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-18.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-19.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-20.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-21.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-22.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-23.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-24.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-25.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-26.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-27.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-28.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-29.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-30.csv\n",
      "ERROR from ../data\\preprocess_2020_10\\2020-10-31.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-01.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-02.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-03.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-04.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-05.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-06.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-07.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-08.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-09.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-10.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-11.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-12.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-13.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-14.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-15.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-16.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-17.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-18.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-19.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-20.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-21.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-22.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-23.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-24.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-25.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-26.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-27.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-28.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-29.csv\n",
      "ERROR from ../data\\preprocess_2020_11\\2020-11-30.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-01.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-02.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-03.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-04.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-05.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-06.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-07.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-08.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-09.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-10.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-11.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-12.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-13.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-14.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-15.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-16.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-17.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR from ../data\\preprocess_2020_12\\2020-12-18.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-19.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-20.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-21.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-22.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-23.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-24.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-25.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-26.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-27.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-28.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-29.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-30.csv\n",
      "ERROR from ../data\\preprocess_2020_12\\2020-12-31.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-01.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-02.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-03.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-04.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-05.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-06.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-07.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-08.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-09.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-10.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-11.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-12.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-13.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-14.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-15.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-16.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-17.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-18.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-19.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-20.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-21.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-22.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-23.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-24.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-25.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-26.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-27.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-28.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-29.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-30.csv\n",
      "ERROR from ../data\\preprocess_2021_01\\2021-01-31.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-01.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-02.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-03.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-04.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-05.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-06.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-07.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-08.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-09.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-10.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-11.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-12.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-13.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-14.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-15.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-16.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-17.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-18.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-19.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-20.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-21.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-22.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-23.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-24.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-25.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-26.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-27.csv\n",
      "ERROR from ../data\\preprocess_2021_02\\2021-02-28.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-01.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-02.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-03.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-04.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-05.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-06.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-07.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-08.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-09.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-10.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-11.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-12.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-13.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-14.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-15.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-16.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-17.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-18.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-19.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-20.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-21.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-22.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-23.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-24.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-25.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-26.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-27.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-28.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-29.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-30.csv\n",
      "ERROR from ../data\\preprocess_2021_03\\2021-03-31.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-01.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-02.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-03.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-04.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-05.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-06.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-07.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-08.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-09.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-10.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-11.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-12.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-13.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-14.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-15.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-16.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-17.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-18.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-19.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-20.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-21.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-22.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-23.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-24.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-25.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-26.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-27.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-28.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-29.csv\n",
      "ERROR from ../data\\preprocess_2021_04\\2021-04-30.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-01.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-02.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-03.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-04.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-05.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-06.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-07.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-08.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-09.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-10.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-11.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-12.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-13.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-14.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-15.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-16.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-17.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-18.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-19.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-20.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-21.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-22.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-23.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-24.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-25.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-26.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-27.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-28.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-29.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR from ../data\\preprocess_2021_05\\2021-05-30.csv\n",
      "ERROR from ../data\\preprocess_2021_05\\2021-05-31.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-01.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-02.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-03.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-04.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-05.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-06.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-07.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-08.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-09.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-10.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-11.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-12.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-13.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-14.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-15.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-16.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-17.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-18.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-19.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-20.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-21.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-22.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-23.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-24.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-25.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-26.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-27.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-28.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-29.csv\n",
      "ERROR from ../data\\preprocess_2021_06\\2021-06-30.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-01.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-02.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-03.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-04.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-05.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-06.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-07.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-08.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-09.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-10.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-11.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-12.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-13.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-14.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-15.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-16.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-17.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-18.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-19.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-20.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-21.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-22.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-23.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-24.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-25.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-26.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-27.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-28.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-29.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-30.csv\n",
      "ERROR from ../data\\preprocess_2021_07\\2021-07-31.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-01.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-02.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-03.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-04.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-05.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-06.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-07.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-08.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-09.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-10.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-11.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-12.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-13.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-14.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-15.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-16.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-17.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-18.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-19.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-20.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-21.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-22.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-23.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-24.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-25.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-26.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-27.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-28.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-29.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-30.csv\n",
      "ERROR from ../data\\preprocess_2021_08\\2021-08-31.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-01.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-02.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-03.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-04.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-05.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-06.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-07.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-08.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-09.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-10.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-11.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-12.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-13.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-14.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-15.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-16.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-17.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-18.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-19.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-20.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-21.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-22.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-23.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-24.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-25.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-26.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-27.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-28.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-29.csv\n",
      "ERROR from ../data\\preprocess_2021_09\\2021-09-30.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-01.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-02.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-03.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-04.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-05.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-06.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-07.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-08.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-09.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-10.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-11.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-12.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-13.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-14.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-15.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-16.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-17.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-18.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-19.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-20.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-21.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-22.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-23.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-24.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-25.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-26.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-27.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-28.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-29.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-30.csv\n",
      "ERROR from ../data\\preprocess_2021_10\\2021-10-31.csv\n",
      "ERROR from ../data\\preprocess_2021_11\\2021-11-01.csv\n",
      "ERROR from ../data\\preprocess_2021_11\\2021-11-02.csv\n",
      "ERROR from ../data\\preprocess_2021_11\\2021-11-03.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Data_preprocess at 0x1ec2e4770f0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_list = glob('../data/*/*.csv')\n",
    "Data_preprocess(csv_list=csv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c81f94b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>avg_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007950</td>\n",
       "      <td>0.008405</td>\n",
       "      <td>0.008044</td>\n",
       "      <td>0.008253</td>\n",
       "      <td>0.004478</td>\n",
       "      <td>0.008164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008127</td>\n",
       "      <td>0.008442</td>\n",
       "      <td>0.008234</td>\n",
       "      <td>0.008253</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.008266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008127</td>\n",
       "      <td>0.008417</td>\n",
       "      <td>0.007993</td>\n",
       "      <td>0.008177</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.008180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008178</td>\n",
       "      <td>0.008417</td>\n",
       "      <td>0.008133</td>\n",
       "      <td>0.008442</td>\n",
       "      <td>0.005041</td>\n",
       "      <td>0.008294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008279</td>\n",
       "      <td>0.008303</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.008215</td>\n",
       "      <td>0.005372</td>\n",
       "      <td>0.008224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231259</th>\n",
       "      <td>0.537299</td>\n",
       "      <td>0.537207</td>\n",
       "      <td>0.538567</td>\n",
       "      <td>0.536190</td>\n",
       "      <td>0.008229</td>\n",
       "      <td>0.538009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231260</th>\n",
       "      <td>0.536262</td>\n",
       "      <td>0.538497</td>\n",
       "      <td>0.539253</td>\n",
       "      <td>0.538148</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>0.538735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231261</th>\n",
       "      <td>0.538575</td>\n",
       "      <td>0.538497</td>\n",
       "      <td>0.539762</td>\n",
       "      <td>0.537415</td>\n",
       "      <td>0.006654</td>\n",
       "      <td>0.539257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231262</th>\n",
       "      <td>0.537488</td>\n",
       "      <td>0.538181</td>\n",
       "      <td>0.540461</td>\n",
       "      <td>0.538199</td>\n",
       "      <td>0.005430</td>\n",
       "      <td>0.539276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231263</th>\n",
       "      <td>0.538272</td>\n",
       "      <td>0.539267</td>\n",
       "      <td>0.541248</td>\n",
       "      <td>0.539223</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.540198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231264 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            open      high       low     close    volume  avg_price\n",
       "0       0.007950  0.008405  0.008044  0.008253  0.004478   0.008164\n",
       "1       0.008127  0.008442  0.008234  0.008253  0.004558   0.008266\n",
       "2       0.008127  0.008417  0.007993  0.008177  0.004535   0.008180\n",
       "3       0.008178  0.008417  0.008133  0.008442  0.005041   0.008294\n",
       "4       0.008279  0.008303  0.008095  0.008215  0.005372   0.008224\n",
       "...          ...       ...       ...       ...       ...        ...\n",
       "231259  0.537299  0.537207  0.538567  0.536190  0.008229   0.538009\n",
       "231260  0.536262  0.538497  0.539253  0.538148  0.004799   0.538735\n",
       "231261  0.538575  0.538497  0.539762  0.537415  0.006654   0.539257\n",
       "231262  0.537488  0.538181  0.540461  0.538199  0.005430   0.539276\n",
       "231263  0.538272  0.539267  0.541248  0.539223  0.004742   0.540198\n",
       "\n",
       "[231264 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(231264, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>after10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231259</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231260</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231261</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231262</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231263</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231264 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        after10\n",
       "0           0.0\n",
       "1           0.0\n",
       "2           1.0\n",
       "3           0.0\n",
       "4           0.0\n",
       "...         ...\n",
       "231259      1.0\n",
       "231260      0.0\n",
       "231261      1.0\n",
       "231262      1.0\n",
       "231263      1.0\n",
       "\n",
       "[231264 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_data = pd.read_csv('1000000_data.csv').drop(columns=['Unnamed: 0'])\n",
    "csv_label = pd.read_csv('1000000_label.csv').drop(columns=['Unnamed: 0'])\n",
    "display(csv_data)\n",
    "display(csv_data.shape)\n",
    "display(csv_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1c97350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>after10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53458000.0</td>\n",
       "      <td>53501000.0</td>\n",
       "      <td>53404000.0</td>\n",
       "      <td>53497000.0</td>\n",
       "      <td>48.929350</td>\n",
       "      <td>53465000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53497000.0</td>\n",
       "      <td>53580000.0</td>\n",
       "      <td>53495000.0</td>\n",
       "      <td>53549000.0</td>\n",
       "      <td>43.200104</td>\n",
       "      <td>53530250.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53549000.0</td>\n",
       "      <td>53550000.0</td>\n",
       "      <td>53355000.0</td>\n",
       "      <td>53355000.0</td>\n",
       "      <td>62.350798</td>\n",
       "      <td>53452250.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53360000.0</td>\n",
       "      <td>53505000.0</td>\n",
       "      <td>53310000.0</td>\n",
       "      <td>53484000.0</td>\n",
       "      <td>32.375780</td>\n",
       "      <td>53414750.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53497000.0</td>\n",
       "      <td>53505000.0</td>\n",
       "      <td>53330000.0</td>\n",
       "      <td>53392000.0</td>\n",
       "      <td>35.808686</td>\n",
       "      <td>53431000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>46000000.0</td>\n",
       "      <td>46184000.0</td>\n",
       "      <td>45998000.0</td>\n",
       "      <td>46155000.0</td>\n",
       "      <td>17.084831</td>\n",
       "      <td>46084250.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>46183000.0</td>\n",
       "      <td>46184000.0</td>\n",
       "      <td>46038000.0</td>\n",
       "      <td>46097000.0</td>\n",
       "      <td>23.687584</td>\n",
       "      <td>46125500.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>46097000.0</td>\n",
       "      <td>46159000.0</td>\n",
       "      <td>46093000.0</td>\n",
       "      <td>46159000.0</td>\n",
       "      <td>19.330314</td>\n",
       "      <td>46127000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>46159000.0</td>\n",
       "      <td>46245000.0</td>\n",
       "      <td>46155000.0</td>\n",
       "      <td>46240000.0</td>\n",
       "      <td>16.882303</td>\n",
       "      <td>46199750.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>46240000.0</td>\n",
       "      <td>46360000.0</td>\n",
       "      <td>46236000.0</td>\n",
       "      <td>46340000.0</td>\n",
       "      <td>22.019772</td>\n",
       "      <td>46294000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           open        high         low       close     volume   avg_price  \\\n",
       "0    53458000.0  53501000.0  53404000.0  53497000.0  48.929350  53465000.0   \n",
       "1    53497000.0  53580000.0  53495000.0  53549000.0  43.200104  53530250.0   \n",
       "2    53549000.0  53550000.0  53355000.0  53355000.0  62.350798  53452250.0   \n",
       "3    53360000.0  53505000.0  53310000.0  53484000.0  32.375780  53414750.0   \n",
       "4    53497000.0  53505000.0  53330000.0  53392000.0  35.808686  53431000.0   \n",
       "..          ...         ...         ...         ...        ...         ...   \n",
       "995  46000000.0  46184000.0  45998000.0  46155000.0  17.084831  46084250.0   \n",
       "996  46183000.0  46184000.0  46038000.0  46097000.0  23.687584  46125500.0   \n",
       "997  46097000.0  46159000.0  46093000.0  46159000.0  19.330314  46127000.0   \n",
       "998  46159000.0  46245000.0  46155000.0  46240000.0  16.882303  46199750.0   \n",
       "999  46240000.0  46360000.0  46236000.0  46340000.0  22.019772  46294000.0   \n",
       "\n",
       "     after10  \n",
       "0        1.0  \n",
       "1        0.0  \n",
       "2        1.0  \n",
       "3        0.0  \n",
       "4        0.0  \n",
       "..       ...  \n",
       "995      0.0  \n",
       "996      1.0  \n",
       "997      1.0  \n",
       "998      1.0  \n",
       "999      0.0  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>avg_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.981553</td>\n",
       "      <td>0.976587</td>\n",
       "      <td>0.983528</td>\n",
       "      <td>0.983642</td>\n",
       "      <td>0.066683</td>\n",
       "      <td>0.983776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.985994</td>\n",
       "      <td>0.985610</td>\n",
       "      <td>0.993866</td>\n",
       "      <td>0.989549</td>\n",
       "      <td>0.058659</td>\n",
       "      <td>0.991257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.991915</td>\n",
       "      <td>0.982184</td>\n",
       "      <td>0.977962</td>\n",
       "      <td>0.967511</td>\n",
       "      <td>0.085479</td>\n",
       "      <td>0.982314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.970394</td>\n",
       "      <td>0.977044</td>\n",
       "      <td>0.972850</td>\n",
       "      <td>0.982165</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.978015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.985994</td>\n",
       "      <td>0.977044</td>\n",
       "      <td>0.975122</td>\n",
       "      <td>0.971714</td>\n",
       "      <td>0.048308</td>\n",
       "      <td>0.979878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.141653</td>\n",
       "      <td>0.129283</td>\n",
       "      <td>0.136090</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.039185</td>\n",
       "      <td>0.130966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.132316</td>\n",
       "      <td>0.140932</td>\n",
       "      <td>0.142224</td>\n",
       "      <td>0.149608</td>\n",
       "      <td>0.022086</td>\n",
       "      <td>0.137530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.153154</td>\n",
       "      <td>0.140932</td>\n",
       "      <td>0.146768</td>\n",
       "      <td>0.143019</td>\n",
       "      <td>0.031333</td>\n",
       "      <td>0.142259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.143361</td>\n",
       "      <td>0.138077</td>\n",
       "      <td>0.153016</td>\n",
       "      <td>0.150062</td>\n",
       "      <td>0.025230</td>\n",
       "      <td>0.142431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.150421</td>\n",
       "      <td>0.147899</td>\n",
       "      <td>0.160059</td>\n",
       "      <td>0.159264</td>\n",
       "      <td>0.021802</td>\n",
       "      <td>0.150772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         open      high       low     close    volume  avg_price\n",
       "0    0.981553  0.976587  0.983528  0.983642  0.066683   0.983776\n",
       "1    0.985994  0.985610  0.993866  0.989549  0.058659   0.991257\n",
       "2    0.991915  0.982184  0.977962  0.967511  0.085479   0.982314\n",
       "3    0.970394  0.977044  0.972850  0.982165  0.043500   0.978015\n",
       "4    0.985994  0.977044  0.975122  0.971714  0.048308   0.979878\n",
       "..        ...       ...       ...       ...       ...        ...\n",
       "994  0.141653  0.129283  0.136090  0.132000  0.039185   0.130966\n",
       "995  0.132316  0.140932  0.142224  0.149608  0.022086   0.137530\n",
       "996  0.153154  0.140932  0.146768  0.143019  0.031333   0.142259\n",
       "997  0.143361  0.138077  0.153016  0.150062  0.025230   0.142431\n",
       "998  0.150421  0.147899  0.160059  0.159264  0.021802   0.150772\n",
       "\n",
       "[999 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      1.0\n",
       "1      0.0\n",
       "2      1.0\n",
       "3      0.0\n",
       "4      0.0\n",
       "      ... \n",
       "994    1.0\n",
       "995    0.0\n",
       "996    1.0\n",
       "997    1.0\n",
       "998    1.0\n",
       "Name: after10, Length: 999, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ticker = 'KRW-BTC'\n",
    "interval ='minute10'\n",
    "to = f'2022-02-23 08:30'\n",
    "count = 1000#000\n",
    "\n",
    "processed_data =  Data_preprocess(ticker, interval, to, count)\n",
    "display(processed_data.dataset)\n",
    "display(processed_data.data)\n",
    "display(processed_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd671a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(999, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(999,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(processed_data.data))\n",
    "display(len(processed_data.label))\n",
    "\n",
    "display((processed_data.data).shape)\n",
    "display((processed_data.label).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "593aa5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display((processed_data.data).shape[0])\n",
    "# tensor_data = torch.Tensor((processed_data.data).values)\n",
    "# display(tensor_data.shape)\n",
    "# print(tensor_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9fbd4f",
   "metadata": {},
   "source": [
    "https://doheon.github.io/%EC%BD%94%EB%93%9C%EA%B5%AC%ED%98%84/time-series/ci-4.transformer-post/\n",
    "\n",
    "참고해서 WindowDataset 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "232d04e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WindowDataGenerator(df_data, df_label, window_size, stride) :\n",
    "    num_sample = (df_data.shape[0] - window_size) // stride + 1     \n",
    "\n",
    "    data = np.zeros([window_size, df_data.shape[1], num_sample])\n",
    "    labels = np.zeros([num_sample])\n",
    "\n",
    "    for i in range(num_sample) :\n",
    "        data_start = stride * i\n",
    "        data_end = data_start + window_size\n",
    "        data[:, :, i] = df_data[data_start : data_end, :]\n",
    "        labels[i] = df_label[data_end - 1]\n",
    "\n",
    "    data = data.transpose((2, 0, 1))\n",
    "    print(\"dataset shape ==== \",data.shape)\n",
    "    # data shape (80, 600, 6), label shape (80,)\n",
    "    return torch.Tensor(data), torch.Tensor(labels)\n",
    "\n",
    "# a,b = WindowDataGenerator(csv_data.values, csv_label.values, 24 * 6, 5)\n",
    "# a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe7e060",
   "metadata": {},
   "source": [
    "# Window Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23edfc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowDataset(Dataset) :\n",
    "    def __init__(self, df_data, df_label, window_size=600, stride=5) :\n",
    "        self.data, self.label = self.WindowDataGenerator(df_data, df_label, window_size, stride)        \n",
    "        \n",
    "    def __getitem__(self, i) :\n",
    "        return self.data[i], self.label[i]\n",
    "                \n",
    "    def __len__(self) :\n",
    "        assert len(self.data) == len(self.label), \"data와 label의 길이가 다름\"\n",
    "        return len(self.data)\n",
    "        \n",
    "    \n",
    "    def WindowDataGenerator(self, df_data, df_label, window_size, stride) :\n",
    "        num_sample = (df_data.shape[0] - window_size) // stride + 1     \n",
    "\n",
    "        data = np.zeros([window_size, df_data.shape[1], num_sample])\n",
    "        labels = np.zeros([num_sample])\n",
    "\n",
    "        for i in range(num_sample) :\n",
    "            data_start = stride * i\n",
    "            data_end = data_start + window_size\n",
    "            data[:, :, i] = df_data[data_start : data_end, :]\n",
    "            labels[i] = df_label[data_end - 1]\n",
    "\n",
    "        data = data.transpose((2, 0, 1))\n",
    "        # data shape (80, 600, 6), label shape (80,)\n",
    "        return torch.Tensor(data), torch.Tensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d2de4f",
   "metadata": {},
   "source": [
    "# nn.Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0980eb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer2FC(nn.Module) :\n",
    "    def __init__(self, input_shape, d_model, n_head, num_layer, dropout, num_class=2):\n",
    "        super(Transformer2FC, self).__init__()\n",
    "        \n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=n_head, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layer)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        \n",
    "        self.Encoder = nn.Sequential(\n",
    "            nn.Linear(input_shape[1], d_model//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model//2, d_model)\n",
    "        )\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model//2, 1)\n",
    "        )\n",
    "\n",
    "        self.linear2 = nn.Sequential(\n",
    "            nn.Linear(input_shape[0], input_shape[0]//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_shape[0]//2, num_class)\n",
    "        )\n",
    "        \n",
    "#         self.sigmoid = nn.Softmax()\n",
    "    \n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "    \n",
    "    def forward(self, x, masked_x) :\n",
    "        # (batch, data, dim)\n",
    "#         print(\"input shape : \", x.shape)\n",
    "        x = self.Encoder(x)\n",
    "#         print(\"Encoder shape : \", x.shape)\n",
    "        x = self.pos_encoder(x)\n",
    "#         print(\"pos_encoder shape : \", x.shape)\n",
    "#         print(\"masked_x shape : \", masked_x.shape)\n",
    "        x = self.transformer_encoder(x.transpose(0,1), masked_x).transpose(0, 1)\n",
    "#         print(\"transformer_encoder shape : \", x.shape)\n",
    "        x = self.linear(x)\n",
    "#         print(\"linear shape : \", x.shape)\n",
    "        x = x.squeeze(2)\n",
    "#         print(\"squeeze shape : \", x.shape)\n",
    "        x = self.linear2(x)\n",
    "#         print(\"linear2 shape : \", x.shape)\n",
    "        x = x.squeeze(1)\n",
    "#         print(\"squeeze shape : \", x.shape)\n",
    "        return x\n",
    "\n",
    "class PositionalEncoding(nn.Module) :\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000) :\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        \n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "\n",
    "        return self.dropout(x)\n",
    "\n",
    "def get_attention_mask(x) :\n",
    "    mask = torch.eq(x, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7a6a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "lr = 1e-4\n",
    "epoch = 200\n",
    "window_size = 24 * 6\n",
    "window_stride = 5\n",
    "feature_len = 6\n",
    "batch_size = 64\n",
    "num_class = 1\n",
    "\n",
    "model = Transformer2FC(input_shape=(window_size, feature_len), \n",
    "                       d_model=512, \n",
    "                       n_head=8, \n",
    "                       num_layer=4, \n",
    "                       dropout=0.3, \n",
    "                       num_class = num_class).to(device)\n",
    "# model = MLSTMfcn(max_seq_len=window_size, num_features=feature_len).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.HuberLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7864db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WindowDataset(processed_data.data.values, \n",
    "                        processed_data.label.values, \n",
    "                       window_size = window_size, \n",
    "                       stride = window_stride)\n",
    "# dataset = WindowDataset(csv_data.values, \n",
    "#                         csv_label.values, \n",
    "#                        window_size = window_size, \n",
    "#                        stride = window_stride)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3a77e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_accuracy(pred, label, threshold=0.5) :\n",
    "#     acc = torch.zeros(pred.shape[0])\n",
    "#     acc[pred > threshold] = 0\n",
    "#     acc[pred < threshold] = 1\n",
    "#     score = [1 if acc[i] == label[i] else 0 for i in range(pred.shape[0])]\n",
    "#     return sum(score) / pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13157a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_accuracy(pred, label, threshold=0.5) :\n",
    "#     res = torch.argmax(pred, dim=1)\n",
    "    \n",
    "#     print(pred)\n",
    "#     print(res)\n",
    "#     print(label)\n",
    "\n",
    "#     score = [1 if res[i] == label[i] else 0 for i in range(pred.shape[0])]\n",
    "#     return sum(score) / pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07b7b55c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.684362:   0%|▎                                                                | 1/200 [00:00<02:32,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6.8339e-03, -2.9426e-05,  1.4647e-02,  5.7623e-02,  6.7890e-02,\n",
      "        -1.1416e-02,  4.2945e-02,  5.4396e-03,  1.2132e-02,  4.0854e-02,\n",
      "         6.5869e-02,  4.7168e-02,  7.1151e-02,  4.0935e-02,  3.5319e-02,\n",
      "         5.9047e-02,  3.0148e-02,  2.7733e-02,  2.2117e-02, -1.0734e-02,\n",
      "         1.5757e-02,  6.2070e-02,  1.3763e-02, -2.2622e-02,  6.1734e-02,\n",
      "         1.3989e-02,  3.9628e-02,  9.1197e-02,  4.9580e-02, -2.1283e-02,\n",
      "        -1.2941e-01, -1.2474e-01, -1.5841e-01, -1.4052e-01, -1.5020e-01,\n",
      "        -8.5914e-02, -3.7076e-02, -1.8862e-02,  3.2406e-02,  9.9804e-03,\n",
      "        -7.7734e-02, -6.4603e-02, -5.5397e-02, -5.4060e-02], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [0 / 200] Loss : 0.6891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.674145:   1%|▋                                                                | 2/200 [00:01<02:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0110, -0.0179, -0.0122, -0.0218, -0.0438, -0.0524, -0.1140, -0.1694,\n",
      "        -0.1720, -0.2285, -0.1251, -0.0408, -0.0308, -0.0211, -0.0868, -0.1094,\n",
      "        -0.0717, -0.0079,  0.0297, -0.0189, -0.0189, -0.1077, -0.1685, -0.1915,\n",
      "        -0.1209, -0.0953,  0.0101, -0.0038, -0.0394, -0.1211, -0.2464, -0.3764,\n",
      "        -0.4585, -0.3836, -0.3247, -0.2539, -0.1219, -0.0681,  0.0067, -0.0318,\n",
      "        -0.1260, -0.1119, -0.1196, -0.1104], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [1 / 200] Loss : 0.6871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.669530:   2%|▉                                                                | 3/200 [00:01<01:46,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0238,  0.0422,  0.1036,  0.0076,  0.0126,  0.0221,  0.0498,  0.0084,\n",
      "         0.0529,  0.0064,  0.0520,  0.0881, -0.0054,  0.0351,  0.0419,  0.0288,\n",
      "         0.0281,  0.0150,  0.0466,  0.0347,  0.0764,  0.0651,  0.0202, -0.0718,\n",
      "         0.0004,  0.0255,  0.0341,  0.0354,  0.0512,  0.0462, -0.0934, -0.2132,\n",
      "        -0.2910, -0.3661, -0.3092, -0.0853,  0.0993,  0.0782,  0.0341,  0.0734,\n",
      "         0.0562,  0.0580, -0.0095, -0.0058], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [2 / 200] Loss : 0.6767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.659258:   2%|█▎                                                               | 4/200 [00:02<01:39,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5.2039e-02,  4.7857e-02,  2.9609e-02,  5.6551e-02,  2.5192e-02,\n",
      "         1.5632e-02,  6.2499e-02,  1.9830e-02,  2.8830e-03,  1.9517e-02,\n",
      "        -4.7499e-02, -1.7721e-03,  7.4571e-02, -5.6901e-02, -1.2649e-01,\n",
      "        -2.0593e-01, -1.8330e-01, -6.8189e-02,  4.3868e-02,  5.0288e-02,\n",
      "         2.0418e-02, -8.0696e-02, -2.2096e-01, -2.3035e-01, -1.9093e-01,\n",
      "        -4.6040e-02,  5.9280e-02,  1.5142e-02,  6.3421e-02,  4.4079e-04,\n",
      "        -3.0734e-01, -5.9238e-01, -7.2014e-01, -8.0534e-01, -5.5618e-01,\n",
      "        -3.1137e-01,  9.1439e-03,  6.5146e-02,  6.4953e-02,  6.8523e-02,\n",
      "        -5.2300e-03, -1.5105e-02,  3.8045e-02,  1.1040e-01], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [3 / 200] Loss : 0.6717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.647478:   2%|█▋                                                               | 5/200 [00:02<01:35,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0782,  0.0640,  0.1444,  0.1797,  0.0538,  0.1340,  0.0755,  0.1250,\n",
      "         0.0895,  0.1008,  0.0628,  0.1168,  0.1231,  0.0830, -0.1077, -0.1037,\n",
      "         0.0209,  0.0851,  0.0750,  0.1558,  0.1085,  0.0863, -0.0213, -0.0917,\n",
      "         0.0614,  0.0907,  0.1145,  0.1329,  0.1029,  0.0576, -0.1814, -0.6596,\n",
      "        -0.8368, -0.9142, -0.6871, -0.1176,  0.0715,  0.1278,  0.1216,  0.1398,\n",
      "         0.1169,  0.1133,  0.0713,  0.1557], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [4 / 200] Loss : 0.661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.636572:   3%|█▉                                                               | 6/200 [00:03<01:32,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2066,  0.2186,  0.2570,  0.2154,  0.2193,  0.1314,  0.1731,  0.1967,\n",
      "         0.2347,  0.1364,  0.1358,  0.1681,  0.1508,  0.1305, -0.1749, -0.1420,\n",
      "        -0.1553,  0.0885,  0.1981,  0.2271,  0.1844,  0.0933,  0.0578, -0.0694,\n",
      "        -0.0046,  0.1140,  0.1717,  0.1834,  0.2605,  0.1829, -0.2536, -0.9271,\n",
      "        -1.3288, -1.2292, -0.7960,  0.0434,  0.2204,  0.2125,  0.2548,  0.2154,\n",
      "         0.2045,  0.2251,  0.1784,  0.2399], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [5 / 200] Loss : 0.6513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.631342:   4%|██▎                                                              | 7/200 [00:03<01:30,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3186,  0.3289,  0.3847,  0.3966,  0.3727,  0.3114,  0.2319,  0.3399,\n",
      "         0.3018,  0.2215,  0.2558,  0.3534,  0.2562,  0.0588, -0.3773, -0.6223,\n",
      "        -0.2832,  0.0062,  0.2847,  0.3298,  0.3017,  0.2186, -0.0222, -0.2159,\n",
      "        -0.0487,  0.2506,  0.3755,  0.3564,  0.4414,  0.1506, -0.4750, -1.2388,\n",
      "        -1.6971, -1.6229, -0.9901,  0.0485,  0.3367,  0.4444,  0.4019,  0.3753,\n",
      "         0.3359,  0.2806,  0.3164,  0.4055], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [6 / 200] Loss : 0.642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.633572:   4%|██▌                                                              | 8/200 [00:04<01:29,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5359,  0.4773,  0.5904,  0.6405,  0.5658,  0.5335,  0.4924,  0.4168,\n",
      "         0.4935,  0.4477,  0.5278,  0.5572,  0.3981,  0.0440, -0.3182, -0.5558,\n",
      "        -0.2176,  0.1236,  0.5067,  0.5821,  0.5617,  0.3459, -0.0170, -0.2918,\n",
      "         0.0256,  0.4308,  0.6382,  0.6516,  0.6716,  0.4810, -0.1389, -1.1829,\n",
      "        -1.7872, -1.7005, -0.8654,  0.2855,  0.6598,  0.7530,  0.7565,  0.7053,\n",
      "         0.5856,  0.5627,  0.6010,  0.7112], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [7 / 200] Loss : 0.6315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.630774:   4%|██▉                                                              | 9/200 [00:04<01:28,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5.7852e-01,  5.3525e-01,  6.4553e-01,  7.2541e-01,  6.8215e-01,\n",
      "         5.6689e-01,  5.1615e-01,  5.1710e-01,  5.2466e-01,  5.2808e-01,\n",
      "         6.0738e-01,  6.9767e-01,  4.2597e-01,  8.6420e-04, -7.3666e-01,\n",
      "        -9.7539e-01, -5.7524e-01,  9.9784e-02,  5.7653e-01,  7.7241e-01,\n",
      "         6.8028e-01,  3.9242e-01, -3.8712e-01, -8.0174e-01, -2.7363e-01,\n",
      "         3.4347e-01,  7.8671e-01,  9.7414e-01,  8.4959e-01,  6.3387e-01,\n",
      "        -4.2574e-01, -1.6526e+00, -2.1059e+00, -2.1049e+00, -1.5460e+00,\n",
      "         1.1119e-01,  8.3955e-01,  9.4593e-01,  9.8060e-01,  8.9012e-01,\n",
      "         7.3456e-01,  6.3316e-01,  7.6101e-01,  8.8338e-01], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [8 / 200] Loss : 0.6255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.626567:   5%|███▏                                                            | 10/200 [00:05<01:27,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6582,  0.7515,  0.9103,  0.8519,  0.8044,  0.6793,  0.6237,  0.5969,\n",
      "         0.5606,  0.5807,  0.7687,  0.8328,  0.6841,  0.3279, -0.5682, -0.6270,\n",
      "        -0.2647,  0.5049,  0.9624,  1.1258,  1.0281,  0.6677, -0.1889, -0.4477,\n",
      "         0.1751,  0.8851,  1.1612,  1.2468,  1.1911,  0.8513, -0.0103, -1.2261,\n",
      "        -1.9082, -1.9566, -1.6719,  0.2160,  1.0601,  1.1835,  1.1301,  1.1377,\n",
      "         0.8525,  0.8439,  0.9688,  1.0292], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [9 / 200] Loss : 0.6238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.609689:   6%|███▌                                                            | 11/200 [00:05<01:29,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3215,  0.5044,  0.5711,  0.5879,  0.5647,  0.3280,  0.2709,  0.1916,\n",
      "         0.1742,  0.2952,  0.5272,  0.6536,  0.4071, -0.0379, -0.6270, -0.7961,\n",
      "        -0.4984,  0.3351,  0.8672,  1.1424,  0.9887,  0.5301, -0.5633, -0.7490,\n",
      "        -0.1611,  0.9689,  1.3331,  1.3964,  1.3441,  0.9084, -0.1296, -1.2595,\n",
      "        -1.8694, -1.9099, -1.4250,  0.0415,  1.0838,  1.2593,  1.2026,  1.0857,\n",
      "         0.8814,  0.6660,  0.8165,  0.9718], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [10 / 200] Loss : 0.6131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.618088:   6%|███▊                                                            | 12/200 [00:06<01:27,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1044,  0.1636,  0.2922,  0.4073,  0.3016,  0.2080,  0.0071, -0.1651,\n",
      "        -0.1221,  0.0984,  0.3189,  0.4699,  0.3247, -0.1692, -0.6841, -0.8587,\n",
      "        -0.6025,  0.1862,  0.9064,  1.2412,  1.1234,  0.2518, -0.7605, -0.9569,\n",
      "        -0.0425,  1.1878,  1.4743,  1.5240,  1.4351,  0.9062, -0.1202, -1.2462,\n",
      "        -1.6675, -1.7951, -1.4441,  0.2208,  1.0691,  1.2607,  1.1970,  1.0721,\n",
      "         0.8064,  0.4476,  0.6768,  0.8897], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [11 / 200] Loss : 0.6093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.615804:   6%|████▏                                                           | 13/200 [00:06<01:26,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1489,  0.3350,  0.5134,  0.5862,  0.4864,  0.2535,  0.0773,  0.0177,\n",
      "        -0.0120,  0.1926,  0.6210,  0.7234,  0.6151,  0.1095, -0.5508, -0.6463,\n",
      "        -0.2974,  0.2564,  1.0843,  1.4661,  1.3290,  0.5532, -0.4404, -0.5658,\n",
      "         0.1755,  1.3956,  1.6657,  1.7628,  1.5483,  1.1070,  0.0163, -0.9152,\n",
      "        -1.4735, -1.7635, -1.1876,  0.3399,  1.1270,  1.2950,  1.2523,  1.0895,\n",
      "         0.6127,  0.3568,  0.4464,  0.7966], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [12 / 200] Loss : 0.6046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.601668:   7%|████▍                                                           | 14/200 [00:07<01:26,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1946,  0.4328,  0.5463,  0.7801,  0.5699,  0.2949,  0.1170,  0.0364,\n",
      "         0.0586,  0.2090,  0.5539,  0.8224,  0.6270,  0.1366, -0.4944, -0.6104,\n",
      "        -0.4149,  0.3865,  1.1206,  1.5557,  1.3704,  0.6521, -0.4712, -0.6560,\n",
      "         0.2599,  1.5221,  1.8385,  1.8379,  1.7154,  1.1358, -0.2464, -1.0111,\n",
      "        -1.6208, -1.7573, -1.3233,  0.2499,  1.1201,  1.3144,  1.2827,  1.1622,\n",
      "         0.5760,  0.0654,  0.0622,  0.5566], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [13 / 200] Loss : 0.6022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.532423:   8%|████▊                                                           | 15/200 [00:07<01:28,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4419,  0.5200,  0.8762,  1.0243,  0.8484,  0.6025,  0.3277,  0.3181,\n",
      "         0.1889,  0.5170,  0.7404,  0.9918,  0.8508,  0.2964, -0.3676, -0.6146,\n",
      "        -0.2567,  0.4346,  1.2633,  1.6165,  1.5826,  0.8567, -0.4623, -0.5543,\n",
      "         0.3691,  1.7432,  1.9562,  1.9709,  1.8150,  1.2946,  0.2284, -0.9687,\n",
      "        -1.6120, -1.6002, -1.4080,  0.5741,  1.2468,  1.3596,  1.4177,  1.2550,\n",
      "         0.8007,  0.1790,  0.0239,  0.6314], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [14 / 200] Loss : 0.5984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.592559:   8%|█████                                                           | 16/200 [00:07<01:28,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2226,  0.5208,  0.8947,  0.9419,  0.7557,  0.5626,  0.2519,  0.1961,\n",
      "         0.0184,  0.2801,  0.6363,  0.8568,  0.6888,  0.0941, -0.6652, -0.7900,\n",
      "        -0.5621,  0.0977,  1.1218,  1.5399,  1.4773,  0.6082, -0.9832, -0.8959,\n",
      "         0.1567,  1.7614,  2.0461,  1.9886,  1.8799,  1.0472, -0.1035, -1.1605,\n",
      "        -1.5177, -1.7575, -1.3994,  0.3455,  1.2229,  1.3686,  1.3910,  1.4028,\n",
      "         0.8513,  0.1599, -0.0543,  0.6357], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [15 / 200] Loss : 0.5875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.579851:   8%|█████▍                                                          | 17/200 [00:08<01:26,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0527,  0.3001,  0.6998,  0.9008,  0.7745,  0.4688,  0.2189,  0.0742,\n",
      "         0.0635,  0.2306,  0.6435,  0.7570,  0.5437, -0.1097, -0.6397, -0.8378,\n",
      "        -0.7016, -0.0556,  0.9662,  1.6122,  1.4933,  0.4017, -1.1744, -1.1794,\n",
      "         0.0798,  1.9230,  2.1163,  2.0411,  1.9073,  1.1456, -0.2597, -1.1375,\n",
      "        -1.6859, -1.6466, -1.2404,  0.9091,  1.4026,  1.4721,  1.5064,  1.4674,\n",
      "         1.2732,  0.4264,  0.1165,  0.8618], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [16 / 200] Loss : 0.5873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.579942:   9%|█████▊                                                          | 18/200 [00:08<01:25,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1813,  0.4363,  0.8825,  1.1444,  1.0185,  0.6095,  0.3748,  0.2761,\n",
      "         0.2482,  0.3665,  0.7120,  1.0089,  0.5666, -0.1320, -0.6520, -0.7717,\n",
      "        -0.6700, -0.2600,  1.0717,  1.7065,  1.7106,  0.7818, -0.9204, -0.9071,\n",
      "         0.3164,  1.9712,  2.1492,  2.1966,  1.9935,  1.1264, -0.1947, -1.2580,\n",
      "        -1.5183, -1.7401, -1.1848,  0.8776,  1.3955,  1.4986,  1.5770,  1.6184,\n",
      "         1.2384,  0.3752,  0.0617,  0.8745], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [17 / 200] Loss : 0.5811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.573771:  10%|██████                                                          | 19/200 [00:09<01:24,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1377,  0.4001,  1.0247,  1.2423,  1.0260,  0.6443,  0.3262,  0.3428,\n",
      "         0.4659,  0.6450,  0.9892,  1.1447,  0.6281, -0.1152, -0.5039, -0.7710,\n",
      "        -0.6283, -0.0976,  1.2263,  1.8394,  1.8355,  0.9658, -0.4485, -0.7099,\n",
      "         0.7090,  2.1275,  2.1836,  2.2024,  2.1025,  1.0051, -0.2841, -1.0015,\n",
      "        -1.5188, -1.7178, -1.4441,  0.9298,  1.4071,  1.4731,  1.5472,  1.5882,\n",
      "         1.5161,  0.0677, -0.0621,  0.6474], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [18 / 200] Loss : 0.5782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.572549:  10%|██████▍                                                         | 20/200 [00:09<01:23,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0316,  0.2999,  0.7746,  1.1020,  0.7288,  0.5401,  0.2795,  0.1520,\n",
      "         0.2000,  0.4206,  0.8110,  1.0743,  0.4294, -0.3095, -0.5610, -0.7133,\n",
      "        -0.6068, -0.3066,  1.0951,  1.7949,  1.7229,  1.0504, -0.5252, -0.7545,\n",
      "         0.6715,  2.1027,  2.2055,  2.2205,  2.1188,  1.3415, -0.4130, -1.0735,\n",
      "        -1.6193, -1.7925, -1.2659,  1.1710,  1.3790,  1.4144,  1.4979,  1.5772,\n",
      "         1.5607,  0.7620,  0.1526,  0.9060], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [19 / 200] Loss : 0.5701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.570748:  10%|██████▋                                                         | 21/200 [00:10<01:25,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0374,  0.1775,  0.7800,  0.9193,  0.6329,  0.2926,  0.1314, -0.0057,\n",
      "         0.0718,  0.3140,  0.7959,  0.7919,  0.2386, -0.3419, -0.6372, -0.7174,\n",
      "        -0.6091, -0.3361,  0.9013,  1.7294,  1.8113,  0.9697, -0.7719, -1.2602,\n",
      "         0.3763,  2.1376,  2.2590,  2.2216,  2.1359,  1.3961, -0.0200, -0.8216,\n",
      "        -1.6173, -1.7472, -1.5044,  1.1844,  1.3523,  1.4061,  1.4790,  1.6252,\n",
      "         1.6884,  1.0101,  0.3696,  0.8306], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [20 / 200] Loss : 0.5675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.559565:  11%|███████                                                         | 22/200 [00:10<01:23,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0847,  0.2309,  0.9566,  1.0692,  0.9527,  0.2846,  0.0757,  0.0383,\n",
      "         0.0878,  0.5242,  1.1776,  1.3109,  0.3846, -0.2773, -0.5299, -0.6938,\n",
      "        -0.5580, -0.2796,  1.0709,  1.7543,  1.7219,  1.1738, -0.8336, -1.1296,\n",
      "         0.5727,  2.1820,  2.2919,  2.2207,  2.2534,  1.6625,  0.3476, -1.0107,\n",
      "        -1.5433, -1.9170, -1.4815,  1.1114,  1.3097,  1.3364,  1.4203,  1.5529,\n",
      "         1.6442,  1.0606,  0.0991,  0.7022], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [21 / 200] Loss : 0.5681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.565840:  12%|███████▎                                                        | 23/200 [00:11<01:22,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0436,  0.3309,  1.1386,  1.5736,  1.0960,  0.3920,  0.2236,  0.1849,\n",
      "         0.3710,  1.0925,  1.4343,  1.5086,  0.5946, -0.1251, -0.4345, -0.5219,\n",
      "        -0.5439, -0.2970,  1.3077,  1.8145,  1.7540,  1.1977, -0.9205, -1.3428,\n",
      "         0.2749,  2.2997,  2.3077,  2.3164,  2.2820,  1.9078,  0.0483, -0.8222,\n",
      "        -1.4701, -1.9168, -1.7010,  1.1838,  1.2814,  1.3350,  1.3846,  1.5742,\n",
      "         1.7051,  0.5710, -0.5145,  0.0101], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [22 / 200] Loss : 0.5619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.555076:  12%|███████▋                                                        | 24/200 [00:11<01:23,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1420,  0.2452,  1.1170,  1.4662,  0.8298,  0.2879,  0.1423,  0.0502,\n",
      "         0.0840,  0.8970,  1.4992,  1.5634,  0.5212, -0.3545, -0.5258, -0.5836,\n",
      "        -0.5558, -0.4711,  1.4019,  1.7839,  1.7996,  1.2419, -0.9762, -1.2628,\n",
      "         1.5029,  2.3641,  2.3181,  2.2657,  2.3537,  1.7102, -0.0912, -0.8170,\n",
      "        -1.4957, -1.8567, -1.7555,  1.5300,  1.3103,  1.3312,  1.4786,  1.5945,\n",
      "         1.8413,  0.8179, -0.7717,  0.2534], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [23 / 200] Loss : 0.5567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.546383:  12%|████████                                                        | 25/200 [00:12<01:22,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1802,  0.1243,  1.3037,  1.6776,  1.1191,  0.2834,  0.0553, -0.0598,\n",
      "        -0.2022,  0.5202,  1.6571,  1.5318,  0.1865, -0.4006, -0.6063, -0.5470,\n",
      "        -0.6219, -0.6028,  1.1660,  1.7243,  1.7449,  1.5445, -0.8513, -0.7966,\n",
      "         1.7028,  2.2555,  2.2149,  2.2661,  2.3611,  2.1361,  0.4823, -0.5248,\n",
      "        -1.4316, -1.8137, -1.0967,  1.6182,  1.3684,  1.2368,  1.3724,  1.5940,\n",
      "         1.9591,  1.4401, -0.0707,  0.9114], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [24 / 200] Loss : 0.5475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.540897:  13%|████████▎                                                       | 26/200 [00:12<01:21,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.9795e-01,  6.2818e-02,  1.0102e+00,  1.3804e+00,  1.2849e+00,\n",
      "         6.1251e-02, -4.0121e-02, -1.5541e-01, -1.5776e-03,  6.7571e-01,\n",
      "         1.2824e+00,  1.1638e+00, -8.2018e-03, -4.5186e-01, -4.7551e-01,\n",
      "        -4.7446e-01, -4.6484e-01, -5.5342e-01,  8.6309e-01,  1.7156e+00,\n",
      "         1.6601e+00,  1.4308e+00, -1.3461e+00, -1.3942e+00,  8.9150e-01,\n",
      "         2.3742e+00,  2.2283e+00,  2.2718e+00,  2.4885e+00,  2.0906e+00,\n",
      "         5.0355e-02, -9.6010e-01, -1.5333e+00, -1.9891e+00, -1.3784e+00,\n",
      "         1.5155e+00,  1.2688e+00,  1.2443e+00,  1.3049e+00,  1.5326e+00,\n",
      "         1.9202e+00,  1.4298e+00, -5.5505e-01,  5.5750e-01], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [25 / 200] Loss : 0.5371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.522817:  14%|████████▋                                                       | 27/200 [00:13<01:20,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2286,  0.3116,  1.6623,  1.8438,  1.5831,  0.3815,  0.0374,  0.0212,\n",
      "         0.3018,  1.4212,  2.0700,  1.8780, -0.3571, -0.6546, -0.5202, -0.5214,\n",
      "        -0.6752, -0.6818,  1.5433,  1.7554,  1.7617,  1.5651, -1.7124, -1.6313,\n",
      "         1.7065,  2.4031,  2.2180,  2.2614,  2.4759,  2.1767,  1.0284, -0.6780,\n",
      "        -1.6155, -2.0485, -1.4906,  1.8816,  1.3483,  1.3027,  1.3524,  1.6018,\n",
      "         2.0258,  1.8130, -0.2703,  1.3082], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [26 / 200] Loss : 0.5244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.519513:  14%|████████▉                                                       | 28/200 [00:13<01:19,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2379,  0.8682,  1.8409,  2.2966,  1.7673,  0.5691,  0.1570,  0.4073,\n",
      "         0.6569,  1.9287,  2.3149,  2.1819,  0.2701, -0.7304, -0.8229, -0.6321,\n",
      "        -0.7738, -1.0731,  1.6262,  1.6507,  1.7157,  1.7749, -0.8973, -1.5127,\n",
      "         1.9701,  2.2373,  2.0610,  2.2257,  2.4211,  2.5780,  0.7481, -0.5290,\n",
      "        -1.1579, -2.2466, -1.5007,  1.9204,  1.3735,  1.2551,  1.3415,  1.5341,\n",
      "         1.9676,  1.9320, -0.5242,  1.7212], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [27 / 200] Loss : 0.5188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.583946:  14%|█████████▎                                                      | 29/200 [00:14<01:18,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5677, -0.4171, -0.0552,  0.9260,  0.2354, -0.2228, -0.2864, -0.3407,\n",
      "        -0.8014, -0.7526, -0.1841, -0.4692, -0.6948, -0.4899, -0.4680, -0.4698,\n",
      "        -0.4505, -0.9257,  0.7653,  1.5841,  1.7175,  1.5194, -2.1238, -1.9708,\n",
      "        -0.5167,  2.3210,  2.1492,  2.2467,  2.7032,  1.7180, -0.9813, -1.5426,\n",
      "        -2.1764, -2.5500, -2.7884,  1.4504,  1.2582,  1.1601,  1.1990,  1.4708,\n",
      "         2.0737, -0.8469, -1.5857, -0.5263], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [28 / 200] Loss : 0.5609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.572922:  15%|█████████▌                                                      | 30/200 [00:14<01:18,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2400,  1.2949,  2.3311,  2.2627,  1.2215,  0.1693,  0.1157,  0.1651,\n",
      "         0.4427,  1.6002,  2.1699,  1.8826,  0.2617, -0.1762, -0.1087, -0.1793,\n",
      "        -0.3989, -0.7645,  1.4116,  1.2352,  1.1792,  1.4666, -0.1143,  0.1576,\n",
      "         2.1344,  1.8122,  1.6532,  1.7762,  2.0330,  2.2874,  1.1867, -0.1417,\n",
      "        -1.3787, -1.8743,  0.7361,  1.6332,  1.0057,  0.8043,  0.9595,  1.1271,\n",
      "         1.5682,  2.3180, -0.4785,  0.8892], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [29 / 200] Loss : 0.5949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.591321:  16%|█████████▉                                                      | 31/200 [00:14<01:17,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3375, -0.4267,  0.0204,  0.4281,  0.1613, -0.0331, -0.0195, -0.1208,\n",
      "        -0.5747, -0.8914, -0.2324, -0.0123, -0.3027, -0.1187, -0.1969, -0.2247,\n",
      "        -0.3429, -0.6823, -0.1049,  1.0990,  1.0500, -0.3468, -1.8111, -1.7050,\n",
      "        -1.4529,  2.0945,  1.8546,  1.9974,  2.2400, -1.0444, -1.3935, -1.6418,\n",
      "        -1.9302, -2.1512, -2.5998, -1.7703,  0.6031,  0.5675,  0.6633,  0.9100,\n",
      "         1.8491, -2.0685, -1.1345, -0.8339], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [30 / 200] Loss : 0.6519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.554298:  16%|██████████▏                                                     | 32/200 [00:15<01:17,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0996,  0.6271,  1.9240,  1.9035,  1.0319,  0.2064,  0.1106,  0.1748,\n",
      "         0.5358,  1.5333,  1.8406,  1.7569,  0.1235, -0.1883, -0.3339, -0.3573,\n",
      "        -0.5604, -0.8450,  0.9400,  0.9362,  0.8039,  1.0047, -0.8806, -0.8461,\n",
      "         1.5670,  1.4324,  1.3664,  1.5480,  2.0749,  2.0878,  0.5481, -0.2154,\n",
      "        -1.2806, -2.0645, -2.1772,  1.4599,  0.7206,  0.5187,  0.6182,  0.8642,\n",
      "         1.4973,  0.9758, -0.4996,  0.3374], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [31 / 200] Loss : 0.5573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.552898:  16%|██████████▌                                                     | 33/200 [00:15<01:16,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4879,  1.6007,  2.2390,  2.4424,  1.5785,  0.5768,  0.3860,  0.5117,\n",
      "         0.9794,  2.0751,  2.0625,  1.9789,  1.3423, -0.7524, -0.9086, -1.0054,\n",
      "        -1.1712, -0.6819,  1.4155,  1.2296,  1.2010,  1.2820,  1.2442,  0.1478,\n",
      "         1.8850,  1.6426,  1.7272,  1.8851,  2.2860,  2.6423,  1.4811,  0.7431,\n",
      "        -0.4845, -1.0125, -0.5385,  1.7301,  1.0744,  0.8970,  0.9286,  1.2328,\n",
      "         1.7754,  2.5476,  0.4960,  2.0317], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [32 / 200] Loss : 0.5638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.531836:  17%|██████████▉                                                     | 34/200 [00:16<01:16,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6025, -0.5137,  0.4167,  1.1070,  0.1805, -0.2121, -0.2480, -0.3367,\n",
      "        -0.5458,  0.0661,  1.1683,  0.9549, -0.6428, -0.8602, -0.8377, -1.0341,\n",
      "        -1.1106, -1.4303,  0.2138,  1.4114,  1.3285,  0.3919, -1.6911, -1.5106,\n",
      "        -0.4264,  1.9310,  1.9385,  2.2518,  2.6772,  1.1578, -0.2380, -0.9618,\n",
      "        -1.6331, -2.2493, -2.2236,  1.4216,  1.2800,  1.0085,  1.1039,  1.3633,\n",
      "         2.1504, -0.4564, -0.7438,  0.1807], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [33 / 200] Loss : 0.5492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.519526:  18%|███████████▏                                                    | 35/200 [00:16<01:16,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4294, -0.2475,  0.1418,  0.9962,  0.2075, -0.1052, -0.0876, -0.1114,\n",
      "        -0.3399, -0.1173,  1.3545,  0.8841, -0.4116, -0.4701, -0.5472, -0.7210,\n",
      "        -0.8369, -1.1175,  0.7017,  1.4045,  1.4213,  0.4259, -1.5140, -1.4654,\n",
      "        -0.5458,  1.9155,  2.0004,  2.3697,  2.8216,  0.7969, -0.1106, -0.7595,\n",
      "        -1.7453, -2.1901, -2.2613,  2.0266,  1.4309,  1.1398,  1.2052,  1.4620,\n",
      "         2.3467,  0.7062, -0.5250,  0.7468], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [34 / 200] Loss : 0.5392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.527955:  18%|███████████▌                                                    | 36/200 [00:17<01:15,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1829,  0.0869,  1.4433,  2.1631,  1.1113,  0.2848,  0.2073,  0.1947,\n",
      "         0.2531,  1.4468,  2.1503,  2.0874,  0.3519, -0.2557, -0.5206, -0.7194,\n",
      "        -0.8554, -1.1092,  1.4588,  1.4589,  1.5702,  1.5923, -1.1940, -1.4687,\n",
      "         1.4766,  1.9145,  1.9674,  2.2641,  2.9079,  2.4788,  0.7329, -0.2973,\n",
      "        -1.5625, -2.2531, -1.2602,  2.4721,  1.4465,  1.1834,  1.2754,  1.5560,\n",
      "         2.2057,  2.9740,  1.2766,  2.2912], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [35 / 200] Loss : 0.5172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.488663:  18%|███████████▊                                                    | 37/200 [00:17<01:17,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1727,  0.1206,  1.5041,  1.9740,  1.3541,  0.2799,  0.1432,  0.1181,\n",
      "         0.0336,  1.2169,  2.3547,  1.9627,  0.1335, -0.5468, -0.6743, -0.9290,\n",
      "        -1.2269, -1.4084,  1.5118,  1.4746,  1.4914,  1.5852, -1.7426, -1.6750,\n",
      "         0.9513,  2.0653,  2.0659,  2.4322,  3.0638,  2.0087,  0.2013, -0.7994,\n",
      "        -1.8431, -2.5389, -2.2356,  2.5904,  1.5140,  1.2277,  1.2484,  1.6365,\n",
      "         2.5661,  2.3656, -0.3000,  1.9443], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [36 / 200] Loss : 0.5059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.492851:  19%|████████████▏                                                   | 38/200 [00:18<01:16,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2852,  0.3041,  1.8479,  2.3980,  1.4843,  0.1463,  0.1116,  0.0036,\n",
      "        -0.1065,  1.0874,  2.3893,  2.1704, -0.3328, -0.9651, -0.9465, -1.0209,\n",
      "        -1.4445, -1.6274,  1.2721,  1.3980,  1.4455,  1.4431, -1.8441, -1.9016,\n",
      "         0.8234,  2.0044,  2.0784,  2.3235,  3.2896,  2.0592,  0.0821, -0.9768,\n",
      "        -2.2021, -2.7535, -2.1379,  2.3370,  1.4431,  1.0761,  1.1358,  1.5012,\n",
      "         2.3579,  0.8028, -1.1337, -0.0623], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [37 / 200] Loss : 0.4978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.489409:  20%|████████████▍                                                   | 39/200 [00:18<01:15,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1873,  1.2280,  2.7209,  2.8933,  2.1874,  0.3382,  0.0807,  0.0616,\n",
      "         0.5258,  1.9465,  2.6457,  2.2025,  0.0138, -1.1999, -0.9446, -1.0215,\n",
      "        -1.3663, -1.4452,  1.2034,  1.0784,  1.1870,  1.2371, -1.4541, -1.6752,\n",
      "         1.3066,  1.7310,  1.7975,  2.0705,  2.8815,  3.0563,  1.0181, -0.0684,\n",
      "        -1.4713, -2.5126, -0.4780,  2.3204,  1.2542,  0.9213,  1.0374,  1.3351,\n",
      "         2.1276,  2.8127,  0.0350,  1.8758], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [38 / 200] Loss : 0.4891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.486141:  20%|████████████▊                                                   | 40/200 [00:19<01:14,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5681,  0.5193,  1.9666,  2.7124,  1.2994,  0.0388,  0.0739, -0.0332,\n",
      "        -0.3299,  0.4097,  1.9779,  1.9275, -0.4385, -0.6144, -0.1662, -0.5179,\n",
      "        -0.8224, -1.9105,  0.8748,  0.9802,  1.1466,  1.3429, -2.0827, -1.7030,\n",
      "         0.3392,  1.8402,  1.7906,  2.2785,  3.1200,  2.6819,  0.8263, -0.3405,\n",
      "        -2.0848, -2.8659, -1.3192,  2.4382,  1.1926,  0.9216,  0.9446,  1.2568,\n",
      "         2.2475,  1.9131, -1.1471,  0.7204], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [39 / 200] Loss : 0.4784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.473352:  20%|█████████████                                                   | 41/200 [00:19<01:17,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6396,  1.1103,  2.8328,  3.1950,  2.3451,  0.0487, -0.0493, -0.1947,\n",
      "        -0.2722,  0.8289,  2.5043,  2.1835, -1.0326, -0.9470, -0.8070, -1.1919,\n",
      "        -1.7280, -2.0964,  0.8839,  1.2390,  1.3220,  1.7810, -2.2831, -2.1378,\n",
      "         1.7219,  2.1714,  2.2124,  2.5168,  3.2873,  3.0519,  1.2937, -0.3226,\n",
      "        -2.1182, -3.1524, -1.8117,  3.0124,  1.5291,  1.1543,  1.1167,  1.5096,\n",
      "         2.3392,  2.7079, -0.2681,  2.3861], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [40 / 200] Loss : 0.4658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.458740:  21%|█████████████▍                                                  | 42/200 [00:20<01:17,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4986,  1.1500,  3.2173,  3.3138,  2.1324,  0.0713, -0.0301, -0.0367,\n",
      "        -0.5438,  0.9909,  2.3332,  1.9656, -1.1601, -1.3350, -0.8807, -1.3844,\n",
      "        -1.5482, -2.4282,  0.5922,  1.1817,  1.2840,  1.8570, -2.3525, -2.2434,\n",
      "         1.4674,  2.1394,  2.0868,  2.5304,  3.6156,  3.2628,  1.2466, -0.4837,\n",
      "        -2.4686, -3.4639, -2.3192,  3.0846,  1.7387,  1.1673,  1.0560,  1.4948,\n",
      "         2.3014,  2.3740, -0.7926,  1.3674], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [41 / 200] Loss : 0.4546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.459893:  22%|█████████████▊                                                  | 43/200 [00:20<01:16,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6320,  2.1502,  3.6348,  3.8233,  1.3961,  0.0998,  0.2494,  0.2502,\n",
      "        -0.1252,  2.0168,  3.2079,  2.4554, -1.4918, -0.6966, -0.3353, -0.6212,\n",
      "        -1.5978, -2.4813,  0.3086,  0.8620,  1.1058,  1.7632, -2.5475, -2.2265,\n",
      "         1.9517,  1.8986,  1.8467,  2.2010,  3.3887,  3.5954,  1.7155,  0.1693,\n",
      "        -2.3199, -3.4854, -3.0574,  2.9832,  1.4106,  1.0037,  0.9524,  1.2076,\n",
      "         2.2193,  2.2234, -1.8085,  2.1038], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [42 / 200] Loss : 0.4388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.447336:  22%|██████████████                                                  | 44/200 [00:21<01:14,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8798,  2.0674,  3.3200,  3.6525,  1.3593,  0.0359,  0.2637,  0.1867,\n",
      "        -0.5123,  2.1801,  3.2488,  2.7743, -1.5808, -1.2512, -1.2544, -0.9739,\n",
      "        -1.6191, -2.7305,  0.4797,  0.7854,  1.0432,  1.9945, -2.7566, -2.3237,\n",
      "         2.1770,  1.8310,  1.8296,  2.3093,  3.2619,  3.7571,  1.3266, -0.0654,\n",
      "        -2.2361, -3.6714, -3.1632,  3.3553,  1.5191,  0.9349,  0.9376,  1.1897,\n",
      "         2.1795,  2.7954, -1.8528,  2.6670], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [43 / 200] Loss : 0.4201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.437089:  22%|██████████████▍                                                 | 45/200 [00:21<01:13,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3416,  2.0053,  2.5095,  3.9200,  3.2749,  0.2217,  0.5514,  0.4597,\n",
      "         0.8684,  2.4513,  3.3171,  3.0740, -1.9248, -2.0743, -1.2134, -1.6452,\n",
      "        -2.5985, -2.9391,  0.4279,  0.8841,  1.1228,  2.3693, -2.6023, -2.2381,\n",
      "         1.5030,  1.8626,  1.7526,  2.4738,  3.4549,  3.5804,  1.5378,  0.0303,\n",
      "        -2.4897, -3.8039, -2.9116,  3.5363,  1.6636,  1.1231,  1.0393,  1.2904,\n",
      "         2.4329,  2.7406, -2.2233,  2.2347], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [44 / 200] Loss : 0.4215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.432384:  23%|██████████████▋                                                 | 46/200 [00:22<01:12,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3756,  1.6054,  3.8950,  3.5942,  0.9753,  0.3862,  0.6792,  0.5149,\n",
      "        -0.4405,  1.7824,  3.3175,  3.4127, -1.3712, -2.0301, -0.5599, -0.8087,\n",
      "        -2.0906, -3.2878,  0.2135,  0.7241,  0.9898,  2.5313, -2.9715, -2.3521,\n",
      "         0.9159,  1.8249,  1.6255,  2.0379,  3.4953,  3.4099,  1.3248,  0.3669,\n",
      "        -1.8005, -3.7639, -3.0793,  3.5538,  1.7151,  0.9237,  0.8757,  1.1410,\n",
      "         2.0361,  3.2627, -1.9629,  1.7854], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [45 / 200] Loss : 0.4013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.417827:  24%|███████████████                                                 | 47/200 [00:22<01:11,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3494,  2.3164,  4.5663,  4.8379,  2.9055,  0.3640,  0.6977,  0.5552,\n",
      "         0.0921,  1.6166,  3.5852,  3.8220, -1.4360, -3.2309, -2.0911, -2.6219,\n",
      "        -3.0786, -2.8543,  0.3524,  0.6851,  0.8739,  2.3449, -2.9557, -2.3317,\n",
      "         2.6201,  1.6451,  1.5044,  1.9255,  3.7428,  3.4706,  1.5276,  0.7801,\n",
      "        -1.5402, -4.0082, -2.4832,  4.0354,  1.6880,  0.9372,  0.7800,  1.1337,\n",
      "         1.9502,  3.2652, -1.7995,  3.6073], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [46 / 200] Loss : 0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.411501:  24%|███████████████▎                                                | 48/200 [00:22<01:10,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.5684,  2.7139,  4.4098,  4.8703,  2.9933,  0.4220,  0.8327,  0.4875,\n",
      "        -1.4936,  0.7969,  2.4299,  3.2870, -1.9046, -2.5918, -2.2166, -1.9738,\n",
      "        -2.6902, -3.9398,  0.0611,  0.6335,  0.8949,  2.6178, -3.3997, -2.7351,\n",
      "         3.0321,  1.5969,  1.4598,  2.1561,  3.7461,  3.5377,  1.4525,  0.2989,\n",
      "        -2.1562, -4.6426, -2.2221,  4.1273,  1.7859,  0.9516,  0.8144,  1.1339,\n",
      "         2.0722,  3.2704, -2.9253,  3.3459], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [47 / 200] Loss : 0.3801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.390509:  24%|███████████████▋                                                | 49/200 [00:23<01:10,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.4206,  1.9262,  4.8772,  4.6431,  3.4638, -0.6367,  0.2879,  0.7165,\n",
      "        -0.6522,  1.1326,  3.7940,  3.6696, -2.2948, -3.5311, -2.9528, -3.2116,\n",
      "        -4.0420, -3.8896,  0.0915,  0.6544,  0.9837,  2.8781, -3.4474, -2.7627,\n",
      "         2.1771,  1.5665,  1.4867,  2.2555,  3.6816,  3.6120,  1.4533,  0.3969,\n",
      "        -1.8955, -4.4179,  1.5918,  4.0608,  1.9648,  1.0744,  0.9387,  1.0622,\n",
      "         1.9815,  3.2487, -1.2281,  4.5776], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [48 / 200] Loss : 0.3726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.444802:  25%|████████████████                                                | 50/200 [00:23<01:09,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.4864,  1.8866,  3.9460,  4.5896,  2.2866, -1.0510,  0.6770,  0.7816,\n",
      "        -1.2444, -0.0160,  2.7291,  2.4844, -3.4025, -2.7186, -2.3621, -1.1998,\n",
      "        -4.4434, -4.7475, -0.2510,  0.7788,  1.1437,  2.5849, -3.7289, -3.6077,\n",
      "        -1.1100,  1.7912,  1.5654,  2.5177,  4.0912,  3.1037,  0.9869, -0.3999,\n",
      "        -2.7085, -5.6809, -3.4152,  3.9672,  2.1428,  1.0726,  0.8542,  1.1000,\n",
      "         2.4929,  1.2744, -4.1298,  2.2855], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [49 / 200] Loss : 0.3823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.517460:  26%|████████████████▎                                               | 51/200 [00:24<01:09,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.3692,  3.0167,  4.6126,  4.6822,  3.1066, -0.4591,  0.7247,  0.5711,\n",
      "        -0.2971,  2.7980,  4.2445,  4.1605, -1.6221, -3.0879, -1.4557, -3.1204,\n",
      "        -4.2062, -3.8692,  1.0821,  0.8604,  0.8439,  3.3741, -3.2819, -2.6091,\n",
      "         3.0116,  1.4040,  1.5108,  2.1756,  4.1853,  3.0038,  1.2498,  0.4656,\n",
      "        -2.8317, -5.5972, -3.8367,  4.0732,  1.6524,  0.7162,  0.4334,  0.8369,\n",
      "         2.2952,  3.7280, -3.0345,  0.8217], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [50 / 200] Loss : 0.4372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.570857:  26%|████████████████▋                                               | 52/200 [00:24<01:08,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.8075, -2.3131,  0.0070,  1.0560,  0.0216,  0.0692,  0.0925, -0.5525,\n",
      "        -1.3452,  0.0598,  1.9537,  3.9001,  2.4795,  1.4994,  1.2095,  1.4934,\n",
      "         1.8035, -4.2732,  0.7656,  0.2415,  0.5968,  2.6104, -3.0339, -2.7399,\n",
      "         2.8762,  1.2376,  0.8935,  1.7316,  3.9437,  2.0889,  0.7600,  0.0460,\n",
      "        -2.2488, -5.5849, -4.1349,  4.0993,  0.9844,  0.0946, -0.1408,  0.2597,\n",
      "         1.4093,  4.1763, -1.6653,  4.5003], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [51 / 200] Loss : 0.5918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.521752:  26%|████████████████▉                                               | 53/200 [00:25<01:08,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.4564,  1.8723,  3.3599,  3.6573,  2.8955, -0.7989, -1.1324,  0.0245,\n",
      "         1.8347,  3.6894,  4.2085,  3.5253, -1.1608, -3.2222, -0.8798,  0.6039,\n",
      "        -3.1859, -2.8441,  1.0634,  1.0079,  0.7430,  2.6494,  0.9717, -1.6020,\n",
      "         2.8918,  1.6301,  1.3764,  2.1948,  3.6516,  2.7017,  1.1891,  0.5946,\n",
      "        -1.1456, -2.8838,  1.7870,  3.6383,  1.7492,  0.7118,  0.7459,  1.0433,\n",
      "         2.0720,  3.8613,  2.8306,  4.5683], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [52 / 200] Loss : 0.5481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.461744:  27%|█████████████████▎                                              | 54/200 [00:25<01:07,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.0284, -1.7005, -0.3781,  0.2560, -0.9364, -2.5631,  0.2971,  1.1864,\n",
      "        -0.4214,  0.4249,  1.0617, -0.4782, -4.6725, -3.2832,  0.1736,  0.3288,\n",
      "        -1.4419, -4.7138, -2.9559, -0.5314,  0.1805, -0.7585, -2.5312, -1.9457,\n",
      "        -2.6354,  0.6243,  1.3402,  1.8422,  1.1369, -0.0637, -0.5180, -1.2025,\n",
      "        -2.8896, -5.2883, -4.1069,  0.3385,  1.7713,  1.2218,  0.9742,  1.3470,\n",
      "         0.9991, -3.8612, -4.4806, -1.6278], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [53 / 200] Loss : 0.5882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.431985:  28%|█████████████████▌                                              | 55/200 [00:26<01:07,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.7476,  2.1326,  2.6168,  2.8075,  2.4933, -0.4347,  0.5352,  0.7725,\n",
      "         0.5481,  1.6567,  2.2358,  2.7048,  0.6979, -3.4570, -3.8693, -2.5272,\n",
      "        -2.1204, -0.6814,  2.2605,  1.6428,  1.7895,  3.2643, -1.4082, -1.0042,\n",
      "         0.7905,  2.8890,  2.5694,  3.3229,  3.1124,  1.4758,  0.9924,  0.5070,\n",
      "        -0.6583, -2.4632, -0.4436,  3.1704,  2.7681,  1.4716,  1.1813,  1.9742,\n",
      "         3.5383,  1.3973, -1.0374,  1.4519], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [54 / 200] Loss : 0.4309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.427551:  28%|█████████████████▉                                              | 56/200 [00:26<01:06,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.2465e+00,  3.3060e+00,  3.7324e+00,  3.6725e+00,  2.9511e+00,\n",
      "         1.0373e-01,  7.8725e-01,  7.8763e-01, -3.5451e-01,  1.1700e+00,\n",
      "         2.3585e+00,  2.8633e+00, -3.7026e-01, -3.4360e+00, -4.0152e+00,\n",
      "        -3.4050e+00, -1.6035e+00,  6.5211e-01,  8.2805e-01, -2.1982e-02,\n",
      "        -8.2360e-02,  1.1055e+00, -1.8139e+00, -1.9304e+00,  2.0297e+00,\n",
      "         4.8859e-01, -3.2454e-03,  1.1034e+00,  2.9619e+00,  2.0469e+00,\n",
      "         9.1073e-01,  4.0276e-01, -7.6304e-01, -2.5501e+00,  1.0093e+00,\n",
      "         3.4920e+00,  3.2892e-01, -3.8008e-01, -6.3136e-01, -1.7838e-01,\n",
      "         1.2253e+00,  2.6722e+00, -5.5589e-01,  3.3668e+00], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [55 / 200] Loss : 0.4453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.410979:  28%|██████████████████▏                                             | 57/200 [00:27<01:06,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0579,  3.1864,  3.6007,  3.8717,  0.9514,  0.7749,  1.0108,  1.0294,\n",
      "         0.1435,  0.1414,  2.0386,  2.3542, -0.4647, -2.1071, -3.6793, -3.4286,\n",
      "        -3.6056, -0.1146,  0.9036,  0.5247,  0.7273,  2.2380, -2.4534, -2.5979,\n",
      "         1.6631,  1.0979,  0.5915,  1.3042,  3.3259,  1.8764,  0.4040, -0.2178,\n",
      "        -3.2318, -4.7591, -2.6058,  4.8261,  1.0187,  0.0162, -0.0775,  0.2778,\n",
      "         2.0760,  1.9685, -3.1336,  3.5417], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [56 / 200] Loss : 0.4195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.403735:  29%|██████████████████▌                                             | 58/200 [00:27<01:05,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5036,  4.1996,  4.9148,  4.6854,  3.0554,  0.4757,  1.1944,  0.9379,\n",
      "        -0.3623,  0.2729,  2.9350,  3.2621, -1.0430, -3.0097, -3.9878, -4.6470,\n",
      "        -4.1304, -1.7258,  1.8239,  1.1445,  1.3806,  3.1130, -3.5995, -3.3787,\n",
      "         2.9938,  2.4884,  1.8621,  2.6946,  4.5103,  2.2363,  0.8691, -0.0366,\n",
      "        -3.2023, -4.4510, -2.0040,  5.2095,  2.7692,  1.1997,  0.9637,  1.5672,\n",
      "         3.1538,  3.1479, -0.3178,  4.8166], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [57 / 200] Loss : 0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.392147:  30%|██████████████████▉                                             | 59/200 [00:28<01:05,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.9358,  3.4690,  4.2639,  4.5808,  2.8502, -0.3976,  0.9440,  0.9196,\n",
      "        -0.9372,  0.6584,  2.9203,  1.9031, -1.9103, -2.7811, -4.2080, -3.7637,\n",
      "        -4.1269, -2.7433,  0.6995,  0.3798,  0.8398,  2.7141, -3.6369, -3.1529,\n",
      "         1.8671,  2.2729,  1.7185,  2.7376,  4.7298,  2.6961,  1.0294,  0.1774,\n",
      "        -3.1141, -4.8080, -2.8589,  5.2703,  3.0294,  1.3847,  0.8127,  1.3007,\n",
      "         3.0056,  0.6621, -3.2071,  3.3515], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [58 / 200] Loss : 0.3654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.377927:  30%|███████████████████▏                                            | 60/200 [00:28<01:04,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.5716,  3.2206,  4.1946,  4.9096,  3.3442, -0.1877,  0.9416,  0.7987,\n",
      "        -1.2890,  0.4252,  2.5972,  1.0717, -2.3589, -2.4569, -1.5792, -2.0710,\n",
      "        -3.7355, -3.8680, -0.4116, -0.1747,  0.1818,  2.2203, -3.5874, -2.7553,\n",
      "         2.5974,  1.8979,  1.5384,  2.3350,  4.6039,  3.0648,  1.4688,  0.3847,\n",
      "        -2.5478, -5.2624, -2.4374,  4.8301,  2.5302,  0.6813,  0.5078,  0.6517,\n",
      "         2.4095,  1.0078, -3.2803,  4.2234], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [59 / 200] Loss : 0.349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.377027:  30%|███████████████████▌                                            | 61/200 [00:28<01:04,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0489,  3.3096,  4.7781,  4.9500,  4.5141, -1.2979,  0.8670,  0.6525,\n",
      "        -0.8681,  1.5179,  3.7643,  3.4981, -2.7938, -3.7532, -2.2888, -1.1769,\n",
      "        -2.0559, -3.8208,  0.2491,  0.1756,  0.4541,  3.4627, -4.0306, -2.9201,\n",
      "         3.0078,  2.4704,  2.0094,  2.9771,  4.9616,  3.4935,  1.7908,  0.7657,\n",
      "        -2.2858, -4.7109, -2.7333,  5.3716,  3.0345,  1.3432,  0.7137,  0.8919,\n",
      "         2.6272,  3.4346, -2.4744,  4.1003], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [60 / 200] Loss : 0.3313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.373385:  31%|███████████████████▊                                            | 62/200 [00:29<01:05,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9088,  4.0030,  5.0545,  5.1647,  4.6385, -1.9484,  0.4073,  0.3081,\n",
      "        -1.1466,  2.4260,  3.4050,  4.6923, -2.2059, -4.5621, -3.9451, -4.2976,\n",
      "        -4.2192, -3.4433,  1.2233,  0.6150,  0.9127,  3.8910, -4.0954, -3.0279,\n",
      "         3.0504,  2.8972,  2.1751,  2.8599,  5.0042,  3.9223,  2.0865,  0.6739,\n",
      "        -2.1111, -5.2338, -2.6407,  5.4599,  3.0008,  0.8778,  0.6807,  0.8337,\n",
      "         2.3897,  3.7451, -2.0736,  4.6193], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [61 / 200] Loss : 0.3238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.354328:  32%|████████████████████▏                                           | 63/200 [00:29<01:05,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.6544,  2.7213,  4.8260,  5.0098,  4.2386, -1.7890,  1.0473,  0.8720,\n",
      "        -1.2524,  1.5624,  3.8458,  4.7375, -3.2282, -4.3913, -4.0018, -4.1543,\n",
      "        -4.2981, -4.0507,  0.7454,  0.2808,  0.5620,  3.6271, -4.4992, -3.2692,\n",
      "         3.2522,  2.2167,  1.6425,  2.4879,  4.6900,  3.7611,  1.7302,  0.1741,\n",
      "        -3.8511, -5.5691, -3.7580,  5.0486,  1.7938,  0.2957,  0.0771,  0.2440,\n",
      "         2.0275,  3.1165, -3.1444,  3.8145], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [62 / 200] Loss : 0.3159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.350938:  32%|████████████████████▍                                           | 64/200 [00:30<01:04,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.7484,  2.8245,  5.0118,  5.5577,  4.4130, -0.5770,  1.6203,  1.0904,\n",
      "        -1.5250,  1.5842,  4.4067,  4.7499, -3.1104, -4.7087, -3.6914, -2.0377,\n",
      "        -5.0096, -3.7915,  1.3075,  1.3137,  0.6366,  4.5630, -4.4289, -3.9427,\n",
      "         4.4925,  2.5330,  1.8397,  2.6626,  4.9248,  4.0032,  1.7608,  0.8109,\n",
      "        -3.5389, -5.3583, -3.1696,  5.6121,  1.9788,  0.3956,  0.0585,  0.3170,\n",
      "         2.4685,  3.9577, -0.5948,  5.5082], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [63 / 200] Loss : 0.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.346984:  32%|████████████████████▊                                           | 65/200 [00:30<01:04,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.2562,  2.9605,  5.2051,  5.4562,  4.0434, -2.1074,  0.3731,  1.7168,\n",
      "        -0.6128,  2.2027,  4.3718,  4.5036, -3.0371, -5.5393, -4.3733, -4.6868,\n",
      "        -5.6115, -3.3943,  1.0161,  1.0654,  1.0792,  4.1928, -4.6242, -4.1468,\n",
      "         3.5631,  2.2790,  1.9188,  2.7484,  5.0891,  4.0349,  2.1065,  0.5057,\n",
      "        -3.0764, -5.4945, -1.5448,  5.9566,  1.8105,  0.4730,  0.0800,  0.4278,\n",
      "         2.7974,  3.0890, -1.2164,  3.6077], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [64 / 200] Loss : 0.3038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.343391:  33%|█████████████████████                                           | 66/200 [00:31<01:03,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.7226,  1.9771,  4.8337,  5.2071,  4.0403, -1.5933,  1.8169,  1.5200,\n",
      "        -0.8032,  1.5061,  4.2908,  4.4171, -3.7103, -5.4879, -4.6923, -4.7323,\n",
      "        -5.7234, -5.2093,  0.7404,  1.0400,  0.9349,  4.1759, -5.2525, -4.6319,\n",
      "         2.5520,  2.1322,  1.5318,  2.3857,  4.9918,  3.3145,  1.3312, -0.0726,\n",
      "        -4.1335, -6.3727, -3.8285,  5.7914,  2.0582,  0.6420,  0.0189,  0.5574,\n",
      "         3.1099,  2.2909, -3.4935,  2.3919], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [65 / 200] Loss : 0.2967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.346058:  34%|█████████████████████▍                                          | 67/200 [00:31<01:03,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.0071,  2.0690,  4.8698,  5.7671,  4.5455, -2.4559,  1.6575,  1.3673,\n",
      "        -1.4449,  2.0112,  4.1489,  4.7709, -4.1068, -5.1092, -5.7546, -5.1125,\n",
      "        -6.1175, -4.8894,  1.5395,  1.0679,  0.9103,  4.4252, -5.1383, -4.6653,\n",
      "         3.8946,  1.9113,  1.9773,  2.4527,  5.3821,  3.2775,  1.4896,  0.2325,\n",
      "        -3.7885, -6.1817, -3.2234,  6.0385,  2.2362,  0.5863,  0.2807,  0.7797,\n",
      "         3.3605,  2.1065, -4.7353,  3.5128], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [66 / 200] Loss : 0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.338068:  34%|█████████████████████▊                                          | 68/200 [00:32<01:03,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.5333,  3.6599,  5.1955,  5.4444,  4.9061, -3.2574,  1.7549,  0.9506,\n",
      "        -1.5610,  1.9130,  3.9788,  5.3344, -4.2561, -5.5982, -5.7603, -6.1084,\n",
      "        -6.2864, -4.5452,  1.4877,  1.0466,  0.9150,  3.4199, -4.9721, -3.9275,\n",
      "         3.6496,  2.0784,  1.6920,  2.5877,  5.4283,  3.0508,  1.4619,  0.1639,\n",
      "        -3.8299, -6.5713, -2.0318,  6.3393,  3.0091,  0.9497, -0.0951,  0.4892,\n",
      "         3.5143,  2.5878, -4.6496,  3.2484], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [67 / 200] Loss : 0.2825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.326296:  34%|██████████████████████                                          | 69/200 [00:32<01:02,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.5042,  3.8946,  5.3671,  5.6865,  4.7468, -3.9214,  1.7582,  1.1300,\n",
      "        -1.4644,  1.3507,  3.7091,  5.0024, -4.4383, -5.4397, -6.1494, -4.2599,\n",
      "        -6.3664, -4.9530,  2.1918,  1.5796,  0.3577,  3.3292, -5.4024, -3.9972,\n",
      "         2.7376,  3.0619,  1.9599,  3.3712,  5.6111,  2.5501,  1.2309,  0.1333,\n",
      "        -3.5438, -6.9587, -4.0805,  6.8236,  3.6294,  1.2093,  0.3222,  1.2172,\n",
      "         3.8325,  4.7603, -4.3228,  2.3462], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [68 / 200] Loss : 0.2672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.324668:  35%|██████████████████████▍                                         | 70/200 [00:33<01:01,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.1703,  3.8167,  4.9184,  5.8312,  4.4777, -3.0071,  1.2124,  1.3570,\n",
      "        -1.2854,  1.9750,  4.0340,  5.4247, -4.4695, -6.5556, -6.3878, -5.5698,\n",
      "        -6.5014, -5.3470,  1.0891,  1.5400, -0.0714,  3.2680, -5.2791, -4.1319,\n",
      "         1.8780,  2.6579,  1.6356,  3.2420,  5.6663,  2.8273,  1.2844,  0.0804,\n",
      "        -3.5586, -7.0875, -2.5498,  7.0486,  3.2809,  0.8922, -0.0458,  0.6072,\n",
      "         3.7436,  4.6067, -3.8220,  4.9293], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [69 / 200] Loss : 0.263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.324594:  36%|██████████████████████▋                                         | 71/200 [00:33<01:01,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.1940,  4.5798,  5.8623,  5.8030,  4.4484, -4.1688,  1.9986,  1.4277,\n",
      "        -1.6651,  0.8882,  2.9902,  4.5216, -4.5250, -5.9536, -4.0794, -6.2959,\n",
      "        -6.1653, -5.2494,  2.6362,  2.1007,  0.3416,  2.9920, -5.8484, -4.5344,\n",
      "         3.2416,  3.6416,  1.9204,  3.3585,  5.9722,  2.9641,  1.4676,  0.3208,\n",
      "        -3.7557, -7.4636, -2.7923,  7.3866,  2.9231,  0.7261,  0.0704,  0.3785,\n",
      "         4.1243,  5.4244, -2.2778,  4.5953], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [70 / 200] Loss : 0.2597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.319442:  36%|███████████████████████                                         | 72/200 [00:34<01:01,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.8449,  4.1342,  6.0734,  5.0080,  4.1750, -3.7416,  2.1823,  1.7454,\n",
      "        -1.9719,  1.6742,  4.9836,  5.1085, -4.2309, -6.0957, -3.9559, -4.1969,\n",
      "        -6.0176, -6.0412,  2.1967,  1.7973,  0.2911,  3.3140, -5.6924, -5.3185,\n",
      "         3.3243,  3.2718,  1.5006,  3.2535,  6.1101,  3.2032,  1.3228,  0.2283,\n",
      "        -3.3794, -7.6581, -3.3405,  7.6165,  2.7467,  0.3057, -0.7185,  0.6136,\n",
      "         5.0336,  3.9862, -3.9503,  5.1818], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [71 / 200] Loss : 0.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.310218:  36%|███████████████████████▎                                        | 73/200 [00:34<01:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.9163,  4.1298,  6.0253,  5.6105,  4.2197, -4.2938,  2.5861,  2.4047,\n",
      "        -1.8310,  3.3373,  4.6427,  6.0574, -4.4207, -6.8154, -5.9300, -5.3716,\n",
      "        -6.9052, -4.5795,  3.0437,  2.4448,  0.1498,  2.3334, -6.0240, -4.8399,\n",
      "         4.0709,  3.5029,  2.7412,  3.9378,  6.2995,  3.3525,  1.6136,  0.6578,\n",
      "        -3.3830, -7.2174, -3.4329,  7.7612,  3.6103,  1.0645,  0.2703,  0.9301,\n",
      "         5.3423,  4.9899, -2.3125,  4.8099], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [72 / 200] Loss : 0.2471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.314226:  37%|███████████████████████▋                                        | 74/200 [00:35<01:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.0951,  3.6123,  5.2384,  5.6520,  2.2260, -4.1079,  2.3609,  1.7847,\n",
      "        -1.8780,  1.9961,  4.3976,  5.0788, -5.5673, -5.9571, -7.2518, -5.6998,\n",
      "        -6.4875, -6.3949,  2.1549,  1.6360, -0.7098,  3.5640, -6.5245, -5.7150,\n",
      "         3.9144,  3.2653,  1.9166,  3.6033,  6.1063,  2.8491,  1.4466,  0.4247,\n",
      "        -4.2367, -7.9457, -4.4160,  7.8543,  3.5097,  0.7021, -0.4392,  0.6921,\n",
      "         5.2260,  2.8780, -4.1363,  3.4879], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [73 / 200] Loss : 0.2411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.320921:  38%|████████████████████████                                        | 75/200 [00:35<00:59,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.8076,  2.8604,  5.4535,  4.5477,  4.2636, -3.7761,  2.4191,  1.7400,\n",
      "        -2.2136,  2.7133,  3.9614,  5.0129, -5.4545, -5.1322, -5.1083, -6.5534,\n",
      "        -6.9058, -6.7149,  2.0697,  3.8829, -0.2000,  2.2652, -6.4002, -5.6996,\n",
      "         4.3316,  4.2829,  2.2258,  4.2776,  6.2754,  3.0513,  1.5637,  0.3931,\n",
      "        -4.0655, -7.8111, -3.4821,  8.1145,  3.3564,  0.8237,  0.1567,  1.5299,\n",
      "         5.9499,  4.8738, -2.3176,  4.1764], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [74 / 200] Loss : 0.2401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.354591:  38%|████████████████████████▎                                       | 76/200 [00:36<00:58,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.1147,  3.8570,  5.9035,  5.8744,  4.9633, -3.8918,  2.2004,  1.6323,\n",
      "        -2.0887,  2.2817,  4.7042,  5.7628, -4.2634, -6.8076, -6.5381, -6.2228,\n",
      "        -6.6755, -6.7713,  1.8699,  3.9319, -0.3344,  2.2444, -6.5537, -5.8248,\n",
      "         2.8827,  4.4180,  2.3935,  4.5173,  6.2428,  3.0388,  1.5735,  0.4789,\n",
      "        -4.4835, -7.8219, -4.2884,  8.2077,  3.3884,  0.7448,  0.0096,  1.1291,\n",
      "         6.9031,  4.2245, -4.8583,  3.8182], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [75 / 200] Loss : 0.2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.353752:  38%|████████████████████████▋                                       | 77/200 [00:36<00:57,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.8792,  4.2431,  5.5540,  6.1104,  4.3294, -3.8530,  2.8493,  2.4468,\n",
      "        -2.3079,  2.2919,  4.6104,  5.0499, -5.4265, -7.5668, -7.5108, -6.5517,\n",
      "        -7.8027, -5.6443,  3.3559,  5.6144,  0.1981,  5.8574, -6.6524, -5.7641,\n",
      "         3.5831,  6.3434,  3.1078,  5.2654,  6.2247,  2.8100,  1.2964,  0.5422,\n",
      "        -3.9662, -8.4858, -4.5229,  8.3165,  3.4828,  1.2590,  0.5671,  2.0998,\n",
      "         6.7010,  5.3155, -3.6580,  4.2303], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [76 / 200] Loss : 0.2403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.366100:  39%|████████████████████████▉                                       | 78/200 [00:37<00:57,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.6809,  4.6855,  5.5902,  5.0126,  4.9295, -3.5510,  2.4947,  2.0446,\n",
      "        -2.6892,  3.5472,  5.2323,  5.5564, -3.8708, -7.6358, -8.6020, -8.3702,\n",
      "        -7.7303, -5.3088,  2.0365,  3.0486, -1.0595,  3.5883, -7.2904, -6.2565,\n",
      "         2.0181,  6.9422,  4.2233,  5.0864,  5.8561,  2.4477,  1.1288, -0.0746,\n",
      "        -3.6098, -8.7087, -4.4968,  8.2887,  3.9660,  1.5666,  0.7519,  1.8828,\n",
      "         7.6389,  3.6072, -3.3305,  5.6933], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [77 / 200] Loss : 0.2458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.349411:  40%|█████████████████████████▎                                      | 79/200 [00:37<00:56,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.4229,  4.1054,  5.8730,  6.1472,  5.8041, -3.8659,  2.4805,  2.2567,\n",
      "        -0.8766,  3.3100,  5.3401,  6.9009, -5.5280, -7.6601, -5.8547, -7.3571,\n",
      "        -6.5081, -6.3136,  3.4429,  0.5322, -2.4773,  2.7250, -6.7923, -5.5181,\n",
      "         4.6838,  3.4601,  0.9017,  2.5740,  5.6658,  2.6014,  1.2269,  0.1942,\n",
      "        -4.5223, -8.1991, -2.6769,  8.0500,  1.1868, -1.0633, -1.8908, -1.0139,\n",
      "         4.1592,  6.7921, -3.9418,  5.8974], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [78 / 200] Loss : 0.2835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.308693:  40%|█████████████████████████▌                                      | 80/200 [00:38<00:56,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.0193,  4.5773,  5.6144,  5.5331,  4.8628, -4.8345,  2.4860,  3.2566,\n",
      "        -1.4006,  3.5888,  5.5830,  4.3968, -6.1068, -6.5721, -4.7719, -6.0909,\n",
      "        -7.4211, -6.7862,  2.1847,  4.9467, -1.2874,  3.7929, -6.5057, -5.3501,\n",
      "         2.8103,  6.6709,  3.0483,  4.4335,  6.0211,  2.6940,  1.2788,  0.3706,\n",
      "        -3.3183, -9.1425, -5.6756,  7.9591,  3.7143,  1.0004,  0.2969,  1.4673,\n",
      "         6.4041,  4.0795, -2.0523,  4.6492], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [79 / 200] Loss : 0.2546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.307271:  40%|█████████████████████████▉                                      | 81/200 [00:38<00:55,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.2524,  3.9400,  5.4274,  5.3281,  4.2854, -5.3293,  2.0775,  2.5792,\n",
      "        -3.4474,  2.7055,  5.2554,  5.8201, -5.9354, -8.0152, -7.6068, -7.3530,\n",
      "        -8.2835, -6.2122,  3.0077,  5.7054, -0.4399,  5.6612, -6.6471, -5.2098,\n",
      "         5.0068,  5.6886,  2.1336,  4.2683,  5.5877,  2.7710,  1.2833,  0.1580,\n",
      "        -3.6005, -8.5620, -5.4329,  8.3374,  3.8735,  1.0188,  0.5284,  1.0014,\n",
      "         6.0703,  4.3457, -1.9646,  5.3982], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [80 / 200] Loss : 0.2531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.305250:  41%|██████████████████████████▏                                     | 82/200 [00:38<00:55,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.3117,  2.4660,  4.7831,  4.3907,  3.5167, -6.4487,  2.7856,  2.2217,\n",
      "        -4.0063,  1.3390,  5.7057,  6.3457, -3.2690, -7.3751, -6.9415, -6.8395,\n",
      "        -8.1039, -6.1800,  1.8355,  8.0503,  1.4494,  7.8291, -6.9648, -5.9475,\n",
      "         5.0034,  7.3920,  4.6299,  6.1423,  5.7634,  2.2099,  1.1754,  0.2558,\n",
      "        -3.7464, -9.0768, -6.0069,  8.0164,  5.2435,  2.5506,  1.4465,  3.3575,\n",
      "         8.1059,  1.8889, -5.7046,  3.8214], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [81 / 200] Loss : 0.2873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.299168:  42%|██████████████████████████▌                                     | 83/200 [00:39<00:54,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.3900,  4.6009,  7.1328,  7.0491,  6.2399, -3.1786,  2.6056,  2.8740,\n",
      "        -1.1322,  3.0656,  7.8648,  7.6371, -3.7889, -3.4350, -6.6418, -6.2779,\n",
      "        -7.2553, -7.0298,  4.7300, -2.1479, -2.7029,  0.6294, -3.5171, -2.3468,\n",
      "         5.8352, -1.4222, -2.5303, -1.5362,  2.9194,  2.5351,  1.3780,  0.6011,\n",
      "        -3.3632, -9.3803, -6.6952,  4.1959, -1.9857, -2.8799, -3.0645, -2.9417,\n",
      "        -1.4200,  5.9984, -4.4002,  5.4514], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [82 / 200] Loss : 0.4251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.331895:  42%|██████████████████████████▉                                     | 84/200 [00:39<00:54,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.5483,  4.0564,  5.3467,  5.6748,  5.1579, -4.6703,  2.5644,  0.8413,\n",
      "        -2.9296,  1.6531,  4.9802,  6.3847, -3.6394, -4.8862, -2.3162, -7.3332,\n",
      "        -7.1110, -6.9188,  2.9952,  7.0198,  3.6257,  7.8754, -4.1540, -3.9671,\n",
      "         1.0538,  7.7183,  5.9832,  6.2941,  5.5479,  2.2887,  1.2397,  0.2774,\n",
      "        -3.7936, -9.1694, -7.1977,  7.1722,  5.4237,  3.2427,  2.4018,  3.6457,\n",
      "         7.6077,  0.2158, -3.8769,  3.3331], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [83 / 200] Loss : 0.3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.421371:  42%|███████████████████████████▏                                    | 85/200 [00:40<00:53,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.6799,  3.5376,  6.1284,  5.3394,  3.0608, -2.9312,  2.7197,  1.0298,\n",
      "        -1.9799,  1.8183,  5.8748,  7.8590, -2.8908, -4.1495, -5.2141, -3.7054,\n",
      "        -6.8782, -5.5274,  6.2397,  4.3368,  1.5656,  6.3934, -6.1677, -4.4843,\n",
      "         4.1173,  5.9782,  3.9200,  4.7742,  4.8875,  2.5480,  1.2614,  0.6540,\n",
      "        -3.6597, -8.3870, -1.7859,  7.1415,  3.6975,  2.2932,  1.8349,  2.3998,\n",
      "         5.2448,  6.3906, -1.2235,  4.8494], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [84 / 200] Loss : 0.3337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.313302:  43%|███████████████████████████▌                                    | 86/200 [00:40<00:53,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.8995e+00,  2.9891e+00,  4.3665e+00,  4.8199e+00,  2.5837e+00,\n",
      "        -1.6729e+00,  3.0672e+00,  2.9780e+00, -3.7591e+00,  2.6479e+00,\n",
      "         4.9462e+00,  7.1373e+00, -3.1457e+00, -5.8222e+00, -6.6316e+00,\n",
      "        -7.6089e+00, -7.2737e+00, -5.9573e+00,  4.4895e+00,  4.0694e-01,\n",
      "        -5.5988e-01,  2.3103e+00, -6.1210e+00, -4.8827e+00,  3.9851e+00,\n",
      "         3.0847e+00,  1.8807e+00,  1.8642e+00,  3.1144e+00,  1.8911e+00,\n",
      "         9.6781e-01,  3.3918e-01, -3.5225e+00, -8.4621e+00, -6.8400e-01,\n",
      "         4.3196e+00,  9.7241e-01,  3.1146e-02, -1.1733e-01,  5.8006e-03,\n",
      "         1.8626e+00,  4.4772e+00, -4.1797e+00,  3.4564e+00], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [85 / 200] Loss : 0.2878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.339915:  44%|███████████████████████████▊                                    | 87/200 [00:41<00:52,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.5262e+00,  1.5572e+00,  4.1965e+00,  3.7439e+00,  2.0488e+00,\n",
      "        -5.2674e+00,  3.4455e+00,  2.5099e+00, -3.9425e+00,  2.8726e+00,\n",
      "         4.2530e+00,  5.2966e+00, -4.5524e+00, -5.7182e+00, -7.7753e+00,\n",
      "        -8.0484e+00, -7.6308e+00, -5.9594e+00,  1.8578e+00,  3.6788e-01,\n",
      "        -7.7228e-01, -1.7738e-01, -5.9906e+00, -5.0724e+00,  2.6219e+00,\n",
      "         2.9039e+00,  1.3963e+00,  1.7774e+00,  2.6655e+00,  1.5862e+00,\n",
      "         7.8450e-01,  6.3213e-03, -3.6400e+00, -7.6279e+00, -2.9325e+00,\n",
      "         3.6966e+00,  7.1138e-01, -1.3827e-01, -3.5910e-01, -1.1381e-01,\n",
      "         1.8656e+00,  4.5115e+00, -4.6119e+00,  2.0295e+00], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [86 / 200] Loss : 0.3101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.312514:  44%|████████████████████████████▏                                   | 88/200 [00:41<00:52,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.7685,  4.7720,  5.6336,  5.7038,  5.2809, -2.6009,  2.2760,  2.1519,\n",
      "        -3.3256,  4.8089,  5.2290,  5.9838, -1.5139, -6.5308, -7.8170, -7.7525,\n",
      "        -6.5109, -3.5561,  5.2387,  1.0440, -0.3103, -0.0391, -4.6691, -3.3849,\n",
      "         4.0957,  3.5217,  2.0402,  2.3604,  3.2149,  2.5163,  1.6748,  1.1000,\n",
      "        -1.6924, -6.0391,  0.1386,  3.6285,  1.3274,  0.5399,  0.2676,  0.5401,\n",
      "         2.0864,  5.7201,  0.7662,  4.3650], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [87 / 200] Loss : 0.3356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.302655:  44%|████████████████████████████▍                                   | 89/200 [00:42<00:51,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.4617,  4.2733,  5.4234,  5.1967,  2.1170,  0.6639,  2.7066,  2.7193,\n",
      "        -0.1512,  0.6201,  5.2344,  6.4611, -3.7631, -1.4066, -2.6896, -2.8971,\n",
      "        -4.7025, -6.7829, -2.0927,  1.8796,  0.7100,  3.0857, -1.4921, -3.4399,\n",
      "        -1.1459,  5.0555,  3.2088,  3.6114,  3.7088,  1.8055,  0.9765, -0.2039,\n",
      "        -5.6392, -8.3547, -8.3799,  6.0207,  2.1766,  1.2593,  0.8920,  1.3469,\n",
      "         3.2980,  2.2164, -5.9461,  1.2150], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [88 / 200] Loss : 0.3167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.311853:  45%|████████████████████████████▊                                   | 90/200 [00:42<00:51,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.7336,  5.7611,  5.7917,  5.7187,  6.1206,  2.7669, -0.9695,  0.0616,\n",
      "         2.8140,  5.2264,  6.1879,  6.4346, -1.4041, -6.2261, -7.2115, -7.1051,\n",
      "        -6.6751, -2.2673,  6.4595,  2.5912,  0.6305,  1.0951, -3.4753, -3.3371,\n",
      "         5.8947,  4.7246,  3.1480,  3.4723,  4.0160,  2.2623,  0.9638,  0.3691,\n",
      "        -3.7234, -8.3423, -6.4887,  6.0885,  2.7590,  1.5838,  1.2770,  1.5845,\n",
      "         3.9135,  5.0767, -3.7774,  3.8475], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [89 / 200] Loss : 0.3393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.304499:  46%|█████████████████████████████                                   | 91/200 [00:43<00:50,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.1960e+00,  8.5085e-01,  4.1534e+00,  3.4653e+00, -1.2180e-01,\n",
      "        -5.5740e-01,  4.0988e+00,  2.6784e+00,  2.3707e-01,  9.5978e-01,\n",
      "         4.2043e+00,  5.8459e-01, -4.4103e+00, -1.6853e+00, -1.7196e+00,\n",
      "        -4.9107e+00, -6.4203e+00, -6.0602e+00,  4.5309e-01,  5.7241e-01,\n",
      "        -4.1450e-03,  2.0095e+00, -5.2368e+00, -4.4228e+00,  3.1803e+00,\n",
      "         3.1912e+00,  2.1251e+00,  2.4765e+00,  2.6657e+00,  7.7253e-01,\n",
      "         5.5575e-02, -6.5468e-01, -6.2332e+00, -8.1644e+00, -8.4610e+00,\n",
      "         5.6119e+00,  1.8626e+00,  5.3368e-01,  3.0951e-01,  4.7462e-01,\n",
      "         2.5623e+00, -1.8255e+00, -6.0842e+00,  6.2822e-01], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [90 / 200] Loss : 0.3282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.321675:  46%|█████████████████████████████▍                                  | 92/200 [00:43<00:51,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.3895,  3.6643,  4.9419,  5.0894,  3.6644, -2.2250,  3.9078,  3.3649,\n",
      "        -0.1557,  2.7060,  5.0837,  4.6597, -4.1422, -3.6291, -5.7610, -5.6242,\n",
      "        -6.4161, -2.6373,  4.5460,  0.7353, -0.4397,  0.9674, -2.5708, -2.1582,\n",
      "         4.2658,  2.3906,  1.4556,  1.6972,  2.9774,  1.8599,  1.0481,  0.4657,\n",
      "        -3.1131, -7.5794, -1.4067,  4.6565,  1.1995,  0.3113,  0.0145,  0.3734,\n",
      "         1.6905,  6.0443,  1.6555,  4.6197], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [91 / 200] Loss : 0.2833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.304982:  46%|█████████████████████████████▊                                  | 93/200 [00:44<00:50,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.6622,  2.8140,  4.8030,  5.3677,  3.3147, -1.6191,  2.7413,  1.4992,\n",
      "        -0.6947,  1.0509,  3.8768,  4.7946, -5.1048, -4.3651, -4.6444, -3.6287,\n",
      "        -5.8343, -2.9764,  2.3174,  1.8443, -0.0964,  2.9386, -3.9845, -2.5681,\n",
      "         2.3601,  3.6731,  2.4559,  2.7465,  3.3362,  1.9760,  1.2935,  0.8638,\n",
      "        -2.5460, -7.3663, -3.3280,  5.6585,  2.1225,  1.0779,  0.6812,  1.2333,\n",
      "         2.9438,  4.4834,  0.8939,  4.0368], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [92 / 200] Loss : 0.2571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.295605:  47%|██████████████████████████████                                  | 94/200 [00:44<00:50,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.7899,  2.2100,  5.0213,  5.5858,  3.2307, -2.5662,  2.2480,  0.0223,\n",
      "        -1.7483,  0.2559,  4.2409,  4.3238, -5.8277, -4.3662, -5.7917, -4.5894,\n",
      "        -4.7854, -5.0245,  2.0300,  3.1836,  0.5645,  4.6633, -3.9585, -2.1650,\n",
      "        -1.0325,  4.5975,  3.0680,  3.8299,  3.6284,  2.1248,  1.2978,  0.5341,\n",
      "        -4.1638, -7.7659, -6.2074,  6.4940,  2.6845,  1.2354,  0.8267,  1.4083,\n",
      "         3.9817,  4.1797, -2.9256,  3.9713], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [93 / 200] Loss : 0.2693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.293072:  48%|██████████████████████████████▍                                 | 95/200 [00:45<00:49,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.8002,  3.6412,  6.4961,  6.1956,  4.7317, -3.9211,  3.5569,  2.2129,\n",
      "        -1.8143,  2.2392,  4.9293,  5.4573, -5.1890, -6.2774, -5.7590, -6.0406,\n",
      "        -5.6588, -4.2602,  3.2595,  2.0213, -0.0793,  3.9274, -4.8740, -3.1904,\n",
      "         1.7010,  4.6685,  3.1407,  3.6392,  4.1894,  2.6331,  1.7672,  1.1778,\n",
      "        -3.6755, -7.7127, -5.1018,  6.5613,  2.5712,  0.9353,  0.6015,  1.0686,\n",
      "         3.4356,  3.7280, -2.2341,  3.8395], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [94 / 200] Loss : 0.2238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.292558:  48%|██████████████████████████████▋                                 | 96/200 [00:45<00:48,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.9027,  5.1268,  7.2889,  6.9032,  5.0604, -3.7210,  2.9973,  3.3793,\n",
      "        -1.0008,  3.9107,  6.1925,  6.9098, -5.1073, -6.2625, -7.2389, -6.4678,\n",
      "        -5.8708, -2.8206,  4.7547,  2.2047, -0.4465,  2.0251, -5.2959, -3.9832,\n",
      "         0.9597,  4.4552,  2.0382,  3.3443,  4.5955,  3.2633,  1.9091,  0.9818,\n",
      "        -4.6260, -7.4485, -3.2175,  7.0596,  1.7177,  0.4301, -0.0357,  0.5381,\n",
      "         3.5760,  5.7836, -4.5102,  4.4900], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [95 / 200] Loss : 0.2286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.275520:  48%|███████████████████████████████                                 | 97/200 [00:46<00:49,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.8876,  6.1890,  7.5871,  7.2915,  6.1326, -3.5158,  3.4362,  2.8795,\n",
      "        -1.2642,  4.1055,  6.6721,  7.0742, -5.4316, -5.9355, -6.5458, -4.5497,\n",
      "        -6.3220, -3.2420,  4.5893,  2.6191, -0.4575,  5.0066, -6.0024, -4.1530,\n",
      "         3.8382,  4.4285,  2.5142,  3.0987,  5.3944,  3.2178,  2.1692,  0.8667,\n",
      "        -5.2801, -7.7406, -3.5475,  7.2070,  2.0406,  0.5085,  0.1112,  0.3893,\n",
      "         3.9224,  3.4241, -4.0762,  4.6448], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [96 / 200] Loss : 0.2216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.278384:  49%|███████████████████████████████▎                                | 98/200 [00:46<00:49,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.2993,  5.9252,  7.7946,  7.3420,  5.9158, -3.8368,  2.9429,  2.1290,\n",
      "        -2.1974,  3.0021,  6.2291,  7.6475, -4.1618, -6.8609, -6.3212, -6.4258,\n",
      "        -6.6375, -4.2350,  4.4219,  3.9695, -0.6644,  3.0563, -6.2625, -4.9593,\n",
      "         3.8807,  5.7641,  3.8663,  4.9607,  5.7308,  3.4214,  1.8233,  0.8261,\n",
      "        -5.4815, -8.1497, -5.2354,  8.5355,  3.3727,  1.2291,  0.6242,  1.5112,\n",
      "         5.2089,  2.1355, -5.1695,  4.6364], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [97 / 200] Loss : 0.2085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.266603:  50%|███████████████████████████████▋                                | 99/200 [00:47<00:50,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.4295,  4.9667,  7.4309,  7.3860,  6.2580, -4.3751,  3.0368,  2.9332,\n",
      "        -1.5932,  3.0610,  6.4487,  7.6594, -3.7253, -6.7928, -6.9966, -7.4817,\n",
      "        -6.7910, -3.7133,  5.7774,  3.9556, -0.9405,  4.5619, -5.9469, -4.8742,\n",
      "         3.7721,  6.5410,  3.5364,  4.9971,  5.6256,  3.3317,  1.9284,  0.7565,\n",
      "        -4.4932, -8.0725, -3.7850,  8.7701,  3.2573,  0.9693,  0.5404,  1.3396,\n",
      "         6.4566,  4.7090, -3.6861,  4.4926], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [98 / 200] Loss : 0.2046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.268135:  50%|███████████████████████████████▌                               | 100/200 [00:47<00:50,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.6385,  4.7545,  7.7277,  7.4570,  5.8937, -5.0641,  3.3895,  3.5087,\n",
      "        -2.4359,  2.3118,  6.6714,  7.5630, -5.4957, -7.0410, -7.7884, -7.7971,\n",
      "        -6.9688, -3.2539,  2.6851,  5.4679, -1.1827,  2.7750, -5.1234, -4.0404,\n",
      "         3.6774,  5.5434,  3.8771,  4.7171,  5.3333,  2.7719,  1.7346,  0.7823,\n",
      "        -4.5368, -7.9158, -3.8381,  8.7717,  3.2575,  0.7923,  0.3336,  1.2553,\n",
      "         5.9889,  4.3333, -3.5408,  4.9705], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [99 / 200] Loss : 0.1966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.256170:  50%|███████████████████████████████▊                               | 101/200 [00:48<00:49,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.5437,  3.1373,  7.0761,  6.8456,  5.8062, -4.6941,  3.8950,  4.2655,\n",
      "        -2.5136,  2.0997,  6.1648,  7.2681, -5.1232, -7.0713, -7.3554, -7.8939,\n",
      "        -7.1877, -5.1475,  4.9323,  3.4971, -1.3884,  4.5476, -6.4260, -4.6949,\n",
      "         3.9887,  5.7187,  2.4067,  4.0210,  5.2759,  2.4171,  1.2182,  0.3929,\n",
      "        -5.4517, -7.7423, -5.7044,  8.5932,  2.9722,  0.8568,  0.2641,  1.2479,\n",
      "         5.7769,  3.2624, -3.8521,  4.7789], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [100 / 200] Loss : 0.2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.262382:  51%|████████████████████████████████▏                              | 102/200 [00:48<00:47,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.7234,  4.8536,  7.2066,  6.7437,  5.7276, -5.0395,  3.4840,  4.6104,\n",
      "        -2.2167,  2.1218,  6.3965,  7.3784, -5.8591, -7.3065, -8.1629, -7.6486,\n",
      "        -7.6339, -4.5287,  3.8150,  5.7182, -1.2240,  5.0486, -7.0286, -4.9539,\n",
      "         3.8487,  6.6865,  4.6096,  5.1729,  4.9687,  2.5951,  1.1321,  0.3670,\n",
      "        -4.6594, -8.4152, -4.9904,  8.8097,  3.3471,  0.9488,  0.4945,  1.4007,\n",
      "         7.1055,  2.7751, -3.3783,  4.6844], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [101 / 200] Loss : 0.1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.271340:  52%|████████████████████████████████▍                              | 103/200 [00:48<00:46,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.8368,  5.4411,  7.5782,  7.2102,  5.9028, -5.5531,  4.2115,  4.4557,\n",
      "        -3.2567,  3.1114,  6.2144,  7.7932, -5.0055, -7.4901, -8.3946, -8.1221,\n",
      "        -7.4891, -4.6003,  4.6339,  5.4482, -0.7832,  6.6582, -6.3880, -4.2268,\n",
      "         4.6689,  7.0796,  4.2650,  5.0626,  5.0534,  2.5510,  1.4099,  0.7220,\n",
      "        -5.2234, -7.6917, -5.1992,  9.1463,  3.7928,  0.7336,  0.6932,  2.1511,\n",
      "         7.1905,  4.2131, -3.7756,  4.7487], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [102 / 200] Loss : 0.1808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.278819:  52%|████████████████████████████████▊                              | 104/200 [00:49<00:45,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.4197,  5.1501,  7.6057,  7.0882,  5.8837, -5.2209,  3.7518,  5.3159,\n",
      "        -3.0171,  4.0306,  7.0519,  7.9823, -5.1952, -7.1146, -7.7883, -7.8430,\n",
      "        -7.5880, -5.7744,  4.7596,  3.2811, -1.6469,  2.3836, -7.2285, -4.8249,\n",
      "         4.8859,  6.2032,  3.5451,  4.6976,  5.0445,  2.1427,  1.3393,  0.7475,\n",
      "        -5.1685, -8.7625, -4.7611,  9.6257,  3.1116, -0.2189, -0.4554,  0.7826,\n",
      "         6.7543,  5.2708, -6.0442,  4.5343], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [103 / 200] Loss : 0.1876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.371145:  52%|█████████████████████████████████                              | 105/200 [00:49<00:45,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.8939,  5.6918,  7.5032,  7.6487,  6.1106, -5.2749,  3.3866,  4.7495,\n",
      "        -2.7027,  4.4740,  7.2421,  8.5067, -5.0886, -7.1655, -7.9558, -7.1022,\n",
      "        -7.3726, -5.3903,  5.0205,  5.8377, -1.3393,  6.0801, -7.0274, -4.8894,\n",
      "         4.6840,  7.6984,  4.2991,  5.8096,  5.3758,  2.7197,  1.4343,  0.7113,\n",
      "        -4.2561, -8.3148, -2.8143,  9.8704,  3.7042,  0.8649,  0.5247,  1.5608,\n",
      "         8.3871,  4.5874, -4.8535,  5.2518], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [104 / 200] Loss : 0.1831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.315402:  53%|█████████████████████████████████▍                             | 106/200 [00:50<00:44,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.4747,  6.8279,  7.7923,  7.7456,  6.3112, -5.3159,  3.2694,  5.0627,\n",
      "        -2.4165,  4.2856,  7.6257,  8.6698, -5.3144, -7.8648, -8.0358, -8.2775,\n",
      "        -7.5727, -5.6651,  6.5731,  4.9880, -1.8374,  5.6017, -6.9429, -3.8584,\n",
      "         4.6188,  8.4979,  4.7412,  6.0417,  5.6751,  2.7426,  1.5724,  0.9499,\n",
      "        -4.4721, -8.8801, -3.5729, 10.1822,  4.0966,  0.6031,  0.4860,  3.0818,\n",
      "         8.9630,  4.7775, -4.1402,  5.1017], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [105 / 200] Loss : 0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.322895:  54%|█████████████████████████████████▋                             | 107/200 [00:50<00:43,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-8.1496e+00,  7.7166e+00,  8.5623e+00,  7.6277e+00,  6.7199e+00,\n",
      "        -5.7443e+00,  3.2351e+00,  4.2882e+00, -3.6595e+00,  4.3699e+00,\n",
      "         7.6977e+00,  8.8915e+00, -5.0287e+00, -7.5615e+00, -8.6352e+00,\n",
      "        -8.8144e+00, -8.0333e+00, -5.4732e+00,  5.8066e+00,  5.8310e+00,\n",
      "        -1.3354e+00,  6.3380e+00, -6.9575e+00, -4.1387e+00,  4.7692e+00,\n",
      "         7.9116e+00,  5.3879e+00,  6.9691e+00,  6.0386e+00,  2.8378e+00,\n",
      "         1.6165e+00,  1.0286e+00, -4.1048e+00, -8.7068e+00, -4.1881e+00,\n",
      "         1.0538e+01,  3.8224e+00, -1.0430e-02,  5.7049e-02,  3.2012e+00,\n",
      "         8.7695e+00,  5.8120e+00, -5.1952e+00,  5.7409e+00], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [106 / 200] Loss : 0.1978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.241487:  54%|██████████████████████████████████                             | 108/200 [00:51<00:43,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.9755,  6.5198,  8.1766,  8.0992,  6.6858, -5.5319,  3.6659,  4.5784,\n",
      "        -3.3500,  4.3110,  7.3473,  9.7199, -4.3992, -7.4768, -8.9544, -8.7293,\n",
      "        -8.6869, -5.2866,  5.6568,  5.0340, -1.9897,  4.4963, -6.1729, -4.9283,\n",
      "         5.5417,  8.4618,  5.8678,  6.2363,  6.0173,  2.7225,  1.3802,  0.8207,\n",
      "        -5.5532, -8.2791, -3.6825, 10.7605,  4.1164,  0.0569,  0.1348,  2.3126,\n",
      "         9.6324,  5.4198, -5.5680,  3.9626], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [107 / 200] Loss : 0.2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.271775:  55%|██████████████████████████████████▎                            | 109/200 [00:51<00:42,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-8.0952,  5.5576,  7.7539,  7.5309,  6.7836, -6.2396,  2.3269,  5.0832,\n",
      "        -3.1994,  5.5350,  7.9275,  9.6388, -6.4862, -7.0615, -7.0475, -8.6637,\n",
      "        -8.6441, -6.5968,  4.0358,  3.7786, -3.0340,  3.6675, -7.7268, -5.7681,\n",
      "         4.3883,  8.9048,  5.4747,  6.9343,  5.5039,  2.4256,  1.3749,  0.3468,\n",
      "        -5.4201, -8.8011, -4.6149, 10.7809,  4.4264,  0.3646,  0.4434,  2.7704,\n",
      "         9.5895,  3.2066, -5.3897,  4.7728], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [108 / 200] Loss : 0.1672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.251935:  55%|██████████████████████████████████▋                            | 110/200 [00:52<00:42,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.7441,  6.6347,  8.4772,  7.4704,  6.6491, -5.9136,  3.9490,  3.7296,\n",
      "        -3.6180,  3.4954,  7.6851, 10.2574, -5.9395, -6.2653, -7.7435, -7.4791,\n",
      "        -8.4466, -6.7574,  3.5821,  6.0634, -2.0949,  6.4114, -7.1279, -4.8704,\n",
      "         6.1853,  9.5349,  6.2686,  7.5072,  5.8870,  2.3855,  1.3461,  0.6173,\n",
      "        -6.6328, -8.8125, -5.4308, 11.0899,  4.7922,  0.7979,  0.2901,  3.3061,\n",
      "         9.8019,  4.8598, -5.0194,  4.3901], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [109 / 200] Loss : 0.1776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.255572:  56%|██████████████████████████████████▉                            | 111/200 [00:52<00:41,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.5497,  7.4985,  8.5821,  8.2042,  6.7347, -6.0075,  3.3138,  3.4408,\n",
      "        -3.3819,  3.5029,  7.1326, 10.2773, -5.3706, -6.2824, -7.2894, -8.3763,\n",
      "        -8.4606, -6.4548,  4.0050,  5.7682, -2.4751,  6.8538, -7.0816, -4.6184,\n",
      "         5.7209,  9.4865,  5.8823,  7.0287,  5.6759,  2.4704,  1.3969,  0.7443,\n",
      "        -4.5293, -8.5468, -4.4197, 11.0914,  3.4332, -0.2521, -0.3951,  2.8477,\n",
      "         9.9283,  5.7205, -3.9677,  5.3372], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [110 / 200] Loss : 0.1669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.238942:  56%|███████████████████████████████████▎                           | 112/200 [00:53<00:41,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.0075,  7.5240,  8.3869,  8.1503,  6.5579, -6.4617,  4.5145,  5.7384,\n",
      "        -4.0989,  4.7206,  8.6268, 10.9145, -6.7914, -5.5277, -8.2870, -8.9648,\n",
      "        -8.9312, -5.0242,  4.4565,  5.7845, -2.1841,  7.0611, -7.7561, -6.2839,\n",
      "         4.7507,  9.6065,  6.4704,  7.5456,  5.4365,  2.2904,  1.2453,  1.0476,\n",
      "        -4.3419, -8.4424, -4.5036, 11.2803,  3.2635, -0.4977, -0.7216,  3.2679,\n",
      "        10.0451,  6.0600, -2.9212,  6.4549], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [111 / 200] Loss : 0.1634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.230528:  56%|███████████████████████████████████▌                           | 113/200 [00:53<00:40,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.3174,  7.3108,  8.6249,  7.9991,  6.5355, -5.6266,  4.9685,  5.0446,\n",
      "        -4.7917,  3.9314,  8.2201, 10.9303, -6.4112, -6.0635, -7.9669, -8.8386,\n",
      "        -8.9418, -6.3322,  5.1144,  4.4112, -1.9657,  6.6496, -8.4269, -5.5737,\n",
      "         4.8432,  9.9002,  6.4320,  7.7325,  5.4649,  2.0244,  1.0704,  0.6429,\n",
      "        -5.6370, -8.5423, -4.4154, 11.2154,  4.2288, -0.2148,  1.1165,  5.1730,\n",
      "        10.0109,  6.4604, -3.6421,  4.9007], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [112 / 200] Loss : 0.1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.210162:  57%|███████████████████████████████████▉                           | 114/200 [00:54<00:40,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.6613,  8.0782,  8.6919,  7.9554,  6.8169, -6.8064,  5.3562,  5.1786,\n",
      "        -4.6517,  3.0352,  9.3411, 10.6259, -6.8084, -6.7403, -8.1316, -9.4056,\n",
      "        -9.0497, -5.5730,  5.2124,  5.2190, -2.2047,  8.1106, -7.7627, -6.2920,\n",
      "         6.8093,  9.2531,  6.0779,  7.0163,  5.4887,  2.0771,  0.8870,  0.5425,\n",
      "        -5.4838, -8.6165, -4.3545, 11.5028,  3.6451, -0.6707, -0.2533,  4.4184,\n",
      "        10.3953,  5.8040, -4.9580,  6.0750], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [113 / 200] Loss : 0.1486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.222059:  57%|████████████████████████████████████▏                          | 115/200 [00:54<00:39,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.7581,  7.5914,  9.8150,  8.5023,  7.0864, -6.3145,  3.5425,  6.4426,\n",
      "        -2.6065,  5.2962,  9.6746, 10.6273, -6.7470, -6.0730, -8.2392, -8.0936,\n",
      "        -8.9837, -6.5749,  5.7792,  2.9192, -3.4905,  6.9105, -7.5096, -6.0720,\n",
      "         7.0518,  9.0286,  5.9350,  7.3008,  5.7169,  2.1239,  1.1940,  1.0520,\n",
      "        -5.8359, -8.0916, -3.3179, 11.7707,  4.0022, -1.1250, -0.0643,  4.6495,\n",
      "        11.0971,  5.8205, -3.0419,  5.6101], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [114 / 200] Loss : 0.1381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.211717:  58%|████████████████████████████████████▌                          | 116/200 [00:55<00:39,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.7997,  7.4933,  9.6065,  8.4472,  7.3493, -6.5900,  4.4877,  4.2196,\n",
      "        -5.4855,  4.0916,  9.9178, 11.5953, -7.1601, -6.8779, -7.3920, -9.1528,\n",
      "        -8.6643, -6.7382,  6.9710,  8.6944, -3.3411,  6.2625, -8.1872, -6.0487,\n",
      "         6.4251, 10.5578,  6.7452,  7.7676,  5.5631,  2.5202,  1.1700,  0.6844,\n",
      "        -4.8999, -8.8735, -5.3992, 11.1454,  4.9572, -0.6518,  1.2732,  5.6987,\n",
      "        10.7798,  5.2289, -4.9937,  5.1882], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [115 / 200] Loss : 0.1404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.201829:  58%|████████████████████████████████████▊                          | 117/200 [00:55<00:38,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.9325,  8.6807,  9.6890,  8.0883,  6.9736, -6.6369,  5.3169,  5.3317,\n",
      "        -6.0291,  3.2899,  9.0856, 11.7992, -7.0671, -6.3043, -8.1427, -8.5819,\n",
      "        -9.4724, -7.4160,  6.0018,  6.9043, -3.2614,  7.4927, -8.1936, -6.0375,\n",
      "         5.9854, 10.7998,  6.5858,  8.1924,  5.9692,  2.0140,  0.9535,  0.8904,\n",
      "        -6.6878, -8.4416, -5.2821, 11.4330,  3.7544, -0.9834, -0.7697,  3.6723,\n",
      "        11.0025,  5.6668, -6.0336,  4.4096], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [116 / 200] Loss : 0.142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.246285:  59%|█████████████████████████████████████▏                         | 118/200 [00:55<00:38,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.1583,  9.0095,  9.7826,  8.8542,  7.8249, -6.4096,  5.5458,  6.4822,\n",
      "        -5.9215,  4.3265, 10.0458, 12.1465, -6.7160, -7.2576, -7.5947, -8.4172,\n",
      "        -9.3455, -5.6295,  6.7147, 10.7558, -1.9946,  7.6708, -7.0419, -5.8332,\n",
      "         6.8749, 11.6767,  9.7597,  9.2964,  6.6708,  2.8881,  1.5653,  1.6994,\n",
      "        -4.6560, -8.3027, -5.0391, 12.5836,  6.7452,  0.8709,  2.8956,  7.4641,\n",
      "        11.9397,  5.9964, -7.0824,  4.9862], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [117 / 200] Loss : 0.1299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.376988:  60%|█████████████████████████████████████▍                         | 119/200 [00:56<00:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.3988,  8.5476,  9.5910,  8.3028,  7.2781, -6.2727,  3.9250,  3.7094,\n",
      "        -6.1205,  4.2997,  9.2468, 11.3417, -7.2386, -6.9991, -8.9308, -9.4826,\n",
      "        -8.6330, -6.9896,  6.8619,  8.9081, -3.6387,  7.4104, -7.3807, -4.6524,\n",
      "         6.2962, 10.5877,  6.6365,  7.6246,  5.3109,  1.7041,  0.7887,  0.9294,\n",
      "        -6.1651, -9.2351, -6.5093, 12.0282,  3.9867, -1.7983, -1.3394,  2.8474,\n",
      "        10.6122,  5.9030, -7.7435,  5.2201], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [118 / 200] Loss : 0.1478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.209051:  60%|█████████████████████████████████████▊                         | 120/200 [00:56<00:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.2333,  9.3689, 10.3482,  9.4326,  7.9569, -6.5905,  4.0340,  6.0151,\n",
      "        -5.5112,  5.5390,  9.7519, 11.5214, -7.4281, -7.4509, -9.0240, -8.5069,\n",
      "        -9.8834, -7.1500,  5.8773,  8.5234, -4.0950,  4.4778, -7.6874, -6.1891,\n",
      "         7.3996, 10.2389,  5.9427,  7.4877,  5.8571,  1.8561,  0.6363,  0.9767,\n",
      "        -5.5661, -9.6414, -5.2630, 11.9987,  2.9139, -2.7082, -1.7771,  3.9195,\n",
      "        11.3857,  6.1752, -7.7600,  5.1377], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [119 / 200] Loss : 0.2075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.353994:  60%|██████████████████████████████████████                         | 121/200 [00:57<00:36,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.7903, 10.1101, 10.7999,  9.8836,  7.9299, -6.1726,  4.6471,  7.3571,\n",
      "        -4.4635,  5.8549, 11.5793, 12.4552, -6.9835, -7.5780, -8.6992, -9.5481,\n",
      "        -9.2442, -7.3756,  5.6929,  9.6609, -3.1208,  1.5878, -2.6808, -6.2620,\n",
      "         9.3935, 12.1043, 10.6399, 10.7560,  7.4907,  3.1291,  1.3146,  1.1392,\n",
      "        -7.0462, -9.3949, -5.9541, 12.4371,  7.4426,  2.4798,  5.1684,  9.6483,\n",
      "        12.3229,  6.3736, -7.8410,  5.6565], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [120 / 200] Loss : 0.1739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.266688:  61%|██████████████████████████████████████▍                        | 122/200 [00:57<00:36,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -6.9412,   8.9180,  10.3670,   8.8444,   6.7865,  -5.3176,   1.5970,\n",
      "          0.8015,  -2.4214,   3.2201,   9.5216,  12.2931,  -6.9441,  -7.6607,\n",
      "         -9.1826,  -8.3968,  -8.0331,  -7.8124,   4.7247,  10.5967,  -2.4231,\n",
      "          6.7015,  -8.4220,  -7.6566,   7.1947,  11.3245,   9.6150,   9.4676,\n",
      "          6.0103,   1.8280,   0.1989,  -0.2254,  -7.8697, -10.2955,  -8.9708,\n",
      "         13.1950,   6.1703,  -0.2276,   0.7400,   7.0776,  11.7242,   5.4205,\n",
      "         -6.9251,   5.5612], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [121 / 200] Loss : 0.1982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.308522:  62%|██████████████████████████████████████▋                        | 123/200 [00:58<00:35,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -7.7231,   9.9917,  10.2421,   9.5531,   6.9542,  -6.4536,   3.4288,\n",
      "          2.3401,  -6.7376,   6.9678,  11.3947,  12.6096,  -5.4010,  -7.7617,\n",
      "         -9.8872,  -9.6787,  -9.5109,  -6.5597,   4.5534,   8.5342,  -3.2485,\n",
      "          1.8842,  -4.4203,  -6.0744,   9.2221,   8.3160,   6.9053,   7.0975,\n",
      "          5.7101,   1.8829,   0.4952,   0.7389,  -6.0510, -10.5445,  -7.1662,\n",
      "         12.6086,   2.9146,  -2.4725,  -2.2865,   1.9751,  10.6046,   7.9605,\n",
      "         -1.7222,   8.4729], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [122 / 200] Loss : 0.1771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.269261:  62%|███████████████████████████████████████                        | 124/200 [00:58<00:35,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -7.8298,   8.7791,  10.2932,   9.2460,   5.0741,  -6.8400,   2.8855,\n",
      "          3.7597,  -6.1542,   5.4302,  11.6409,  13.2659,  -6.2523,  -7.6639,\n",
      "         -9.4164,  -8.7188,  -8.6606,  -8.7409,   5.1726,   9.2591,  -2.3919,\n",
      "          7.6230,  -7.4596,  -8.1174,   9.1146,  10.3728,   6.0954,   7.2831,\n",
      "          6.3824,   1.7655,   0.5172,   0.7923,  -6.8635, -11.0157,  -8.2012,\n",
      "         13.0021,   4.8962,  -1.8322,  -1.6775,   3.5324,  11.5160,   5.3852,\n",
      "         -2.9410,   6.4838], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [123 / 200] Loss : 0.2042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.227341:  62%|███████████████████████████████████████▍                       | 125/200 [00:59<00:34,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -6.4895,   9.5850,  10.3737,   8.9468,   4.7954,  -3.0616,   5.5951,\n",
      "          4.4407,  -0.3987,   1.1446,  11.8436,  13.8125,  -4.7415,  -4.8971,\n",
      "         -6.8398,  -5.4245,  -7.5076,  -8.9410,   5.2091,  10.1102,  -0.3997,\n",
      "          9.9535,  -6.1476,  -7.9131,   5.0937,  11.2428,   7.9293,  10.0160,\n",
      "          7.4539,   3.1766,   1.1768,   1.1703,  -8.3899, -10.9699,  -6.5041,\n",
      "         13.6966,   8.2611,   0.0677,   0.8682,   6.9174,  12.6061,   7.8310,\n",
      "         -5.1145,   6.4630], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [124 / 200] Loss : 0.1888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.253275:  63%|███████████████████████████████████████▋                       | 126/200 [00:59<00:34,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -7.4689,  10.1969,  10.7709,   9.9509,   8.7407,  -7.1285,   2.8164,\n",
      "          4.7887,  -4.8451,   8.3753,  12.7070,  13.4090,  -5.6985,  -6.3185,\n",
      "         -8.4090,  -9.0979,  -9.3623,  -8.6539,   6.2317,  10.4161,  -1.6433,\n",
      "          3.8789,  -4.1305,  -8.0711,   7.7583,  10.5463,   8.2849,   9.1920,\n",
      "          6.4185,   2.4673,   0.6857,   1.1287,  -5.9916, -10.4556,  -5.5490,\n",
      "         12.4710,   4.3590,   0.3250,   2.1086,   6.6710,  11.0828,   7.1427,\n",
      "         -4.3343,   6.7602], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [125 / 200] Loss : 0.1752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.213149:  64%|████████████████████████████████████████                       | 127/200 [01:00<00:33,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -8.5499,   5.9107,   8.0474,   6.6095,   3.6179,  -7.4765,   1.8693,\n",
      "          6.7421,  -5.2648,   1.1215,   9.6029,  12.1207,  -6.0896,  -6.1122,\n",
      "         -7.4608,  -6.4047,  -7.6935, -10.6603,  -2.8545,   6.9273,  -1.2933,\n",
      "          4.7461,  -8.8629,  -9.3879,  -2.5831,   8.5953,   8.6196,   7.4679,\n",
      "          3.3953,  -0.7217,  -1.5336,  -2.7755, -11.1543, -11.2719,  -9.2161,\n",
      "         12.2880,   2.8593,  -0.7505,   0.8607,   5.0909,   8.6188,  -1.2977,\n",
      "        -10.4668,  -1.6055], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [126 / 200] Loss : 0.2832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.494283:  64%|████████████████████████████████████████▎                      | 128/200 [01:00<00:33,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.3837, 11.5908, 10.3576,  9.7336,  9.0855, -3.8374,  4.4492,  4.8180,\n",
      "        -3.5001,  6.7527, 10.7564, 13.6214, -2.7917, -3.5489, -6.7670, -8.0361,\n",
      "        -8.5603, -2.7725, 13.2116,  8.0774, -1.9996,  2.1505, -4.5330, -4.7862,\n",
      "        10.8086, 10.9367,  7.8168,  7.0646,  6.1952,  2.2979,  1.3034,  2.0149,\n",
      "        -1.0910, -6.0523,  2.7983, 12.9890,  4.2872, -0.4866,  0.9589,  4.0516,\n",
      "         9.5542, 11.3740,  7.6651,  9.7759], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [127 / 200] Loss : 0.3102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.305316:  64%|████████████████████████████████████████▋                      | 129/200 [01:01<00:33,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -7.3118,   4.6624,   4.4173,   3.1032,   2.7361,  -3.9756,   5.6532,\n",
      "          4.6390,  -2.8434,  -2.7418,   4.8421,  11.1453,  -2.4430,  -3.4142,\n",
      "         -5.5442,  -5.3319,  -7.9200,  -7.9458,   3.7269,   6.0254,  -1.6885,\n",
      "          8.3095,  -9.3571,  -7.3085,   1.8470,   9.8247,   3.3140,   4.9694,\n",
      "          3.3480,   0.7264,   0.3265,  -0.1226,  -9.8759, -10.9295, -10.1136,\n",
      "         10.9627,   4.9277,  -1.8668,  -1.2407,   1.9183,   7.3884,   4.0935,\n",
      "         -5.2437,   4.2170], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [128 / 200] Loss : 0.4097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.506783:  65%|████████████████████████████████████████▉                      | 130/200 [01:01<00:32,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -8.3499,   5.6130,   5.1033,   4.5788,   2.8129,  -4.3872,   3.0190,\n",
      "          5.1291,  -1.6566,   4.2295,   6.6056,   8.9845,  -5.8700,  -5.7597,\n",
      "         -8.5956,  -9.7562,  -7.6414,  -3.2373,   7.6715,   7.7512,  -3.5516,\n",
      "          5.6440,  -7.2515,  -5.5010,   3.8117,   8.7259,   6.6231,   5.6075,\n",
      "          2.9141,   1.3982,   1.2005,   1.3161,  -5.5105, -10.7007, -10.1084,\n",
      "         11.4642,   2.6995,  -0.8490,   0.0509,   3.2186,   6.1169,   4.7954,\n",
      "          0.6462,   4.2301], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [129 / 200] Loss : 0.2557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.286634:  66%|█████████████████████████████████████████▎                     | 131/200 [01:02<00:32,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.5324,  3.5640,  3.6376,  3.2870,  2.3917, -2.6409,  3.6694,  5.0477,\n",
      "        -0.2549,  3.1416,  5.4760,  9.2329, -4.4844, -2.2862, -1.8460, -3.4769,\n",
      "        -6.2391, -3.1986,  6.4432,  6.1596, -2.5949,  6.7975, -2.7300, -1.5841,\n",
      "         2.5204,  9.4197,  8.1172,  6.2564,  3.0589,  1.3969,  1.0813,  0.9126,\n",
      "        -7.2087, -8.8642, -9.2752, 10.5628,  4.0040, -0.5895,  0.8349,  3.8334,\n",
      "         7.0457,  4.0928, -1.3581,  2.5904], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [130 / 200] Loss : 0.2738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.297088:  66%|█████████████████████████████████████████▌                     | 132/200 [01:02<00:31,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.3502,  4.2907,  5.2049,  4.5391,  3.4720, -1.6862,  4.3611,  4.9984,\n",
      "        -0.2767,  4.7436,  6.6826,  8.7005, -3.6140, -1.3833, -0.7396, -0.5719,\n",
      "        -4.5762, -4.4447,  6.5481,  8.3965, -1.7117,  6.1025, -2.3071, -1.9433,\n",
      "         0.5941, 10.1248, 10.0239,  7.9568,  4.0741,  1.3038,  0.8086,  0.3455,\n",
      "        -8.7700, -8.3930, -8.4170, 11.5557,  4.4504, -0.3009,  1.5739,  5.5779,\n",
      "         7.9486,  0.9987, -3.0158,  3.5319], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [131 / 200] Loss : 0.2666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.253198:  66%|█████████████████████████████████████████▉                     | 133/200 [01:02<00:31,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.2796,  8.0960,  6.5675,  5.6091,  5.9649, -1.9748,  2.0194,  3.9399,\n",
      "         1.9858,  5.6895,  7.2488,  8.6811, -3.7022, -5.8572, -7.6980, -8.1566,\n",
      "        -5.0907, -1.0251,  8.5394, 10.8228, -2.8537,  1.3456, -2.9209, -2.4908,\n",
      "         6.5634, 10.4671, 10.2733,  8.8242,  5.1792,  1.9284,  1.0961,  1.0978,\n",
      "        -5.8992, -9.4308, -8.0095, 11.7354,  3.8283,  0.4449,  2.7266,  6.8649,\n",
      "         8.1659,  4.3218, -1.1181,  5.8498], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [132 / 200] Loss : 0.2163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.236626:  67%|██████████████████████████████████████████▏                    | 134/200 [01:03<00:30,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.6786,  7.5244,  5.1719,  4.2211,  4.5811, -2.8587,  2.4126,  4.1275,\n",
      "        -1.6092,  1.6188,  4.5929,  7.2993, -5.2498, -5.5009, -7.4327, -8.2154,\n",
      "        -6.6838, -1.9717,  6.5542,  8.5059, -2.7272,  6.0501, -4.4650, -3.7506,\n",
      "         4.4636,  9.6529,  7.0723,  7.7582,  4.2226,  0.9490,  0.1575,  0.3831,\n",
      "        -7.4898, -9.2318, -7.7543, 11.0487,  2.4783, -1.0312, -0.2425,  5.0818,\n",
      "         8.5380,  3.5113, -2.1614,  4.1954], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [133 / 200] Loss : 0.2104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.243300:  68%|██████████████████████████████████████████▌                    | 135/200 [01:03<00:30,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.3980,  4.4741,  4.0921,  3.5180,  2.5319, -3.3363,  4.2901,  3.0934,\n",
      "        -1.6208,  0.0598,  3.1177,  6.7898, -4.6730, -4.2061, -4.8697, -5.1964,\n",
      "        -7.0994, -5.9627,  4.7295,  6.7127,  0.4964,  9.9251, -6.3464, -4.8510,\n",
      "         4.8197, 10.6213,  7.1375,  7.3602,  4.2696,  0.7344,  0.1877,  0.0169,\n",
      "        -8.8469, -9.0509, -8.3057, 10.0156,  5.1677, -1.6862, -0.3949,  4.2603,\n",
      "         9.0877,  1.0786, -5.3918,  3.4766], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [134 / 200] Loss : 0.1819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.208328:  68%|██████████████████████████████████████████▊                    | 136/200 [01:04<00:29,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.1047,  5.8570,  5.7605,  5.0383,  2.4633, -3.2525,  4.7857,  1.9802,\n",
      "        -1.0637,  0.3202,  3.8778,  5.6123, -4.9790, -3.9243, -5.6120, -6.2854,\n",
      "        -5.6051, -6.1779,  1.8537,  3.7648, -1.6950,  9.1834, -4.9936, -3.8616,\n",
      "         7.1139, 10.5879,  6.0433,  7.8496,  5.9438,  2.2498,  1.5264,  2.0662,\n",
      "        -7.3969, -8.6319, -8.0254, 11.0406,  5.2248, -1.2385, -0.3807,  4.7294,\n",
      "         9.9426,  5.8724, -3.9875,  4.8922], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [135 / 200] Loss : 0.1774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.191524:  68%|███████████████████████████████████████████▏                   | 137/200 [01:04<00:29,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.4353,  8.4188,  7.1946,  6.3013,  5.7464, -3.1406,  4.1249,  4.4168,\n",
      "        -1.3052,  1.4028,  4.0726,  8.1266, -5.5874, -4.5707, -7.3058, -6.6865,\n",
      "        -7.1702, -4.4502,  4.5822,  7.6456, -2.9262,  7.1900, -3.4348, -2.6149,\n",
      "         7.3907, 11.3410,  9.5311,  9.3498,  7.1443,  3.3298,  2.4640,  3.2918,\n",
      "        -6.1436, -8.7827, -6.7112, 11.7273,  5.5717,  0.7417,  1.1283,  6.8439,\n",
      "        10.3360,  7.7312, -0.3959,  7.1459], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [136 / 200] Loss : 0.1622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.194257:  69%|███████████████████████████████████████████▍                   | 138/200 [01:05<00:28,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.2342,  8.3813,  7.4006,  6.1663,  3.8741, -3.5804,  4.7790,  4.3621,\n",
      "        -1.5753,  0.5464,  3.5536,  5.6405, -5.9237, -4.8559, -7.6375, -6.7693,\n",
      "        -7.1014, -7.1952,  3.3054,  5.9838, -3.7317,  3.8303, -4.1682, -3.4916,\n",
      "         7.5564, 11.2765,  9.1332,  8.7186,  5.5236,  2.2619,  1.1275,  2.3860,\n",
      "        -7.4148, -8.9538, -7.8658, 11.0172,  3.2923, -1.6065,  1.3150,  5.8267,\n",
      "        10.1556,  6.8152, -4.2651,  5.6515], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [137 / 200] Loss : 0.1291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.186506:  70%|███████████████████████████████████████████▊                   | 139/200 [01:05<00:28,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.7158e+00,  8.1547e+00,  7.1685e+00,  6.4209e+00,  4.5175e+00,\n",
      "        -4.6022e+00,  4.0105e+00,  5.1537e+00, -3.0057e+00,  9.1939e-01,\n",
      "         4.3914e+00,  8.7387e+00, -6.3086e+00, -5.8955e+00, -7.1087e+00,\n",
      "        -8.1273e+00, -6.5935e+00, -6.8633e+00,  4.7216e+00,  6.2229e+00,\n",
      "        -3.8615e+00,  4.0748e+00, -5.1522e+00, -4.6927e+00,  7.9999e+00,\n",
      "         1.1447e+01,  9.2934e+00,  9.0106e+00,  5.3410e+00,  1.4817e+00,\n",
      "         2.9417e-01,  1.4290e+00, -8.1131e+00, -8.8640e+00, -7.6965e+00,\n",
      "         1.0328e+01,  3.3418e+00, -1.7125e+00,  4.9777e-03,  5.6164e+00,\n",
      "         1.0484e+01,  5.2587e+00, -5.7289e+00,  5.1347e+00], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [138 / 200] Loss : 0.1256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.179653:  70%|████████████████████████████████████████████                   | 140/200 [01:06<00:28,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.8084,  8.1704,  6.5394,  6.5933,  5.0739, -4.7986,  5.5053,  4.3679,\n",
      "        -3.1907,  1.2474,  5.8850,  9.1558, -6.5091, -5.5050, -7.4654, -7.3913,\n",
      "        -7.4442, -6.7550,  4.1137, 11.0876, -3.1264,  7.3112, -6.7358, -5.5239,\n",
      "         7.9906, 12.4634, 11.5693, 10.1998,  6.7970,  2.0683,  0.6459,  1.8550,\n",
      "        -8.2140, -8.8379, -7.8543, 11.4110,  3.1891, -0.9638,  3.2307,  8.5359,\n",
      "        11.4603,  5.0545, -8.2177,  4.2291], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [139 / 200] Loss : 0.1191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.185625:  70%|████████████████████████████████████████████▍                  | 141/200 [01:06<00:27,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.7717,  8.9237,  8.7341,  7.2851,  7.0421, -4.6716,  3.6977,  4.5986,\n",
      "        -2.0570,  2.2911,  6.3087, 10.9937, -6.1617, -6.1293, -7.9828, -8.3825,\n",
      "        -7.5289, -6.9618,  5.0497,  9.1854, -2.9992,  4.7762, -7.1294, -7.3394,\n",
      "         6.7782, 12.8006,  9.2238,  9.2679,  6.7781,  1.8178,  0.6017,  1.7254,\n",
      "        -8.6555, -8.9019, -7.7871, 11.1109,  3.8375, -1.8681,  0.7717,  8.4445,\n",
      "        12.2724,  5.0280, -8.5462,  3.3900], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [140 / 200] Loss : 0.1118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.175296:  71%|████████████████████████████████████████████▋                  | 142/200 [01:07<00:27,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.1918,  9.5197,  9.2141,  8.9457,  8.1949, -5.4434,  3.7197,  4.2427,\n",
      "        -4.0881,  4.3008,  7.8362, 11.6817, -6.4621, -6.4481, -7.8892, -8.3568,\n",
      "        -7.9617, -5.9524,  8.4293,  7.1670, -4.1970,  1.4689, -6.4707, -7.5543,\n",
      "         9.2619, 12.6593,  6.0740,  8.5067,  7.0500,  1.7137,  0.4438,  0.7093,\n",
      "        -8.1240, -9.1632, -7.2999, 11.1063,  1.3224, -1.8006,  1.5419,  7.9280,\n",
      "        12.3924,  5.8719, -6.4528,  6.2513], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [141 / 200] Loss : 0.1108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.165372:  72%|█████████████████████████████████████████████                  | 143/200 [01:07<00:26,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.4468, 11.2026,  9.4712,  8.9779,  8.4433, -5.2386,  3.9912,  4.0520,\n",
      "        -3.6781,  5.3001,  8.5706, 12.1363, -5.4936, -5.8746, -7.0004, -8.4336,\n",
      "        -7.8354, -5.9896,  8.0127, 11.9826, -0.7238, 11.8586, -6.8946, -6.9927,\n",
      "         9.4373, 13.6257,  7.9317, 11.4356,  8.3976,  2.4396, -0.0147,  2.2250,\n",
      "        -7.8728, -8.9299, -7.4423, 12.6555,  7.9356,  1.1934,  7.2585, 11.2065,\n",
      "        13.4455,  6.6423, -8.5559,  6.6875], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [142 / 200] Loss : 0.1099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.165742:  72%|█████████████████████████████████████████████▎                 | 144/200 [01:08<00:26,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.4416, 11.8117, 10.2400,  8.2620,  8.1513, -3.8711,  6.4746,  5.8075,\n",
      "        -3.6939,  4.7382,  9.1142, 12.3214, -5.8112, -5.9247, -7.5653, -8.5017,\n",
      "        -7.9372, -6.7417,  7.2386,  2.4267, -2.9943, 11.2260, -5.6529, -6.9984,\n",
      "         9.9767, 11.9893,  1.3511,  5.4964,  6.7196,  0.3213, -0.7633,  0.8557,\n",
      "        -7.2025, -8.8022, -6.3971, 11.8953,  3.4947, -3.2613, -0.1186,  7.6483,\n",
      "        13.0566,  6.3387, -8.0308,  5.5522], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [143 / 200] Loss : 0.1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.154745:  72%|█████████████████████████████████████████████▋                 | 145/200 [01:08<00:25,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.9397,  9.9656,  9.3445,  8.3734,  8.2267, -2.1263,  7.5167,  5.2454,\n",
      "        -4.0892,  3.3258,  9.7400, 12.7189, -5.3681, -5.8010, -7.5533, -8.0906,\n",
      "        -7.4616, -7.0270,  8.1670, 13.0476, -0.4976, 12.5725, -7.5794, -7.5571,\n",
      "         8.2298, 14.4433, 12.3970, 12.3347, 10.0467,  2.4977,  0.2352,  3.6495,\n",
      "        -8.1817, -8.8451, -7.4605, 11.8113,  9.5660, -1.0626,  4.9711, 11.8063,\n",
      "        14.0364,  2.0698, -7.6584,  6.0489], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [144 / 200] Loss : 0.1046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.162183:  73%|█████████████████████████████████████████████▉                 | 146/200 [01:09<00:25,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.4767e+00,  1.0843e+01,  1.0038e+01,  1.0012e+01,  9.6599e+00,\n",
      "        -5.7475e+00,  4.3102e+00,  5.0149e+00, -4.1267e+00,  6.8737e+00,\n",
      "         1.0249e+01,  1.3282e+01, -6.4689e+00, -6.4352e+00, -8.0037e+00,\n",
      "        -9.7009e+00, -8.7563e+00, -4.7309e+00,  1.0693e+01,  1.0298e+01,\n",
      "        -4.0804e+00,  1.1835e+01, -6.1101e+00, -7.1290e+00,  8.0997e+00,\n",
      "         1.4289e+01,  1.0275e+01,  1.1510e+01,  8.7647e+00,  2.5410e+00,\n",
      "        -4.4556e-03,  2.7447e+00, -6.1983e+00, -8.9400e+00, -7.3666e+00,\n",
      "         1.2384e+01,  6.3379e+00, -2.9217e+00,  1.6500e+00,  9.7040e+00,\n",
      "         1.3996e+01,  7.0507e+00, -6.7149e+00,  8.2808e+00], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [145 / 200] Loss : 0.0846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.152601:  74%|██████████████████████████████████████████████▎                | 147/200 [01:09<00:24,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -6.4359,  12.4717,  11.0612,  10.0232,   9.0606,  -6.4694,   3.5490,\n",
      "          2.0003,  -4.7383,   5.9933,  10.4942,  13.6525,  -6.9347,  -7.0278,\n",
      "         -8.6717, -10.1942,  -8.0687,  -6.0029,  10.1929,   8.6797,  -5.2951,\n",
      "          8.3249,  -7.4503,  -7.8244,   8.7520,  14.2668,   8.9017,   9.7234,\n",
      "          7.1384,   1.3042,  -0.8610,   2.3119,  -6.3574,  -9.1045,  -6.7706,\n",
      "         12.0207,   2.1247,  -4.0390,  -0.1828,   9.9438,  13.8276,   5.3593,\n",
      "         -4.7036,   7.3434], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [146 / 200] Loss : 0.0979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.151279:  74%|██████████████████████████████████████████████▌                | 148/200 [01:09<00:24,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.6154, 11.4403,  9.8719,  9.0456, 10.3258, -5.8596,  4.5536,  3.9239,\n",
      "        -4.6904,  5.8737,  8.7298, 13.3740, -7.1952, -7.5542, -9.4965, -9.7774,\n",
      "        -8.2055, -6.4345,  8.8721, 13.2374, -5.2028,  7.5070, -7.9177, -8.5241,\n",
      "         8.9370, 14.7527, 13.3468, 12.4827,  9.4353,  2.1351, -0.3126,  3.4137,\n",
      "        -6.5977, -9.6346, -7.8016, 12.7637,  6.3246, -0.3748,  6.9868, 12.8645,\n",
      "        13.7194,  5.5581, -5.7523,  7.1313], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [147 / 200] Loss : 0.0918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.145587:  74%|██████████████████████████████████████████████▉                | 149/200 [01:10<00:23,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.2771, 11.9572, 10.5093,  9.5214,  9.4229, -5.6997,  3.3926,  4.8604,\n",
      "        -5.3173,  5.6843, 10.0090, 13.3925, -7.2656, -6.9146, -8.7620, -8.7784,\n",
      "        -8.2770, -7.6395,  8.1650, 10.8177, -5.5805, 11.8000, -8.2769, -8.5598,\n",
      "         8.7065, 14.8026, 12.5640, 11.9624,  8.8573,  0.9660, -0.9807,  2.7956,\n",
      "        -7.6699, -9.4997, -7.8749, 12.5152,  4.3693, -2.7210,  7.4045, 12.4782,\n",
      "        13.8498,  6.7005, -8.5969,  5.4892], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [148 / 200] Loss : 0.0813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.144567:  75%|███████████████████████████████████████████████▎               | 150/200 [01:10<00:23,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -6.3691,  11.6298,  10.5873,   9.8911,  10.0166,  -5.1800,   5.8999,\n",
      "          7.2431,  -5.4698,   7.6714,   9.1638,  13.9462,  -7.5011,  -6.9121,\n",
      "         -8.2309,  -9.9687,  -9.4023,  -7.5003,   9.0070,   9.9065,  -5.1935,\n",
      "         10.5913,  -8.4896,  -8.4662,   8.1835,  15.0119,  10.9296,  12.5169,\n",
      "         10.5783,   2.1825,  -1.0532,   2.8052,  -6.9546, -10.0597,  -7.9181,\n",
      "         12.1466,   5.7826,  -4.1723,   4.0839,  12.7582,  14.2237,   5.9099,\n",
      "         -9.0695,   6.3751], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [149 / 200] Loss : 0.0758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.162564:  76%|███████████████████████████████████████████████▌               | 151/200 [01:11<00:22,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.9276, 12.2161, 10.4674,  9.6259,  8.8265, -4.5670,  8.0250,  7.0372,\n",
      "        -5.4137,  5.8049, 10.0039, 13.3279, -6.6704, -6.0609, -8.2101, -9.7214,\n",
      "        -8.6236, -7.7379,  7.1686, 13.0534, -4.1003, 12.6648, -8.2973, -9.2121,\n",
      "         8.8581, 15.1854, 12.7744, 13.4644, 11.7766,  4.0003, -0.3058,  3.2350,\n",
      "        -9.6519, -9.9800, -7.8836, 11.8890,  9.7883, -4.1617,  1.8421, 12.8184,\n",
      "        14.5627,  4.7582, -5.6638,  4.9113], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [150 / 200] Loss : 0.0789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.167522:  76%|███████████████████████████████████████████████▉               | 152/200 [01:11<00:22,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.9210, 12.3097, 10.7661, 10.0918,  9.0145, -4.4231,  7.3736,  6.3546,\n",
      "        -4.4960,  6.0489, 10.1530, 13.2124, -7.2555, -6.8312, -8.5633, -9.8827,\n",
      "        -9.3092, -8.3558,  4.6609, 14.4150, -2.8360, 12.2375, -8.7688, -9.5071,\n",
      "         8.4575, 15.4960, 13.6977, 14.3892, 11.5608,  1.7871, -1.5186,  2.4969,\n",
      "        -8.1568, -9.9566, -8.5098, 12.4710, 10.3712, -3.1796,  6.6296, 13.4937,\n",
      "        14.2686,  4.0186, -9.1017,  6.4127], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [151 / 200] Loss : 0.0823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.365769:  76%|████████████████████████████████████████████████▏              | 153/200 [01:12<00:22,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -6.1757,  12.7792,  11.4279,  10.4027,  10.9179,  -5.5792,   7.4462,\n",
      "          7.1935,  -6.3598,   6.6710,  10.8196,  14.3478,  -7.1602,  -6.8980,\n",
      "         -9.5242, -10.3484,  -9.4812,  -8.1621,   6.1343,  15.3630,  -3.6034,\n",
      "         12.2073,  -6.1694,  -8.9106,  11.1961,  15.7545,  12.1450,  13.5066,\n",
      "         12.0380,   3.4826,  -1.2403,   3.0080,  -7.3095,  -9.9819,  -8.0821,\n",
      "         12.4101,   4.7358,  -4.4851,   7.1239,  14.2978,  14.8021,   6.8055,\n",
      "         -8.0309,   6.1895], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [152 / 200] Loss : 0.0828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.559317:  77%|████████████████████████████████████████████████▌              | 154/200 [01:12<00:21,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -7.2620,  12.8506,  10.7225,   9.9800,  11.0169,  -6.5418,   6.1938,\n",
      "          7.6246,  -3.2645,   6.8297,  10.8910,  14.1531,  -7.7920,  -7.9070,\n",
      "         -9.5853,  -9.3266, -10.1845,  -6.9423,   5.0296,  15.5287,  -3.8660,\n",
      "          9.6927,  -7.7499,  -8.7704,   9.9253,  15.7979,  14.0832,  13.4910,\n",
      "         11.8905,   2.0969,  -2.5420,   1.7289,  -8.3149,  -9.6163,  -7.9057,\n",
      "         12.4998,   4.5356,  -3.6335,   6.1726,  14.1596,  14.8003,   6.9886,\n",
      "         -7.7819,   7.1879], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [153 / 200] Loss : 0.1575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.403530:  78%|████████████████████████████████████████████████▊              | 155/200 [01:13<00:21,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -7.2614,  12.9687,  11.6207,  10.3873,   8.5877,  -6.0697,   6.3085,\n",
      "          4.8806,  -3.7424,   5.4523,  11.4629,  14.4106,  -7.7439,  -7.2852,\n",
      "         -9.9941, -10.3779,  -9.7199,  -6.6124,   8.4072,  15.0268,  -4.9712,\n",
      "          7.4395,  -7.4736,  -8.7208,   9.4525,  15.8408,  13.6347,  13.5496,\n",
      "         11.7914,   2.4201,  -1.9118,   3.4378,  -6.6953,  -9.6210,  -7.3584,\n",
      "         11.6055,   5.6784,  -3.4806,   7.7032,  14.7524,  15.0282,   6.6661,\n",
      "         -8.5040,   5.7576], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [154 / 200] Loss : 0.2217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.348162:  78%|█████████████████████████████████████████████████▏             | 156/200 [01:13<00:20,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -7.3017,  12.3149,  11.4741,   9.3082,  10.8435,  -6.6409,   7.3473,\n",
      "          7.1652,  -5.2802,   7.2079,  12.2797,  14.8208,  -7.6437,  -7.5906,\n",
      "         -9.6470, -10.8317,  -9.7579,  -6.8581,   8.6109,  14.3910,  -5.3067,\n",
      "         10.3234,  -3.3754,  -8.1341,  10.8200,  15.9125,  14.7198,  14.1313,\n",
      "         13.0859,   4.0250,  -0.6835,   5.8251,  -4.6757,  -8.9471,  -6.3039,\n",
      "         12.5360,   4.0078,  -4.3526,   8.8139,  14.8295,  14.6366,   6.3096,\n",
      "         -6.5688,   5.4358], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [155 / 200] Loss : 0.2207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.240513:  78%|█████████████████████████████████████████████████▍             | 157/200 [01:14<00:20,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -7.3486,  11.5064,  10.4898,   8.3694,   8.5853,  -7.8869,   4.3580,\n",
      "          4.8514,  -5.4566,   7.1792,  11.5741,  14.1383,  -6.7972,  -7.4931,\n",
      "         -9.6336, -10.5470, -10.1951,  -7.5458,   5.3648,  12.6577,  -5.0902,\n",
      "         11.6198,  -6.1873,  -7.4777,   8.9082,  15.6241,  13.5028,  14.1189,\n",
      "         12.5801,   2.4956,  -1.8217,   3.5043,  -5.9472,  -9.0739,  -7.6618,\n",
      "          9.9651,   5.8693,  -4.6163,   2.6935,  14.4267,  14.4744,   3.9472,\n",
      "         -7.5201,   3.1671], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [156 / 200] Loss : 0.1987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.282369:  79%|█████████████████████████████████████████████████▊             | 158/200 [01:14<00:19,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.4423, 11.8706, 10.2658,  9.1544,  6.1514, -7.5814,  4.1571,  4.2139,\n",
      "        -3.7813,  7.8518, 11.6435, 14.1725, -6.5970, -5.9886, -9.0433, -9.4143,\n",
      "        -9.3359, -6.8846,  4.8097,  4.9120, -2.8445, 12.3080, -5.4398, -6.9487,\n",
      "         7.7061, 14.0625,  4.9021, 10.3938, 12.5433,  1.6026, -2.8911,  1.7261,\n",
      "        -7.6828, -9.4181, -7.4365, 10.9865, 11.3741, -5.2424, -5.3670, -0.6281,\n",
      "        14.7183,  1.3341, -8.8961,  1.2078], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [157 / 200] Loss : 0.1822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.240086:  80%|██████████████████████████████████████████████████             | 159/200 [01:15<00:19,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.8704, 12.9012, 11.2145, 10.4734, 11.0779, -5.3020,  7.3771,  3.4824,\n",
      "        -5.1325,  8.3844, 10.7094, 14.0593, -0.0634, -3.6454, -7.8353, -9.6606,\n",
      "        -9.0780, -4.3215, 10.1173, 13.1584, -1.0068, 12.4105, -5.1236, -4.4035,\n",
      "        11.2613, 15.4077, 12.4548, 14.4645, 14.6076,  9.0557,  3.6528,  7.1874,\n",
      "        -5.2236, -8.0570, -4.9531, 12.7722, 13.1338, -0.2813, -0.6412,  9.9860,\n",
      "        15.2338,  8.2840, -1.4455,  9.4288], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [158 / 200] Loss : 0.1853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.198973:  80%|██████████████████████████████████████████████████▍            | 160/200 [01:15<00:18,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.7164, 13.0618, 10.5845, 10.3737, 10.5561, -6.2588,  7.9316,  6.6700,\n",
      "        -5.8716,  7.6757, 12.1178, 13.8978, -4.7271, -3.2493, -6.3433, -7.8182,\n",
      "        -9.0926, -3.1307, 11.1691,  9.2486, -3.5366, 11.8203, -4.3843, -5.4767,\n",
      "        11.0287, 14.6459,  8.1536, 11.6745, 11.2626,  1.2642, -2.5763,  3.7198,\n",
      "        -5.2344, -7.9711, -5.2479, 12.8300, 10.0527, -2.8219, -1.0619, 10.5348,\n",
      "        14.4955,  7.7569, -1.2660,  9.9812], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [159 / 200] Loss : 0.1366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.198453:  80%|██████████████████████████████████████████████████▋            | 161/200 [01:16<00:18,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.9703, 12.1722,  9.9572,  8.6384,  8.9949, -6.3290,  5.7541,  6.7460,\n",
      "        -5.9853,  8.0862, 11.1156, 13.5778, -4.8498, -3.9899, -5.3184, -7.3837,\n",
      "        -7.9088, -5.8498,  9.6334,  7.7873, -4.5709,  8.8365, -4.9304, -5.4389,\n",
      "         9.7553, 14.4468,  9.0464, 11.2982,  8.9629, -0.2689, -2.2382,  0.2020,\n",
      "        -6.3264, -8.0900, -6.2238, 12.1700,  9.5228, -0.7912,  4.3137, 12.2575,\n",
      "        13.4547,  5.9304, -5.1275,  7.9063], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [160 / 200] Loss : 0.1171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.203926:  81%|███████████████████████████████████████████████████            | 162/200 [01:16<00:17,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.2942, 12.1096,  9.2293,  8.4964,  9.0648, -5.6864,  5.2160,  6.0849,\n",
      "        -5.5789,  9.5069, 10.9844, 12.9712, -5.4024, -4.1390, -6.4895, -7.9610,\n",
      "        -8.2061, -6.2055,  6.8933, 11.9688, -4.8983,  6.2239, -4.3733, -5.6403,\n",
      "         8.7615, 14.3440, 11.4413, 12.6045, 11.7065,  4.4833, -0.3790,  3.1602,\n",
      "        -7.1067, -8.6527, -6.2243, 12.2642,  7.0244,  0.9008,  9.8040, 13.1965,\n",
      "        13.5703,  2.3883, -4.8020,  8.3246], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [161 / 200] Loss : 0.1203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.188660:  82%|███████████████████████████████████████████████████▎           | 163/200 [01:17<00:17,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.7633, 12.0663,  9.1954,  8.6501,  9.3959, -6.7070,  2.6416,  5.5222,\n",
      "        -5.9359,  8.7145, 11.2744, 11.9653, -4.9984, -4.1512, -6.7118, -7.3994,\n",
      "        -7.5986, -7.5143,  7.0056, 10.8019, -4.6836,  6.4995, -6.3003, -4.4952,\n",
      "         8.9954, 14.3292, 11.3645, 10.8463, 11.5657,  4.7510,  1.2281,  5.8419,\n",
      "        -8.1076, -8.7158, -7.0176,  9.8417,  3.0731, -3.7448,  3.3086, 12.0559,\n",
      "        13.7411,  3.6553, -4.1580,  8.7554], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [162 / 200] Loss : 0.1194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.180281:  82%|███████████████████████████████████████████████████▋           | 164/200 [01:17<00:16,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.8099, 10.8467,  9.3496,  7.7960,  7.6652, -6.9307,  7.6913,  2.3650,\n",
      "        -6.5892,  6.8366, 11.2900, 12.0285, -5.3755, -4.7612, -6.5991, -6.9690,\n",
      "        -7.4993, -7.7524,  2.0830, 15.0818, -3.4925, 13.2512, -5.1561, -4.6251,\n",
      "         6.1882, 14.2200, 11.2876, 12.3251,  9.6506,  1.2896, -1.7092,  1.4770,\n",
      "        -7.7609, -9.1898, -7.6512, 12.7389,  8.6261, -3.2057,  1.5975, 10.5046,\n",
      "        13.7291,  1.3672, -8.4094,  7.8222], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [163 / 200] Loss : 0.0985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.172678:  82%|███████████████████████████████████████████████████▉           | 165/200 [01:17<00:16,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.7784, 12.1248,  9.7170,  8.6988,  8.4845, -6.9053,  4.1869,  4.8178,\n",
      "        -6.0304,  7.5682, 11.3012, 11.1338, -5.5482, -3.9630, -7.2342, -6.8015,\n",
      "        -6.8733, -7.6643,  3.3792, 15.2506, -1.9798, 13.0247, -5.7364, -4.8909,\n",
      "         8.8660, 14.2371, 10.1162, 11.5292, 10.2985,  1.4788, -1.3989,  2.2359,\n",
      "        -7.0675, -9.0970, -7.0168, 12.7967,  9.4948, -3.6112, -0.0852,  9.2158,\n",
      "        13.9342,  7.1784, -6.0807,  8.3337], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [164 / 200] Loss : 0.1131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.160806:  83%|████████████████████████████████████████████████████▎          | 166/200 [01:18<00:15,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.6402, 13.0167, 10.7342, 10.1086,  9.2507, -6.6197,  8.6413,  6.0944,\n",
      "        -5.1620,  8.3359, 12.1270,  9.2047, -4.6814, -3.0267, -5.9513, -6.2553,\n",
      "        -8.0085, -7.0652,  8.8392, 12.5444, -4.1429, 12.1893, -5.2503, -4.7609,\n",
      "        11.2671, 13.0853,  2.8934,  6.9005, 11.4409,  3.9189, -0.4638,  4.6978,\n",
      "        -7.4190, -8.6105, -6.1487, 12.5756,  7.7373, -3.8472, -1.0607,  7.5840,\n",
      "        13.8133, 10.7792, -0.9078, 10.2338], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [165 / 200] Loss : 0.098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.157766:  84%|████████████████████████████████████████████████████▌          | 167/200 [01:18<00:15,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.2033, 12.8555, 10.1401,  9.6802,  9.7905, -6.2412,  8.6717,  5.1581,\n",
      "        -6.6512,  6.1685, 11.6580, 10.5680, -5.1523, -3.8984, -5.9837, -7.5422,\n",
      "        -8.2321, -6.7813,  5.6048, 12.4437, -3.8373, 12.6019, -6.6549, -5.5450,\n",
      "        10.3087, 13.8522,  5.6640,  6.7495, 12.3360,  6.2501,  0.1835,  5.2973,\n",
      "        -8.0972, -8.5074, -6.6398, 12.9224,  9.0057, -1.2800,  5.5635, 11.8752,\n",
      "        14.3767,  7.3497, -4.6944,  9.5101], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [166 / 200] Loss : 0.0964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.161545:  84%|████████████████████████████████████████████████████▉          | 168/200 [01:19<00:14,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.5683, 11.9822,  9.7778,  8.6933,  7.9220, -6.7426,  9.2725,  5.3342,\n",
      "        -4.3008,  5.6721, 11.1329, 12.1502, -5.8479, -4.0540, -6.3714, -7.2268,\n",
      "        -7.7914, -8.0416,  3.6278, 15.4218, -3.0838, 13.2693, -7.0863, -6.1798,\n",
      "         7.0413, 14.6448, 10.2790, 10.6409, 11.1702,  2.2850, -1.4318,  3.7105,\n",
      "        -9.4007, -8.6716, -7.1447, 13.0383,  9.6609, -0.1404,  9.1946, 12.9198,\n",
      "        13.8107,  5.9392, -7.1146,  5.6267], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [167 / 200] Loss : 0.0851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.157375:  84%|█████████████████████████████████████████████████████▏         | 169/200 [01:19<00:14,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.0322, 12.5034, 10.2173,  8.5247,  7.9501, -6.5801,  8.5608,  5.8599,\n",
      "        -4.9568,  4.9915, 10.6002,  8.6659, -5.8377, -4.1636, -7.3839, -8.7461,\n",
      "        -8.3502, -7.8448,  5.4209, 14.2359, -4.5605, 13.1280, -6.9899, -6.8920,\n",
      "         7.5328, 14.5390,  8.8110,  6.5871,  9.4276, -1.0189, -2.8947,  1.0883,\n",
      "        -8.4988, -9.1675, -6.5618, 11.0703,  3.3672, -2.2955,  7.9682, 12.8728,\n",
      "        13.8640,  5.6343, -7.5330,  5.7221], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [168 / 200] Loss : 0.0888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.150218:  85%|█████████████████████████████████████████████████████▌         | 170/200 [01:20<00:14,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.0339, 13.8039, 11.2529, 10.1313,  9.7890, -6.4247,  7.0976,  5.7879,\n",
      "        -7.1229,  7.8263, 12.5447, 11.6559, -5.8890, -4.7207, -7.5206, -7.2791,\n",
      "        -9.1288, -6.4942,  6.4669, 14.2760, -4.8719,  9.4449, -6.4041, -6.6942,\n",
      "         9.2308, 15.0906, 11.2210,  7.5496, 11.0169,  2.7993, -1.6675,  5.3253,\n",
      "        -8.4626, -8.9619, -6.9801, 10.9105,  4.5168, -3.4364,  7.3409, 13.5154,\n",
      "        14.2026,  6.4471, -7.0698,  8.8580], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [169 / 200] Loss : 0.0748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.160859:  86%|█████████████████████████████████████████████████████▊         | 171/200 [01:20<00:13,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.1186, 13.2665, 11.9188,  9.8596, 10.0773, -5.4766,  8.2073,  5.5243,\n",
      "        -7.3593,  8.2784, 12.8396, 12.9314, -5.9294, -4.2478, -6.9046, -9.0417,\n",
      "        -8.9911, -7.5079,  5.1028, 13.9268, -4.2570,  7.1832, -8.1340, -7.1051,\n",
      "         6.8423, 15.3859,  7.6702,  5.9597, 12.5765,  4.8637,  1.3216,  7.1547,\n",
      "        -8.0885, -8.8827, -6.6419, 11.6212,  2.3608, -3.2648,  6.6224, 13.6590,\n",
      "        14.8834,  4.9661, -7.6847,  9.1454], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [170 / 200] Loss : 0.0864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.153439:  86%|██████████████████████████████████████████████████████▏        | 172/200 [01:21<00:13,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.1890, 13.1985, 11.1809,  8.9652,  9.5562, -5.4381, 10.7131,  5.2179,\n",
      "        -7.4057,  4.9426, 11.6710, 12.7264, -6.1225, -3.9176, -7.6449, -8.1952,\n",
      "        -7.9424, -8.4900,  5.6669, 15.3639, -2.5045, 13.6605, -7.4451, -7.8610,\n",
      "         6.1362, 15.5352, 11.3296,  9.2747, 12.4927,  1.0270, -2.8988,  3.5904,\n",
      "        -8.4257, -9.2513, -6.7334, 13.3929,  8.2851, -3.8993,  4.5757, 13.1037,\n",
      "        14.8223,  6.5181, -8.5315,  6.8195], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [171 / 200] Loss : 0.077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.140370:  86%|██████████████████████████████████████████████████████▍        | 173/200 [01:21<00:12,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.0463, 13.4562, 11.1307,  9.3153,  9.1221, -4.5929, 10.7533,  7.3646,\n",
      "        -6.8473,  6.3616, 12.0699, 11.1755, -5.9611, -4.8837, -7.0962, -7.3692,\n",
      "        -8.1441, -8.9300,  5.7216, 14.8760, -2.3532, 14.5468, -7.7563, -6.4639,\n",
      "         7.6320, 15.6050,  9.6200,  9.9902, 12.6845,  1.4031, -3.0375,  2.1585,\n",
      "        -7.8959, -8.9875, -6.7382, 13.7320, 11.2952, -3.5759,  2.9045, 12.8830,\n",
      "        14.7247,  3.9040, -7.4773,  7.6197], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [172 / 200] Loss : 0.0748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.140404:  87%|██████████████████████████████████████████████████████▊        | 174/200 [01:22<00:12,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.4524, 13.7313, 11.2864,  9.7198, 10.9656, -4.8526, 10.6975,  4.9827,\n",
      "        -7.2579,  6.9212, 13.0782, 13.2100, -6.3563, -5.2706, -6.6492, -8.0401,\n",
      "        -8.7806, -8.7947,  6.5520, 12.8956, -3.5992, 15.0313, -7.4564, -6.4700,\n",
      "         7.9241, 15.9753, 11.2842, 11.0388, 14.1944,  5.2186, -2.3836,  2.3055,\n",
      "        -8.5450, -8.9749, -6.4294, 14.3553, 13.5558, -3.0757,  5.1672, 13.7042,\n",
      "        15.1537,  5.5910, -8.1313,  8.2926], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [173 / 200] Loss : 0.0759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.136187:  88%|███████████████████████████████████████████████████████▏       | 175/200 [01:22<00:11,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.5466, 14.2353, 12.2770,  8.8799, 11.5403, -5.8667,  9.9557,  4.6342,\n",
      "        -7.7761,  9.8572, 12.7951, 13.5197, -6.5448, -5.5864, -7.2000, -9.5796,\n",
      "        -8.0043, -8.5153,  6.2217, 14.5571, -4.6392, 14.9326, -7.3153, -6.7967,\n",
      "         9.7942, 16.2628, 12.0115, 11.4620, 14.8309,  7.8015, -1.8541,  6.6279,\n",
      "        -8.0221, -9.4011, -6.5684, 14.4571, 13.5392, -3.7071,  5.4652, 12.7243,\n",
      "        15.7044,  8.3230, -6.7437,  8.1124], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [174 / 200] Loss : 0.0672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.138588:  88%|███████████████████████████████████████████████████████▍       | 176/200 [01:23<00:11,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.5915, 14.2116, 12.4823, 10.3997, 11.3779, -5.3448,  8.8418,  3.0078,\n",
      "        -6.8578,  9.8837, 13.5298, 13.1800, -7.2270, -6.2595, -8.2138, -9.8834,\n",
      "        -9.1759, -7.7638, 10.1810, 14.4181, -5.1526, 12.8873, -5.2816, -7.1952,\n",
      "         8.4331, 16.1283, 10.9842,  9.9732, 15.3930,  8.3421, -1.0516,  6.9565,\n",
      "        -8.1780, -9.0306, -7.0172, 13.5970, 13.5304, -4.4080,  3.4835, 13.0332,\n",
      "        15.4821,  8.9116, -3.7107, 10.6241], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [175 / 200] Loss : 0.0671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.143633:  88%|███████████████████████████████████████████████████████▊       | 177/200 [01:23<00:10,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.5784, 14.2124, 12.2049, 11.0029, 12.5092, -6.6500,  7.6624,  4.4313,\n",
      "        -8.0535,  9.3246, 13.8963, 10.2840, -6.9481, -6.8308, -8.2367, -9.9169,\n",
      "        -9.4824, -7.6826,  6.5613, 14.5068, -5.8214, 12.8914, -4.8367, -8.0515,\n",
      "         8.3186, 16.0257,  9.0503,  9.7551, 14.8253,  6.1518, -2.4573,  6.3437,\n",
      "        -7.1930, -9.5359, -7.1968, 13.7579, 11.8656, -4.9397,  3.5956, 12.5896,\n",
      "        15.3660,  9.8853, -6.4916, 10.1160], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [176 / 200] Loss : 0.066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.142005:  89%|████████████████████████████████████████████████████████       | 178/200 [01:24<00:10,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.6614, 14.1008, 11.9590, 10.3757, 10.7814, -6.6306,  7.5508,  5.1382,\n",
      "        -7.9688,  8.8431, 13.7042, 12.8044, -7.1171, -6.3728, -8.7934, -9.7151,\n",
      "        -8.8415, -7.9652,  7.5866, 12.8687, -6.0846, 10.6938, -7.6653, -7.5635,\n",
      "         5.4609, 15.8436,  8.1710,  7.1580, 14.3723,  5.7610, -2.8609,  4.3307,\n",
      "        -8.4214, -9.8992, -7.5520, 13.1040, 11.9293, -5.1295,  0.6380, 12.2015,\n",
      "        15.4075,  9.5984, -4.0643, 10.0240], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [177 / 200] Loss : 0.0673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.132271:  90%|████████████████████████████████████████████████████████▍      | 179/200 [01:24<00:09,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.6833, 12.8279, 11.4910,  9.9001, 11.0057, -6.6486,  8.3144,  5.5009,\n",
      "        -7.0462,  4.7783, 12.9207, 13.3551, -7.3907, -6.8076, -7.7448, -9.5555,\n",
      "        -7.7403, -8.6078,  6.5730, 15.1589, -5.9427,  8.3264, -7.9949, -7.4571,\n",
      "         8.8478, 16.2943, 13.2269, 11.8032, 15.1839,  4.8388, -3.3822,  4.0935,\n",
      "        -7.5799, -9.8892, -7.5281, 13.6312, 11.6694, -3.9404,  8.6479, 14.9699,\n",
      "        14.9173,  6.7335, -7.8370,  7.9816], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [178 / 200] Loss : 0.0645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.002501:  90%|████████████████████████████████████████████████████████▋      | 180/200 [01:24<00:09,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -7.4133,  13.1362,  12.0981,  10.0322,  11.2070,  -6.3629,   6.8493,\n",
      "          5.6445,  -8.1796,   5.0447,  13.0534,  13.9108,  -8.0109,  -6.9864,\n",
      "         -8.2941,  -8.5661,  -7.8456,  -8.8325,   8.1575,  16.2803,  -5.5046,\n",
      "         10.1354,  -8.7895,  -7.2960,   9.5537,  16.1243,  12.8118,  12.4787,\n",
      "         14.9028,   4.5107,  -3.5123,   5.4067,  -7.1743, -10.0931,  -8.1073,\n",
      "         13.0118,  11.5816,  -3.1779,  10.1137,  15.2615,  14.6313,   7.6927,\n",
      "         -8.1858,   6.6477], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [179 / 200] Loss : 0.0607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.132852:  90%|█████████████████████████████████████████████████████████      | 181/200 [01:25<00:08,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.4691, 13.9304, 11.9343,  9.6842, 11.0923, -5.8585,  7.2152,  4.9695,\n",
      "        -4.8713,  7.5936, 12.8892, 13.0832, -7.6522, -7.0574, -7.9199, -9.3036,\n",
      "        -7.8765, -8.7100,  4.7858, 15.6046, -6.0418, 10.1533, -8.0177, -8.0213,\n",
      "         9.0996, 16.6774, 13.2865, 10.4845, 15.0491,  3.9198, -3.7423,  4.6405,\n",
      "        -7.0615, -9.9261, -7.6948, 13.5462,  9.6697, -3.7580, 10.8006, 15.2498,\n",
      "        15.7910,  6.8489, -6.3251,  8.5351], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [180 / 200] Loss : 0.0653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.131460:  91%|█████████████████████████████████████████████████████████▎     | 182/200 [01:25<00:08,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.6429, 14.4289, 11.6555, 10.2099, 12.1183, -6.9438,  8.8936,  6.1720,\n",
      "        -7.9982,  7.1132, 14.0878, 14.5058, -7.3732, -6.0386, -7.3417, -9.6970,\n",
      "        -6.8607, -9.9876,  7.3016, 12.6846, -6.3897,  6.9473, -8.8856, -9.1702,\n",
      "         9.8642, 16.9946,  8.2402,  8.4255, 15.9974,  5.1889, -4.2842,  3.2430,\n",
      "        -8.0568, -9.7630, -7.3371, 13.6843,  8.3276, -5.6533,  5.1010, 15.2583,\n",
      "        15.9672,  9.6960, -6.7883,  9.8342], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [181 / 200] Loss : 0.0643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.123494:  92%|█████████████████████████████████████████████████████████▋     | 183/200 [01:26<00:07,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -6.8878,  14.5536,  11.5972,  10.9063,  11.6218,  -6.1030,   7.7701,\n",
      "          6.9181,  -8.1720,  10.6134,  14.0909,  13.2812,  -6.8707,  -5.7767,\n",
      "         -7.1922,  -9.6676,  -7.9492,  -9.0062,   7.9488,  13.9433,  -6.1999,\n",
      "         11.0392,  -6.4147,  -8.8381,  11.6120,  17.1576,  10.5296,   5.4754,\n",
      "         15.6010,   6.4368,  -3.2429,   4.2901,  -7.4377,  -9.6154,  -7.5833,\n",
      "         13.5517,  13.4715,  -5.2908,   4.1742,  14.0970,  16.6791,   7.8839,\n",
      "        -10.0744,   9.5894], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [182 / 200] Loss : 0.0635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.129771:  92%|█████████████████████████████████████████████████████████▉     | 184/200 [01:26<00:07,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.4805, 14.9058, 11.8714, 10.6882, 10.9928, -4.4461,  9.2690,  6.3934,\n",
      "        -8.9885,  9.5358, 14.8604, 15.0514, -6.8407, -5.4138, -7.0696, -9.3584,\n",
      "        -7.7367, -8.2826,  7.7233, 16.2750, -5.5653, 13.4049, -7.8494, -8.4312,\n",
      "        10.3460, 17.4380, 11.8468,  8.9004, 16.1902,  6.2622, -3.3865,  5.1081,\n",
      "        -7.9872, -9.9693, -6.7634, 13.5064, 11.2517, -4.7244,  5.3588, 15.3092,\n",
      "        16.5948,  4.8433, -9.5028,  7.0140], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [183 / 200] Loss : 0.0566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.123363:  92%|██████████████████████████████████████████████████████████▎    | 185/200 [01:27<00:07,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -6.0250,  14.7769,  12.6708,  11.5620,  11.5362,  -5.4551,   7.1437,\n",
      "          2.8707,  -9.1037,  10.9875,  14.1850,  15.3822,  -7.2400,  -5.6387,\n",
      "         -7.0961,  -9.8003,  -8.9331, -10.0772,   5.9494,  16.1462,  -4.8464,\n",
      "         15.5201,  -8.7824,  -8.9703,   9.6981,  17.8204,  11.1915,  12.8304,\n",
      "         16.6455,   5.6758,  -3.7078,   4.5410,  -7.5612, -10.0885,  -6.4824,\n",
      "         13.6884,  15.0203,  -3.8616,   7.2495,  15.8662,  16.9044,   2.0830,\n",
      "        -11.0671,   8.8407], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [184 / 200] Loss : 0.0587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.129922:  93%|██████████████████████████████████████████████████████████▌    | 186/200 [01:27<00:06,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -5.1934,  15.5720,  13.2063,  11.5319,  12.9413,  -4.3864,   8.9573,\n",
      "          4.2421,  -8.6871,  10.8516,  15.6145,  15.8169,  -7.0359,  -5.1249,\n",
      "         -6.4069, -10.1657,  -9.5021,  -8.7751,   8.6045,  17.6275,  -4.5255,\n",
      "         14.3418,  -8.2025,  -8.1099,  10.3097,  17.9050,  11.4723,  11.9732,\n",
      "         16.8183,   5.6496,  -4.4017,   7.1653,  -6.7767,  -9.3537,  -6.5071,\n",
      "         13.8265,  14.8403,  -4.6740,   7.0493,  16.2170,  16.9656,   6.4657,\n",
      "        -10.3371,   7.5230], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [185 / 200] Loss : 0.0565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.126161:  94%|██████████████████████████████████████████████████████████▉    | 187/200 [01:28<00:06,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -5.8623,  15.7544,  12.7790,  11.8662,  12.8557,  -5.0074,   9.5721,\n",
      "          3.8964,  -8.7534,  11.1396,  15.7115,  16.5115,  -7.2208,  -5.8599,\n",
      "         -5.5888,  -9.2703, -11.0401,  -8.1151,   9.6917,  13.9638,  -4.5653,\n",
      "         14.4849,  -6.6515,  -8.4638,  11.1254,  17.8765,  12.5024,  11.8575,\n",
      "         16.8370,   6.4318,  -4.3044,   7.1182,  -5.0758,  -9.3583,  -6.0858,\n",
      "         13.0621,  11.0529,  -5.1807,   4.2278,  16.3334,  17.3980,   6.0419,\n",
      "         -9.4513,  10.9916], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [186 / 200] Loss : 0.0561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.113387:  94%|███████████████████████████████████████████████████████████▏   | 188/200 [01:28<00:05,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -5.7802,  14.9904,  13.8843,  12.6935,  13.4544,  -6.5919,   7.8269,\n",
      "          6.2438,  -9.8508,  10.9520,  16.2467,  15.5520,  -7.4677,  -5.9390,\n",
      "         -6.7924, -10.3864,  -9.4011,  -4.9436,  11.5509,  15.2349,  -5.3362,\n",
      "         12.2176,  -5.2266,  -8.3457,  13.0376,  17.9584,  10.8250,   9.6874,\n",
      "         16.6476,   5.0548,  -4.8038,   7.4949,  -6.4705,  -8.9357,  -6.4148,\n",
      "         12.8942,  11.5348,  -6.0703,   4.7907,  15.7126,  17.7392,   8.3187,\n",
      "         -6.3472,  10.3836], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [187 / 200] Loss : 0.056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.117758:  94%|███████████████████████████████████████████████████████████▌   | 189/200 [01:29<00:05,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.2981e+00,  1.5897e+01,  1.4192e+01,  1.2782e+01,  1.2821e+01,\n",
      "        -6.0302e+00,  7.8960e+00,  5.3650e+00, -9.6768e+00,  9.5704e+00,\n",
      "         1.5886e+01,  1.5426e+01, -7.5930e+00, -6.1480e+00, -6.4104e+00,\n",
      "        -9.5916e+00, -1.0670e+01, -7.8305e+00,  9.6698e+00,  1.5841e+01,\n",
      "        -5.9749e+00,  1.1632e+01, -4.8791e+00, -8.4032e+00,  1.2630e+01,\n",
      "         1.7945e+01,  1.1233e+01,  7.7596e+00,  1.6014e+01,  5.3085e+00,\n",
      "        -4.6655e+00,  6.8478e+00, -6.2023e+00, -1.0247e+01, -6.1257e+00,\n",
      "         1.3283e+01,  9.2313e+00, -6.2262e+00, -1.7276e-02,  1.5680e+01,\n",
      "         1.7865e+01,  7.7590e+00, -6.8684e+00,  1.0599e+01], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [188 / 200] Loss : 0.0649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.110494:  95%|███████████████████████████████████████████████████████████▊   | 190/200 [01:29<00:04,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -5.6276,  15.6171,  13.0098,  11.6316,  13.5148,  -5.6262,   6.2928,\n",
      "          2.6422,  -7.8886,   9.9054,  15.4541,  16.3147,  -8.2467,  -6.7011,\n",
      "         -7.0890, -10.5327, -11.0909,  -8.6127,  10.8771,  18.3339,  -3.8401,\n",
      "         13.4656,  -7.3942,  -8.2617,  11.4703,  17.8430,  16.4768,  15.2871,\n",
      "         17.3719,   6.3155,  -2.9915,   7.3159,  -6.9393, -10.2337,  -7.3206,\n",
      "         13.2020,   9.7915,  -1.8046,  14.4755,  17.6143,  16.4239,   7.5357,\n",
      "         -7.3461,   9.9968], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [189 / 200] Loss : 0.0633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.123789:  96%|████████████████████████████████████████████████████████████▏  | 191/200 [01:30<00:04,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -7.2589,  15.4381,  13.3171,  11.9048,  14.0905,  -6.3148,   5.9656,\n",
      "          6.2048,  -7.5363,  10.2498,  15.7991,  16.5457,  -8.4583,  -6.9579,\n",
      "         -7.7297, -11.4073, -10.5505,  -8.7417,  10.0222,  18.3194,  -6.1427,\n",
      "         10.1568,  -7.7520,  -7.3447,  12.6700,  17.9881,  14.8059,  11.4521,\n",
      "         16.6365,   6.0897,  -4.4965,   8.6399,  -6.4403,  -9.6526,  -7.2840,\n",
      "         13.2474,  14.0363,  -3.5128,  13.0235,  17.3403,  17.4238,   7.7973,\n",
      "         -8.0210,  10.3411], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [190 / 200] Loss : 0.0549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.155336:  96%|████████████████████████████████████████████████████████████▍  | 192/200 [01:30<00:03,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -8.1400,  14.7547,  14.0342,  12.5725,  13.6177,  -6.6371,   5.1938,\n",
      "          7.2146,  -6.0681,  10.1686,  16.3804,  13.7678,  -7.5989,  -6.3717,\n",
      "         -7.4292, -10.4436,  -9.4273,  -8.3413,   9.9811,   9.2818,  -7.0443,\n",
      "          4.6933,  -7.6615,  -8.5918,  13.6533,  17.7686,   5.8363,   0.3019,\n",
      "         14.3863,   3.4800,  -5.6375,   7.6044,  -7.6198,  -9.2814,  -6.6183,\n",
      "         10.2630,   1.1208,  -7.3250,  -0.1131,  11.5283,  17.7670,  10.7004,\n",
      "         -7.2035,  11.4079], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [191 / 200] Loss : 0.0654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.020281:  96%|████████████████████████████████████████████████████████████▊  | 193/200 [01:30<00:03,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -6.9872,  15.0718,  12.5049,  10.8156,  13.4329,  -5.7403,   4.8410,\n",
      "          6.6828,  -6.2289,   8.6251,  14.9150,  17.5797,  -8.2682,  -6.7873,\n",
      "         -8.1833,  -8.9821,  -9.4595,  -9.6089,  10.4064,  19.0004,  -5.0113,\n",
      "         15.2626,  -6.8408,  -7.2557,  12.0673,  17.8439,  17.2530,  17.1679,\n",
      "         17.3556,   7.5711,  -3.0615,   7.7750,  -5.7289, -10.3510,  -8.0941,\n",
      "         13.1922,  16.2386,   0.2271,  15.6274,  17.1165,  17.4080,   5.9538,\n",
      "         -7.5147,  10.0161], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [192 / 200] Loss : 0.079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.139801:  97%|█████████████████████████████████████████████████████████████  | 194/200 [01:31<00:02,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -6.9084,  15.1628,  12.9105,  11.4346,  14.3368,  -6.7993,   5.7532,\n",
      "          6.2965,  -8.3859,   8.3757,  14.6405,  17.2510,  -8.0339,  -6.5206,\n",
      "         -7.4025,  -8.8039,  -8.5054,  -8.6819,   9.1537,  18.8958,  -4.7609,\n",
      "         14.5494,  -8.8775,  -7.6880,  10.6282,  17.6845,  18.0471,  18.0387,\n",
      "         17.5584,   7.5295,  -2.8408,   7.8363,  -8.0014, -10.3444,  -6.8002,\n",
      "         15.3445,  16.7334,  -3.3243,   9.1432,  16.9851,  18.1681,   8.2142,\n",
      "         -8.9238,  10.6395], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [193 / 200] Loss : 0.076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.125294:  98%|█████████████████████████████████████████████████████████████▍ | 195/200 [01:32<00:02,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -7.5650,  15.2191,  11.8432,   7.8870,   8.5402,  -5.7967,   4.9781,\n",
      "         -2.5049,  -6.0196,   7.1973,  13.4858,  17.7706,  -7.3946,  -6.5996,\n",
      "         -7.4902,  -6.1864,  -6.9839,  -8.2316,   8.4571,  19.2744,  -6.1986,\n",
      "         17.0494,  -9.7433,  -9.1336,  12.8328,  18.0004,  18.2005,  17.9004,\n",
      "         17.7888,   6.3857,  -4.3831,   6.0710,  -6.8940, -10.8161,  -7.5671,\n",
      "         15.0995,  17.9979,  -4.8406,   7.7245,  17.5040,  17.8177,   5.5284,\n",
      "         -9.6498,   8.1712], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [194 / 200] Loss : 0.1011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.166742:  98%|█████████████████████████████████████████████████████████████▋ | 196/200 [01:32<00:01,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -8.1359,  15.3826,  13.1678,  10.0837,   8.4153,  -6.5613,   2.9385,\n",
      "          4.8140,  -6.8116,  11.4141,  16.0640,  17.1850,  -7.1197,  -6.8022,\n",
      "         -7.3345,  -7.5833,  -8.4177,  -7.1618,   9.5107,  18.5411,  -6.7439,\n",
      "         12.0152,  -7.8475,  -9.4217,  11.9674,  18.2168,  18.1580,  17.9231,\n",
      "         17.9062,   5.8571,  -5.2302,   6.5812,  -6.6843, -10.1136,  -6.1426,\n",
      "         16.5404,  15.4173,  -6.2782,   2.8525,  16.7754,  18.1621,   9.4088,\n",
      "         -9.8752,   7.5497], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [195 / 200] Loss : 0.064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.128150:  98%|██████████████████████████████████████████████████████████████ | 197/200 [01:32<00:01,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -8.3561,  15.0516,  11.6927,   8.7540,   6.1348,  -6.3570,   3.8643,\n",
      "          7.0383,  -7.2077,  11.4696,  15.5139,  16.5594,  -7.6802,  -6.4329,\n",
      "         -7.7954,  -9.7550,  -9.5859,  -8.4924,   7.4592,  19.1556,  -6.8484,\n",
      "         11.2746,  -5.5746,  -9.5369,  11.4563,  17.8364,  18.2607,  17.3809,\n",
      "         17.6450,   4.3966,  -5.1400,   4.2538,  -7.8193, -11.4647,  -7.9076,\n",
      "         16.2614,  16.5080,  -5.9055,   6.2749,  16.9605,  17.1364,   4.0679,\n",
      "        -12.5966,   8.1686], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [196 / 200] Loss : 0.078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.128095:  99%|██████████████████████████████████████████████████████████████▎| 198/200 [01:33<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -8.1014,  15.5129,  11.1547,   8.9571,   6.4143,  -6.3179,   3.5209,\n",
      "          9.1114,  -9.3854,  12.3642,  15.4832,  17.7031,  -8.1277,  -5.4342,\n",
      "         -8.4279,  -9.9017, -10.9492,  -8.0424,  10.0718,  19.5133,  -6.8453,\n",
      "         11.6951,  -7.8618,  -6.8134,  11.9772,  17.3058,  18.1993,  17.8926,\n",
      "         16.9210,   4.7326,  -4.9457,   3.9207,  -7.6336, -11.9414,  -8.7073,\n",
      "         16.0443,  17.5613,  -6.3265,   4.5384,  17.0683,  17.2173,   5.1925,\n",
      "         -8.3486,   8.4107], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [197 / 200] Loss : 0.0726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.120783: 100%|██████████████████████████████████████████████████████████████▋| 199/200 [01:33<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -8.1057,  16.1284,  13.3902,  10.1827,   9.8216,  -7.1518,   4.7785,\n",
      "         10.4456,  -7.7018,  14.5219,  16.6407,  18.0719,  -7.5102,  -5.1873,\n",
      "         -7.2588, -10.4681, -11.0169,  -7.4122,  11.1643,  19.1244,  -6.3970,\n",
      "          7.9007,  -1.3107,  -5.8375,  12.7049,  17.8173,  18.3625,  17.9666,\n",
      "         17.0874,   5.1821,  -5.1770,   7.5816,  -4.7048, -10.6816,  -7.7492,\n",
      "         17.0883,  16.1201,  -6.5650,   7.0047,  17.2214,  17.6765,   8.2822,\n",
      "         -8.0584,  11.0325], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [198 / 200] Loss : 0.0821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 0.002766: 100%|███████████████████████████████████████████████████████████████| 200/200 [01:34<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -7.8707,  16.0659,  11.8437,   8.2021,   8.9129,  -5.3317,   8.1530,\n",
      "         10.0195,  -6.8407,  12.0673,  16.2925,  17.4405,  -6.1937,  -4.4285,\n",
      "         -6.5959,  -9.0924, -10.1322,  -7.5856,   9.7915,  19.1430,  -5.8327,\n",
      "         15.8462,  -9.5082,  -9.6626,  12.5388,  17.6464,  18.2295,  18.0145,\n",
      "         17.2460,   3.9784,  -5.0568,   5.6695,  -4.5037, -11.5925,  -6.9592,\n",
      "         16.6225,  17.0890,  -6.0363,   3.0293,  17.0173,  16.4765,   5.2298,\n",
      "         -7.8882,  11.1786], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch : [199 / 200] Loss : 0.0655\n"
     ]
    }
   ],
   "source": [
    "progress = tqdm(range(epoch))\n",
    "\n",
    "model.train()\n",
    "for i in progress :\n",
    "    batchloss = 0.0\n",
    "    batchacc= 0\n",
    "    for (data, label) in dataloader :\n",
    "        optim.zero_grad()\n",
    "        src_mask = model.generate_square_subsequent_mask(data.shape[1]).to(device)      \n",
    "        pred = model(data.to(device), src_mask)\n",
    "        \n",
    "        loss = criterion(pred, label.to(device, dtype=torch.float64))\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "#         score = cal_accuracy(pred.cpu(), label.cpu())\n",
    "#         progress.set_description(\"loss : {:0.6f} acc : {:0.6f}\".format(loss.cpu().item(), score))\n",
    "        progress.set_description(\"loss : {:0.6f}\".format(loss.cpu().item()))\n",
    "        \n",
    "        batchloss += loss\n",
    "#         batchacc += score\n",
    "#     print(f\"Epoch : [{i} / {epoch}] Loss : {round((batchloss/len(dataloader)).item(), 4)} Acc : {round((batchacc/len(dataloader)), 4)}\")\n",
    "    print(pred)\n",
    "    print(label)\n",
    "    print(f\"Epoch : [{i} / {epoch}] Loss : {round((batchloss/len(dataloader)).item(), 4)}\")\n",
    "    \n",
    "torch.save(model.state_dict(), f'./model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d191aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'./model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b97cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "__output = torch.full([10, 64], 1.5)\n",
    "__output.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5e0ece4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0590, -0.0577], device='cuda:0', grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.rand(2, 144, 6).to(device)\n",
    "data\n",
    "src_mask = model.generate_square_subsequent_mask(data.shape[1]).to(device)  \n",
    "re = model(data, src_mask)\n",
    "re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e7fa2d",
   "metadata": {},
   "source": [
    "# MLSTM-fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8d0efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class MLSTMfcn(nn.Module):\n",
    "    def __init__(self, *, num_classes=1, max_seq_len=144, num_features=6,\n",
    "                 num_lstm_out=128, num_lstm_layers=1, \n",
    "                 conv1_nf=128, conv2_nf=256, conv3_nf=128,\n",
    "                 lstm_drop_p=0.8, fc_drop_p=0.3):\n",
    "        \n",
    "        super(MLSTMfcn, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.num_features = num_features\n",
    "\n",
    "        self.num_lstm_out = num_lstm_out\n",
    "        self.num_lstm_layers = num_lstm_layers\n",
    "\n",
    "        self.conv1_nf = conv1_nf\n",
    "        self.conv2_nf = conv2_nf\n",
    "        self.conv3_nf = conv3_nf\n",
    "\n",
    "        self.lstm_drop_p = lstm_drop_p\n",
    "        self.fc_drop_p = fc_drop_p\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.num_features, \n",
    "                            hidden_size=self.num_lstm_out,\n",
    "                            num_layers=self.num_lstm_layers,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(self.num_features, self.conv1_nf, 8)\n",
    "        self.conv2 = nn.Conv1d(self.conv1_nf, self.conv2_nf, 5)\n",
    "        self.conv3 = nn.Conv1d(self.conv2_nf, self.conv3_nf, 3)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(self.conv1_nf)\n",
    "        self.bn2 = nn.BatchNorm1d(self.conv2_nf)\n",
    "        self.bn3 = nn.BatchNorm1d(self.conv3_nf)\n",
    "\n",
    "        self.se1 = SELayer(self.conv1_nf)  # ex 128\n",
    "        self.se2 = SELayer(self.conv2_nf)  # ex 256\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstmDrop = nn.Dropout(self.lstm_drop_p)\n",
    "        self.convDrop = nn.Dropout(self.fc_drop_p)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.conv3_nf+self.num_lstm_out, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, self.num_classes)\n",
    "        )\n",
    "\n",
    "#         self.out_layer = nn.Linear(1000+128, self.num_classes)\n",
    "#         self.dropout = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ''' input x should be in size [B,T,F], where \n",
    "            B = Batch size\n",
    "            T = Time samples\n",
    "            F = features\n",
    "        '''\n",
    "#         x1 = nn.utils.rnn.pack_padded_sequence(x, seq_lens.cpu(), \n",
    "#                                                batch_first=True, \n",
    "#                                                enforce_sorted=False)\n",
    "#         x1 = nn.utils.rnn.pack_padded_sequence(x, seq_lens, \n",
    "#                                                batch_first=True, \n",
    "#                                                enforce_sorted=False)\n",
    "        \n",
    "        x1, (ht,ct) = self.lstm(x)\n",
    "#         x1, _ = nn.utils.rnn.pad_packed_sequence(x1, batch_first=True, \n",
    "#                                                  padding_value=0.0)\n",
    "        x1 = x1[:,-1,:]\n",
    "        \n",
    "        x2 = x.transpose(2,1)\n",
    "        x2 = self.convDrop(self.relu(self.bn1(self.conv1(x2))))\n",
    "        x2 = self.se1(x2)\n",
    "        x2 = self.convDrop(self.relu(self.bn2(self.conv2(x2))))\n",
    "        x2 = self.se2(x2)\n",
    "        x2 = self.convDrop(self.relu(self.bn3(self.conv3(x2))))\n",
    "        x2 = torch.mean(x2,2)\n",
    "        \n",
    "        x_all = torch.cat((x1,x2),dim=1)\n",
    "        x_out = self.fc(x_all)\n",
    "#         concat = torch.cat([enc_out, x_out], dim=1)  # enc_out + hidden \n",
    "#         output = self.dropout(concat)\n",
    "#         x_output = self.out_layer(output)\n",
    "#         x_out = F.log_softmax(x_out, dim=1)\n",
    "\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee04206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
